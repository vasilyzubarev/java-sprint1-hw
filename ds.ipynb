{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   client_id  reject_count  confirm_count  last_summ    summ_  count_position  \\\n",
      "0       8195            27             13   132684.4  34875.3              18   \n",
      "1      16392            29             15   149790.1  19537.4              11   \n",
      "2      16396            25             17    80195.2  44583.0              23   \n",
      "3       8206            22             10    80089.5  22561.6              15   \n",
      "4      16398            14             14   163565.6  27986.4              17   \n",
      "\n",
      "   target  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('orders_seafood.csv')\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "RANDOM_STATE = 77\n",
    "\n",
    "X = data.drop(columns=['target', 'client_id'])\n",
    "y = data['target'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y, test_size=0.25, random_state=RANDOM_STATE)\n",
    "X_train_scalled = scaler.fit_transform(X_train)\n",
    "X_test_scalled = scaler.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf = clf.fit(X_train_scalled, y_train)\n",
    "y_pred = clf.predict(X_test_scalled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.648936170212766\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "RANDOM_STATE = 77\n",
    "\n",
    "data = pd.read_csv('orders_seafood.csv')\n",
    "X = data.drop(columns=['target', 'client_id'])\n",
    "y = data['target']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y, test_size=0.25, random_state=RANDOM_STATE)\n",
    "X_train_scalled = scaler.fit_transform(X_train)\n",
    "X_test_scalled = scaler.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf = clf.fit(X_train_scalled, y_train)\n",
    "y_pred = clf.predict(X_test_scalled)\n",
    "\n",
    "r = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066557.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZubarevVV\\AppData\\Local\\Temp\\ipykernel_22368\\2971787153.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  predicts['y_pred'] = y_pred\n",
      "C:\\Users\\ZubarevVV\\AppData\\Local\\Temp\\ipykernel_22368\\2971787153.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  predicts['y_test'] = y_test\n"
     ]
    }
   ],
   "source": [
    "predicts = X_test[['summ_']]\n",
    "predicts['y_pred'] = y_pred\n",
    "predicts['y_test'] = y_test\n",
    "\n",
    "TP = predicts[(predicts['y_pred']==1)&(predicts['y_test']==1)]['summ_'].sum()*0.7*0.8\n",
    "FP = predicts[(predicts['y_pred']==1)&(predicts['y_test']==0)]['summ_'].sum()*0.2\n",
    "\n",
    "money = TP-FP\n",
    "print(money) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  0.1    money:  1089660.98\n",
      "threshold:  0.18    money:  1089660.98\n",
      "threshold:  0.25    money:  1089660.98\n",
      "threshold:  0.32    money:  1089660.98\n",
      "threshold:  0.4    money:  1087737.372\n",
      "threshold:  0.48    money:  1080149.3480000002\n",
      "threshold:  0.55    money:  1049577.9239999999\n",
      "threshold:  0.62    money:  1022793.4440000001\n",
      "threshold:  0.7    money:  982374.764\n",
      "threshold:  0.77    money:  941061.4520000002\n",
      "threshold:  0.85    money:  858757.1720000001\n",
      "threshold:  0.92    money:  574174.244\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "thresholds = [round(i,2) for i in np.linspace(0.1,1,num = 12,endpoint=False)]\n",
    "y_proba_log = clf.predict_proba(X_test_scalled)[:,1]\n",
    "\n",
    "for i in thresholds:\n",
    "    y_pred_log = []\n",
    "    for j in y_proba_log:\n",
    "        if j<i:\n",
    "            y_pred_log.append(0)          \n",
    "        else:\n",
    "            y_pred_log.append(1) \n",
    "    predicts = pd.DataFrame(zip(y_pred_log, y_test,  X_test['summ_'].tolist()), \\\n",
    "                        columns = ['y_pred', 'y_test', 'summ_'])\n",
    "    TP = predicts[(predicts['y_pred']==1)&(predicts['y_test']==1)]['summ_'].sum()*0.7*0.8\n",
    "    FP = predicts[(predicts['y_pred']==1)&(predicts['y_test']==0)]['summ_'].sum()*0.2\n",
    "    money = TP-FP\n",
    "    print('threshold: ', i, '   money: ',money)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66629411, 0.33370589],\n",
       "       [0.0731452 , 0.9268548 ],\n",
       "       [0.11988478, 0.88011522],\n",
       "       [0.434114  , 0.565886  ],\n",
       "       [0.05873193, 0.94126807],\n",
       "       [0.36371976, 0.63628024],\n",
       "       [0.09251944, 0.90748056],\n",
       "       [0.39484904, 0.60515096],\n",
       "       [0.46739861, 0.53260139],\n",
       "       [0.18681317, 0.81318683],\n",
       "       [0.46131004, 0.53868996],\n",
       "       [0.44551028, 0.55448972],\n",
       "       [0.55804626, 0.44195374],\n",
       "       [0.44592497, 0.55407503],\n",
       "       [0.43112853, 0.56887147],\n",
       "       [0.35332039, 0.64667961],\n",
       "       [0.47616315, 0.52383685],\n",
       "       [0.38936303, 0.61063697],\n",
       "       [0.31611435, 0.68388565],\n",
       "       [0.08999448, 0.91000552],\n",
       "       [0.38521656, 0.61478344],\n",
       "       [0.49054469, 0.50945531],\n",
       "       [0.07437472, 0.92562528],\n",
       "       [0.14141904, 0.85858096],\n",
       "       [0.03644003, 0.96355997],\n",
       "       [0.47720563, 0.52279437],\n",
       "       [0.47907336, 0.52092664],\n",
       "       [0.19666456, 0.80333544],\n",
       "       [0.159852  , 0.840148  ],\n",
       "       [0.08235293, 0.91764707],\n",
       "       [0.2498764 , 0.7501236 ],\n",
       "       [0.40614588, 0.59385412],\n",
       "       [0.2829402 , 0.7170598 ],\n",
       "       [0.50741753, 0.49258247],\n",
       "       [0.39317965, 0.60682035],\n",
       "       [0.53826973, 0.46173027],\n",
       "       [0.12936655, 0.87063345],\n",
       "       [0.04709013, 0.95290987],\n",
       "       [0.28743793, 0.71256207],\n",
       "       [0.40396869, 0.59603131],\n",
       "       [0.03945029, 0.96054971],\n",
       "       [0.05189122, 0.94810878],\n",
       "       [0.05795959, 0.94204041],\n",
       "       [0.28600058, 0.71399942],\n",
       "       [0.04417266, 0.95582734],\n",
       "       [0.2063488 , 0.7936512 ],\n",
       "       [0.46404872, 0.53595128],\n",
       "       [0.05916632, 0.94083368],\n",
       "       [0.36615897, 0.63384103],\n",
       "       [0.46821891, 0.53178109],\n",
       "       [0.06812824, 0.93187176],\n",
       "       [0.05277791, 0.94722209],\n",
       "       [0.31856585, 0.68143415],\n",
       "       [0.42260707, 0.57739293],\n",
       "       [0.03300526, 0.96699474],\n",
       "       [0.27774353, 0.72225647],\n",
       "       [0.37836646, 0.62163354],\n",
       "       [0.48441019, 0.51558981],\n",
       "       [0.190791  , 0.809209  ],\n",
       "       [0.17401944, 0.82598056],\n",
       "       [0.49544021, 0.50455979],\n",
       "       [0.44462441, 0.55537559],\n",
       "       [0.2996889 , 0.7003111 ],\n",
       "       [0.39349067, 0.60650933],\n",
       "       [0.36067874, 0.63932126],\n",
       "       [0.07904744, 0.92095256],\n",
       "       [0.10914819, 0.89085181],\n",
       "       [0.4329838 , 0.5670162 ],\n",
       "       [0.20826158, 0.79173842],\n",
       "       [0.26835301, 0.73164699],\n",
       "       [0.1022851 , 0.8977149 ],\n",
       "       [0.65510175, 0.34489825],\n",
       "       [0.44551159, 0.55448841],\n",
       "       [0.37339867, 0.62660133],\n",
       "       [0.33898291, 0.66101709],\n",
       "       [0.04936636, 0.95063364],\n",
       "       [0.37346469, 0.62653531],\n",
       "       [0.40023192, 0.59976808],\n",
       "       [0.34787819, 0.65212181],\n",
       "       [0.37596117, 0.62403883],\n",
       "       [0.44690266, 0.55309734],\n",
       "       [0.34598522, 0.65401478],\n",
       "       [0.29408751, 0.70591249],\n",
       "       [0.55334769, 0.44665231],\n",
       "       [0.07531901, 0.92468099],\n",
       "       [0.31562861, 0.68437139],\n",
       "       [0.44530017, 0.55469983],\n",
       "       [0.15626185, 0.84373815],\n",
       "       [0.3921794 , 0.6078206 ],\n",
       "       [0.40604366, 0.59395634],\n",
       "       [0.09486325, 0.90513675],\n",
       "       [0.19542568, 0.80457432],\n",
       "       [0.0845698 , 0.9154302 ],\n",
       "       [0.43453049, 0.56546951],\n",
       "       [0.33209831, 0.66790169],\n",
       "       [0.20681525, 0.79318475],\n",
       "       [0.14179857, 0.85820143],\n",
       "       [0.05760532, 0.94239468],\n",
       "       [0.49250855, 0.50749145],\n",
       "       [0.56846817, 0.43153183],\n",
       "       [0.33369316, 0.66630684],\n",
       "       [0.2151843 , 0.7848157 ],\n",
       "       [0.2973188 , 0.7026812 ],\n",
       "       [0.48215034, 0.51784966],\n",
       "       [0.07406509, 0.92593491],\n",
       "       [0.44599181, 0.55400819],\n",
       "       [0.36568586, 0.63431414],\n",
       "       [0.31767637, 0.68232363],\n",
       "       [0.3154261 , 0.6845739 ],\n",
       "       [0.36146603, 0.63853397],\n",
       "       [0.11116762, 0.88883238],\n",
       "       [0.40800249, 0.59199751],\n",
       "       [0.05516596, 0.94483404],\n",
       "       [0.27923322, 0.72076678],\n",
       "       [0.39272079, 0.60727921],\n",
       "       [0.32907085, 0.67092915],\n",
       "       [0.26715911, 0.73284089],\n",
       "       [0.10764073, 0.89235927],\n",
       "       [0.06990012, 0.93009988],\n",
       "       [0.32962423, 0.67037577],\n",
       "       [0.285628  , 0.714372  ],\n",
       "       [0.06360753, 0.93639247],\n",
       "       [0.43708188, 0.56291812],\n",
       "       [0.3498984 , 0.6501016 ],\n",
       "       [0.06244094, 0.93755906],\n",
       "       [0.13060084, 0.86939916],\n",
       "       [0.55671307, 0.44328693],\n",
       "       [0.05564468, 0.94435532],\n",
       "       [0.35348544, 0.64651456],\n",
       "       [0.62084458, 0.37915542],\n",
       "       [0.44411389, 0.55588611],\n",
       "       [0.11035435, 0.88964565],\n",
       "       [0.44097499, 0.55902501],\n",
       "       [0.02955012, 0.97044988],\n",
       "       [0.25766024, 0.74233976],\n",
       "       [0.35028095, 0.64971905],\n",
       "       [0.02045562, 0.97954438],\n",
       "       [0.22517492, 0.77482508],\n",
       "       [0.03124408, 0.96875592],\n",
       "       [0.38092471, 0.61907529],\n",
       "       [0.13626595, 0.86373405],\n",
       "       [0.03466869, 0.96533131],\n",
       "       [0.49743511, 0.50256489],\n",
       "       [0.50754736, 0.49245264],\n",
       "       [0.1067357 , 0.8932643 ],\n",
       "       [0.12775531, 0.87224469],\n",
       "       [0.35264925, 0.64735075],\n",
       "       [0.3040249 , 0.6959751 ],\n",
       "       [0.09342142, 0.90657858],\n",
       "       [0.02553185, 0.97446815],\n",
       "       [0.24759011, 0.75240989],\n",
       "       [0.28500725, 0.71499275],\n",
       "       [0.14744728, 0.85255272],\n",
       "       [0.3135598 , 0.6864402 ],\n",
       "       [0.43076068, 0.56923932],\n",
       "       [0.38221247, 0.61778753],\n",
       "       [0.38801473, 0.61198527],\n",
       "       [0.15103177, 0.84896823],\n",
       "       [0.04949862, 0.95050138],\n",
       "       [0.05791262, 0.94208738],\n",
       "       [0.34578209, 0.65421791],\n",
       "       [0.06142425, 0.93857575],\n",
       "       [0.55517808, 0.44482192],\n",
       "       [0.36567908, 0.63432092],\n",
       "       [0.33625037, 0.66374963],\n",
       "       [0.35173137, 0.64826863],\n",
       "       [0.43280043, 0.56719957],\n",
       "       [0.60251646, 0.39748354],\n",
       "       [0.61213871, 0.38786129],\n",
       "       [0.38079228, 0.61920772],\n",
       "       [0.37748227, 0.62251773],\n",
       "       [0.12156611, 0.87843389],\n",
       "       [0.11734457, 0.88265543],\n",
       "       [0.2852279 , 0.7147721 ],\n",
       "       [0.29234307, 0.70765693],\n",
       "       [0.23651032, 0.76348968],\n",
       "       [0.36483497, 0.63516503],\n",
       "       [0.38520085, 0.61479915],\n",
       "       [0.36135013, 0.63864987],\n",
       "       [0.40015404, 0.59984596],\n",
       "       [0.16755785, 0.83244215],\n",
       "       [0.26067797, 0.73932203],\n",
       "       [0.0236199 , 0.9763801 ],\n",
       "       [0.28730818, 0.71269182],\n",
       "       [0.44299668, 0.55700332],\n",
       "       [0.0291439 , 0.9708561 ],\n",
       "       [0.30837587, 0.69162413],\n",
       "       [0.50443289, 0.49556711]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba_log = clf.predict_proba(X_test_scalled)\n",
    "y_proba_log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
