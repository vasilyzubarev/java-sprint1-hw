{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Неработающая нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Пример данных\n",
    "data = {\n",
    "    \"description\": [\n",
    "        \"Apple iPhone 13 with 128GB storage\",\n",
    "        \"Samsung Galaxy S21 Smartphone\",\n",
    "        \"Organic cotton T-shirt size M\",\n",
    "        \"Wireless Bluetooth Headphones\",\n",
    "        \"Stainless steel kitchen knife set\",\n",
    "        \"Leather office chair black\"\n",
    "    ],\n",
    "    \"category\": [\n",
    "        \"electronics\",\n",
    "        \"electronics\",\n",
    "        \"clothing\",\n",
    "        \"electronics\",\n",
    "        \"kitchen\",\n",
    "        \"furniture\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Кодируем целевые метки\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(df[\"category\"])\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Разделяем на train и test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"description\"], y_categorical, test_size=0.3, random_state=42)\n",
    "\n",
    "# Токенизация текстов\n",
    "tokenizer = Tokenizer(num_words=1000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Приведение последовательностей к одной длине\n",
    "max_len = 20\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
    "\n",
    "# Построение модели нейросети\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=1000, output_dim=64, input_length=max_len),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(X_train_pad, y_train, epochs=20, batch_size=4, verbose=1)\n",
    "\n",
    "# Оценка модели\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Пример предсказания\n",
    "texts = [\"New wireless mouse\", \"Blue denim jacket\"]\n",
    "seqs = tokenizer.texts_to_sequences(texts)\n",
    "pads = pad_sequences(seqs, maxlen=max_len, padding='post')\n",
    "preds = model.predict(pads)\n",
    "pred_labels = label_encoder.inverse_transform(preds.argmax(axis=1))\n",
    "for text, label in zip(texts, pred_labels):\n",
    "    print(f\"'{text}' → predicted category: {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Работающий простой пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE  # Для балансировки классов\n",
    "from imblearn.over_sampling import RandomOverSampler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('tmc.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель: Logistic Regression | Точность: 0.880\n",
      "                                           precision    recall  f1-score   support\n",
      "\n",
      "                                 Абразивы       1.00      0.80      0.89         5\n",
      "                    Адаптеры компьютерные       0.56      1.00      0.71         5\n",
      "                                  Антенны       1.00      1.00      1.00         9\n",
      "           Аппараты телефонные (телефоны)       1.00      1.00      1.00        34\n",
      "                 Арматура светосигнальная       1.00      1.00      1.00        18\n",
      "                        Бани лабораторные       1.00      1.00      1.00        10\n",
      "                                    Бетон       0.00      0.00      0.00         8\n",
      "                                   Бидоны       1.00      1.00      1.00        15\n",
      "                          Блоки системные       0.83      1.00      0.91         5\n",
      "                 Ведра для нефтепродуктов       0.62      1.00      0.77         5\n",
      "     Вентиляторы приборные (компьютерные)       1.00      1.00      1.00        24\n",
      "           Вещества поверхностно-активные       1.00      1.00      1.00         2\n",
      "                               Видеокарты       1.00      1.00      1.00         4\n",
      "                             Вискозиметры       1.00      0.95      0.98        22\n",
      "               Втулки переходные конусные       0.83      1.00      0.91         5\n",
      "               Выключатели автоматические       1.00      0.99      1.00       127\n",
      "          Выключатели электроустановочные       1.00      1.00      1.00        22\n",
      "                  Вышки и мачты мобильные       0.07      0.20      0.11         5\n",
      "                 Горелки теплотехнические       1.00      1.00      1.00        13\n",
      "                    Датчики виброскорости       0.50      0.60      0.55         5\n",
      " Дет. телеф., радио-, звук-, видеотехники       0.14      0.05      0.07        40\n",
      "                         Диски (CD и DVD)       1.00      1.00      1.00         3\n",
      " Диски жесткие (накопители твердотельные)       1.00      1.00      1.00        14\n",
      "                             Дистилляторы       1.00      0.83      0.91         6\n",
      "                    Документы нормативные       1.00      1.00      1.00         8\n",
      "                                 Домкраты       1.00      1.00      1.00         7\n",
      "              Жилеты дем. сигнал. 2 класс       1.00      1.00      1.00        14\n",
      "  Запчасти и комплектующие средств защиты       1.00      0.39      0.56        18\n",
      "                                    Знаки       0.97      1.00      0.98        60\n",
      "Изделия деревянные плотничные и столярные       0.01      1.00      0.01         1\n",
      " Изделия для прокладки кабелей и проводов       0.98      0.87      0.92       284\n",
      "         Изделия и детали изготавливаемые       0.99      0.94      0.96       829\n",
      " Измерители концентрац. и хим состава в-в       0.81      0.55      0.65        31\n",
      "                    Индикаторы химические       1.00      0.96      0.98        28\n",
      "  Источники питан., аккум-ры (кр.автом-х)       0.88      0.88      0.88         8\n",
      "                    Кабели силовые прочие       1.00      1.00      1.00       189\n",
      "                Катализаторы отработанные       1.00      0.79      0.88        14\n",
      "                               Клавиатуры       0.91      1.00      0.95        10\n",
      "                       Клапаны скважинные       0.69      1.00      0.82         9\n",
      "        Ключи буровые, трубные, штанговые       0.67      0.75      0.71         8\n",
      "     Колеры, краски, грунтовки и покрытия       0.98      0.96      0.97        49\n",
      "  Колпачки, протекторы, заглушки защитные       0.41      0.78      0.54         9\n",
      "                  Кольца общепромышленные       1.00      1.00      1.00         1\n",
      "     Компл. приб., датч., изм. инстр. пр.       0.45      0.50      0.47        28\n",
      " Комплектующие лабораторного оборудования       0.84      0.77      0.80       236\n",
      "         Комплектующие машин слива/налива       0.14      0.54      0.22        13\n",
      "            Комплекты (клавиатуры и мышь)       1.00      1.00      1.00         6\n",
      "             Кондиционеры и сплит-системы       1.00      0.99      0.99        89\n",
      "                           Контейнеры IBC       0.30      0.75      0.43         4\n",
      "                  Костюмы лет муж ЛМ03-01       1.00      1.00      1.00       104\n",
      "              Костюмы противоэнцефалитные       1.00      1.00      1.00        51\n",
      "      Крышки к канистрам однокомпонентные       1.00      1.00      1.00        15\n",
      "  Материалы гидроиз. ленточные и рулонные       0.37      1.00      0.54         7\n",
      "        Материалы прокладочные графитовые       1.00      1.00      1.00         9\n",
      "        Машины слива и налива цистерн ж/д       0.40      0.86      0.55         7\n",
      "     Мебель лабораторная и вытяжные шкафы       1.00      0.97      0.98        65\n",
      "                     Мешалки лабораторные       0.50      0.10      0.17        10\n",
      "                Модули оперативной памяти       1.00      1.00      1.00        12\n",
      "                          Мотор-редукторы       0.00      0.00      0.00         3\n",
      "                      Набивки сальниковые       1.00      1.00      1.00        66\n",
      "  Ножи, лески триммерные, общетехнические       0.63      0.65      0.64        26\n",
      "                                 Ноутбуки       1.00      0.88      0.93         8\n",
      "     Оборуд. диспетчер. и оператор. связи       0.90      0.60      0.72        15\n",
      "     Оборуд., машины, уст-ва смесительные       0.00      0.00      0.00         7\n",
      "                      Образцы стандартные       1.00      1.00      1.00       276\n",
      "                                Огнеупоры       1.00      1.00      1.00         2\n",
      "                         Одежда форменная       1.00      1.00      1.00         5\n",
      "      Печи и шкафы сушильные лабораторные       0.43      0.55      0.48        11\n",
      "            Пистолеты (ручной инструмент)       1.00      1.00      1.00        18\n",
      "                      Пластики однородные       1.00      1.00      1.00        23\n",
      "                      Плитки строительные       1.00      1.00      1.00        10\n",
      "              Подстанции трансформаторные       1.00      1.00      1.00        40\n",
      "             Полимеры поликонденсационные       0.00      0.00      0.00         5\n",
      " Полумаски фильтр для защиты от аэрозолей       1.00      0.33      0.50        12\n",
      "  Посуда лабораторная немерная фарфоровая       1.00      1.00      1.00        19\n",
      "                 Преобразователи ржавчины       0.33      0.29      0.31         7\n",
      "                 Преобразователи сигналов       0.81      0.67      0.73        33\n",
      "                         Приводы CD и DVD       0.33      0.14      0.20         7\n",
      "                              Противогазы       0.80      0.44      0.57         9\n",
      "                       Процессоры для АРМ       1.00      1.00      1.00         3\n",
      "               Пульты и панели управления       0.76      1.00      0.86        16\n",
      "     Пульты управления (панели оператора)       0.76      0.80      0.78        20\n",
      "                             Радиостанции       0.89      0.57      0.70        14\n",
      "           Радиоустройства (кроме антенн)       0.00      0.00      0.00         5\n",
      "                                Развертки       1.00      1.00      1.00        13\n",
      " Раств-ли и ср-ва д чист. марк-го оборуд.       0.00      0.00      0.00         0\n",
      "               Растворители и разбавители       0.25      0.20      0.22         5\n",
      "    Реактивы гот. спец., наборы реактивов       0.92      0.74      0.82        46\n",
      "         Резцы токарные (кроме резьбовых)       1.00      1.00      1.00        51\n",
      "                          Ремни приводные       0.99      0.99      0.99       353\n",
      "                            Самоспасатели       0.32      0.86      0.46         7\n",
      "                Серверы и рабочие станции       1.00      0.57      0.73         7\n",
      "                                Смартфоны       1.00      1.00      1.00         5\n",
      "            Смеси и растворы строительные       0.00      0.00      0.00        10\n",
      "  Сооружения назн. энерг. инфрастр. стац.       0.33      0.50      0.40         4\n",
      "           Средства защиты информационные       0.63      0.59      0.61        29\n",
      " Средства моющие, чист., дезинф., промыш.       1.00      0.59      0.74        17\n",
      " Станки и машины пильные, распил., отрез.       0.00      0.00      0.00         3\n",
      "     Станки ме-обр. заточные шлифовальные       0.61      1.00      0.76        11\n",
      "  Станки ме-обр. сверлил. расточн. резьб.       0.00      0.00      0.00         7\n",
      "      Станции (системы) связи оперативной       0.33      0.33      0.33         9\n",
      "                       Станции управления       0.95      0.95      0.95        19\n",
      "                   Стикеры  самоклеящиеся       1.00      0.73      0.84        11\n",
      "             Таблички, вывески и наклейки       0.97      0.74      0.84        39\n",
      " Тара д. материалов жидких, вязких прочая       0.17      0.14      0.15         7\n",
      "  Тара специальная для оборудования и ЗиП       0.15      1.00      0.26         4\n",
      "    Уголь активированный для очистки воды       0.75      1.00      0.86         3\n",
      "                Узлы сетей и систем связи       0.47      0.15      0.22        55\n",
      "      Узлы, уст-ва полиграф. оборудования       0.25      1.00      0.40         4\n",
      "     Уст-ва управл. и защиты эл/установок       1.00      0.75      0.86         4\n",
      "     Уст-ки заправ., раздаточные, ЗИП пр.       0.09      0.50      0.15         2\n",
      "       Устройства и оснастка лабораторные       0.38      0.35      0.36        26\n",
      "              Устройства контроля доступа       0.00      0.00      0.00        10\n",
      "  Устройства предоставления информ. (УПИ)       0.57      0.62      0.59        13\n",
      "                        Факсы (телефаксы)       0.80      0.89      0.84         9\n",
      " Фильтроэлементы, картриджи, кассеты смен       0.80      0.47      0.59        17\n",
      "  Фильтры д/очистки жидк. и газообр. сред       0.95      0.98      0.96       123\n",
      "                          Флеш-накопители       1.00      1.00      1.00        24\n",
      "                                  Цементы       0.50      1.00      0.67         3\n",
      "     Цепи приводные роликовые и втулочные       0.80      1.00      0.89         4\n",
      " Части и комплектующие распределит. уст-в       0.33      0.33      0.33         6\n",
      "   Части, дет. двигат., прив.,мех. прочие       0.89      0.62      0.73       154\n",
      " Части, компл-щие генераторов электромаш.       0.71      1.00      0.83        15\n",
      "                          Щебень и гравий       0.75      1.00      0.86         3\n",
      "  Щетки д/зачистных, шлиф. и полир. машин       1.00      1.00      1.00         8\n",
      "  Эл/агрегаты и эл/станции с дизельн. ДВС       0.17      0.10      0.12        10\n",
      "  Электродвигатели асинхронные общ. назн.       1.00      1.00      1.00       152\n",
      "                     Этикетки вплавляемые       1.00      1.00      1.00       162\n",
      "                   Этикетки самоклеящиеся       1.00      1.00      1.00       327\n",
      "\n",
      "                                 accuracy                           0.88      5090\n",
      "                                macro avg       0.72      0.75      0.71      5090\n",
      "                             weighted avg       0.92      0.88      0.89      5090\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель: Random Forest | Точность: 0.899\n",
      "                                           precision    recall  f1-score   support\n",
      "\n",
      "                                 Абразивы       0.50      0.40      0.44         5\n",
      "                    Адаптеры компьютерные       0.83      1.00      0.91         5\n",
      "                                  Антенны       1.00      1.00      1.00         9\n",
      "           Аппараты телефонные (телефоны)       1.00      1.00      1.00        34\n",
      "                 Арматура светосигнальная       0.95      1.00      0.97        18\n",
      "                        Бани лабораторные       1.00      1.00      1.00        10\n",
      "                                    Бетон       0.00      0.00      0.00         8\n",
      "                                   Бидоны       1.00      1.00      1.00        15\n",
      "                          Блоки системные       0.83      1.00      0.91         5\n",
      "                 Ведра для нефтепродуктов       0.62      1.00      0.77         5\n",
      "     Вентиляторы приборные (компьютерные)       1.00      1.00      1.00        24\n",
      "           Вещества поверхностно-активные       0.50      0.50      0.50         2\n",
      "                               Видеокарты       1.00      1.00      1.00         4\n",
      "                             Вискозиметры       1.00      1.00      1.00        22\n",
      "               Втулки переходные конусные       1.00      1.00      1.00         5\n",
      "               Выключатели автоматические       1.00      1.00      1.00       127\n",
      "          Выключатели электроустановочные       1.00      1.00      1.00        22\n",
      "                  Вышки и мачты мобильные       0.00      0.00      0.00         5\n",
      "                 Горелки теплотехнические       1.00      1.00      1.00        13\n",
      "                    Датчики виброскорости       0.43      0.60      0.50         5\n",
      " Дет. телеф., радио-, звук-, видеотехники       0.27      0.10      0.15        40\n",
      "                         Диски (CD и DVD)       1.00      1.00      1.00         3\n",
      " Диски жесткие (накопители твердотельные)       0.93      1.00      0.97        14\n",
      "                             Дистилляторы       1.00      0.83      0.91         6\n",
      "                    Документы нормативные       1.00      1.00      1.00         8\n",
      "                                 Домкраты       1.00      1.00      1.00         7\n",
      "              Жилеты дем. сигнал. 2 класс       1.00      1.00      1.00        14\n",
      "  Запчасти и комплектующие средств защиты       0.88      0.39      0.54        18\n",
      "                                    Знаки       0.97      0.97      0.97        60\n",
      "Изделия деревянные плотничные и столярные       0.01      1.00      0.01         1\n",
      " Изделия для прокладки кабелей и проводов       1.00      0.90      0.95       284\n",
      "         Изделия и детали изготавливаемые       0.99      1.00      0.99       829\n",
      " Измерители концентрац. и хим состава в-в       0.73      0.61      0.67        31\n",
      "                    Индикаторы химические       1.00      0.96      0.98        28\n",
      "  Источники питан., аккум-ры (кр.автом-х)       0.88      0.88      0.88         8\n",
      "                    Кабели силовые прочие       1.00      1.00      1.00       189\n",
      "                Катализаторы отработанные       1.00      0.57      0.73        14\n",
      "                               Клавиатуры       0.83      1.00      0.91        10\n",
      "                       Клапаны скважинные       0.82      1.00      0.90         9\n",
      "        Ключи буровые, трубные, штанговые       0.78      0.88      0.82         8\n",
      "     Колеры, краски, грунтовки и покрытия       0.90      0.96      0.93        49\n",
      "  Колпачки, протекторы, заглушки защитные       1.00      0.78      0.88         9\n",
      "                  Кольца общепромышленные       1.00      1.00      1.00         1\n",
      "     Компл. приб., датч., изм. инстр. пр.       0.61      0.68      0.64        28\n",
      " Комплектующие лабораторного оборудования       0.83      0.85      0.84       236\n",
      "         Комплектующие машин слива/налива       1.00      0.46      0.63        13\n",
      "            Комплекты (клавиатуры и мышь)       1.00      0.83      0.91         6\n",
      "             Кондиционеры и сплит-системы       1.00      1.00      1.00        89\n",
      "                           Контейнеры IBC       0.75      0.75      0.75         4\n",
      "                  Костюмы лет муж ЛМ03-01       1.00      1.00      1.00       104\n",
      "              Костюмы противоэнцефалитные       1.00      1.00      1.00        51\n",
      "      Крышки к канистрам однокомпонентные       1.00      1.00      1.00        15\n",
      "  Материалы гидроиз. ленточные и рулонные       0.39      1.00      0.56         7\n",
      "        Материалы прокладочные графитовые       1.00      1.00      1.00         9\n",
      "        Машины слива и налива цистерн ж/д       0.75      0.43      0.55         7\n",
      "     Мебель лабораторная и вытяжные шкафы       1.00      1.00      1.00        65\n",
      "                     Мешалки лабораторные       0.50      0.10      0.17        10\n",
      "                Модули оперативной памяти       1.00      1.00      1.00        12\n",
      "                          Мотор-редукторы       0.00      0.00      0.00         3\n",
      "                      Набивки сальниковые       1.00      1.00      1.00        66\n",
      "  Ножи, лески триммерные, общетехнические       0.62      0.69      0.65        26\n",
      "                                 Ноутбуки       1.00      0.88      0.93         8\n",
      "     Оборуд. диспетчер. и оператор. связи       0.78      0.47      0.58        15\n",
      "     Оборуд., машины, уст-ва смесительные       0.00      0.00      0.00         7\n",
      "                      Образцы стандартные       1.00      1.00      1.00       276\n",
      "                                Огнеупоры       0.67      1.00      0.80         2\n",
      "                         Одежда форменная       1.00      1.00      1.00         5\n",
      "      Печи и шкафы сушильные лабораторные       0.67      0.55      0.60        11\n",
      "            Пистолеты (ручной инструмент)       1.00      1.00      1.00        18\n",
      "                      Пластики однородные       1.00      1.00      1.00        23\n",
      "                      Плитки строительные       1.00      1.00      1.00        10\n",
      "              Подстанции трансформаторные       1.00      1.00      1.00        40\n",
      "             Полимеры поликонденсационные       0.00      0.00      0.00         5\n",
      " Полумаски фильтр для защиты от аэрозолей       1.00      0.33      0.50        12\n",
      "  Посуда лабораторная немерная фарфоровая       1.00      1.00      1.00        19\n",
      "                 Преобразователи ржавчины       0.67      0.29      0.40         7\n",
      "                 Преобразователи сигналов       0.82      0.70      0.75        33\n",
      "                         Приводы CD и DVD       0.50      0.14      0.22         7\n",
      "                              Противогазы       0.80      0.44      0.57         9\n",
      "                       Процессоры для АРМ       1.00      1.00      1.00         3\n",
      "               Пульты и панели управления       0.88      0.94      0.91        16\n",
      "     Пульты управления (панели оператора)       0.73      0.80      0.76        20\n",
      "                             Радиостанции       0.92      0.86      0.89        14\n",
      "           Радиоустройства (кроме антенн)       0.00      0.00      0.00         5\n",
      "                                Развертки       1.00      1.00      1.00        13\n",
      " Раств-ли и ср-ва д чист. марк-го оборуд.       0.00      0.00      0.00         0\n",
      "               Растворители и разбавители       0.25      0.20      0.22         5\n",
      "    Реактивы гот. спец., наборы реактивов       0.97      0.85      0.91        46\n",
      "         Резцы токарные (кроме резьбовых)       1.00      1.00      1.00        51\n",
      "                          Ремни приводные       0.99      1.00      1.00       353\n",
      "                            Самоспасатели       0.32      0.86      0.46         7\n",
      "                Серверы и рабочие станции       1.00      0.57      0.73         7\n",
      "                                Смартфоны       1.00      1.00      1.00         5\n",
      "            Смеси и растворы строительные       0.00      0.00      0.00        10\n",
      "  Сооружения назн. энерг. инфрастр. стац.       0.38      0.75      0.50         4\n",
      "           Средства защиты информационные       0.59      0.45      0.51        29\n",
      " Средства моющие, чист., дезинф., промыш.       0.50      0.71      0.59        17\n",
      " Станки и машины пильные, распил., отрез.       0.00      0.00      0.00         3\n",
      "     Станки ме-обр. заточные шлифовальные       0.67      0.73      0.70        11\n",
      "  Станки ме-обр. сверлил. расточн. резьб.       0.44      0.57      0.50         7\n",
      "      Станции (системы) связи оперативной       0.75      0.33      0.46         9\n",
      "                       Станции управления       0.95      0.95      0.95        19\n",
      "                   Стикеры  самоклеящиеся       1.00      0.82      0.90        11\n",
      "             Таблички, вывески и наклейки       0.85      0.74      0.79        39\n",
      " Тара д. материалов жидких, вязких прочая       0.20      0.14      0.17         7\n",
      "  Тара специальная для оборудования и ЗиП       0.15      1.00      0.26         4\n",
      "    Уголь активированный для очистки воды       0.00      0.00      0.00         3\n",
      "                Узлы сетей и систем связи       0.48      0.29      0.36        55\n",
      "      Узлы, уст-ва полиграф. оборудования       0.29      1.00      0.44         4\n",
      "     Уст-ва управл. и защиты эл/установок       1.00      0.75      0.86         4\n",
      "     Уст-ки заправ., раздаточные, ЗИП пр.       0.25      0.50      0.33         2\n",
      "       Устройства и оснастка лабораторные       0.53      0.31      0.39        26\n",
      "              Устройства контроля доступа       0.00      0.00      0.00        10\n",
      "  Устройства предоставления информ. (УПИ)       0.60      0.46      0.52        13\n",
      "                        Факсы (телефаксы)       0.80      0.89      0.84         9\n",
      " Фильтроэлементы, картриджи, кассеты смен       0.75      0.53      0.62        17\n",
      "  Фильтры д/очистки жидк. и газообр. сред       0.95      0.99      0.97       123\n",
      "                          Флеш-накопители       1.00      1.00      1.00        24\n",
      "                                  Цементы       1.00      1.00      1.00         3\n",
      "     Цепи приводные роликовые и втулочные       1.00      1.00      1.00         4\n",
      " Части и комплектующие распределит. уст-в       1.00      0.17      0.29         6\n",
      "   Части, дет. двигат., прив.,мех. прочие       0.89      0.66      0.76       154\n",
      " Части, компл-щие генераторов электромаш.       0.67      0.93      0.78        15\n",
      "                          Щебень и гравий       0.60      1.00      0.75         3\n",
      "  Щетки д/зачистных, шлиф. и полир. машин       1.00      1.00      1.00         8\n",
      "  Эл/агрегаты и эл/станции с дизельн. ДВС       0.50      0.10      0.17        10\n",
      "  Электродвигатели асинхронные общ. назн.       1.00      1.00      1.00       152\n",
      "                     Этикетки вплавляемые       1.00      1.00      1.00       162\n",
      "                   Этикетки самоклеящиеся       1.00      1.00      1.00       327\n",
      "\n",
      "                                 accuracy                           0.90      5090\n",
      "                                macro avg       0.75      0.73      0.72      5090\n",
      "                             weighted avg       0.92      0.90      0.91      5090\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель: Linear SVM | Точность: 0.885\n",
      "                                           precision    recall  f1-score   support\n",
      "\n",
      "                                 Абразивы       0.80      0.80      0.80         5\n",
      "                    Адаптеры компьютерные       0.62      1.00      0.77         5\n",
      "                                  Антенны       1.00      1.00      1.00         9\n",
      "           Аппараты телефонные (телефоны)       1.00      1.00      1.00        34\n",
      "                 Арматура светосигнальная       1.00      0.94      0.97        18\n",
      "                        Бани лабораторные       1.00      1.00      1.00        10\n",
      "                                    Бетон       0.00      0.00      0.00         8\n",
      "                                   Бидоны       1.00      1.00      1.00        15\n",
      "                          Блоки системные       0.83      1.00      0.91         5\n",
      "                 Ведра для нефтепродуктов       0.62      1.00      0.77         5\n",
      "     Вентиляторы приборные (компьютерные)       1.00      0.96      0.98        24\n",
      "           Вещества поверхностно-активные       1.00      0.50      0.67         2\n",
      "                               Видеокарты       0.67      1.00      0.80         4\n",
      "                             Вискозиметры       1.00      0.95      0.98        22\n",
      "               Втулки переходные конусные       0.83      1.00      0.91         5\n",
      "               Выключатели автоматические       0.99      1.00      1.00       127\n",
      "          Выключатели электроустановочные       0.96      1.00      0.98        22\n",
      "                  Вышки и мачты мобильные       0.10      0.20      0.13         5\n",
      "                 Горелки теплотехнические       1.00      1.00      1.00        13\n",
      "                    Датчики виброскорости       0.60      0.60      0.60         5\n",
      " Дет. телеф., радио-, звук-, видеотехники       0.19      0.07      0.11        40\n",
      "                         Диски (CD и DVD)       1.00      1.00      1.00         3\n",
      " Диски жесткие (накопители твердотельные)       0.93      1.00      0.97        14\n",
      "                             Дистилляторы       1.00      0.83      0.91         6\n",
      "                    Документы нормативные       1.00      1.00      1.00         8\n",
      "                                 Домкраты       1.00      1.00      1.00         7\n",
      "              Жилеты дем. сигнал. 2 класс       1.00      1.00      1.00        14\n",
      "  Запчасти и комплектующие средств защиты       0.62      0.44      0.52        18\n",
      "                                    Знаки       0.97      1.00      0.98        60\n",
      "Изделия деревянные плотничные и столярные       0.01      1.00      0.01         1\n",
      " Изделия для прокладки кабелей и проводов       0.99      0.87      0.93       284\n",
      "         Изделия и детали изготавливаемые       0.99      0.97      0.98       829\n",
      " Измерители концентрац. и хим состава в-в       0.76      0.61      0.68        31\n",
      "                    Индикаторы химические       0.96      0.93      0.95        28\n",
      "  Источники питан., аккум-ры (кр.автом-х)       0.88      0.88      0.88         8\n",
      "                    Кабели силовые прочие       0.99      1.00      1.00       189\n",
      "                Катализаторы отработанные       1.00      0.79      0.88        14\n",
      "                               Клавиатуры       0.91      1.00      0.95        10\n",
      "                       Клапаны скважинные       0.73      0.89      0.80         9\n",
      "        Ключи буровые, трубные, штанговые       0.67      0.75      0.71         8\n",
      "     Колеры, краски, грунтовки и покрытия       0.96      0.96      0.96        49\n",
      "  Колпачки, протекторы, заглушки защитные       0.70      0.78      0.74         9\n",
      "                  Кольца общепромышленные       1.00      1.00      1.00         1\n",
      "     Компл. приб., датч., изм. инстр. пр.       0.43      0.57      0.49        28\n",
      " Комплектующие лабораторного оборудования       0.84      0.78      0.81       236\n",
      "         Комплектующие машин слива/налива       0.22      0.46      0.30        13\n",
      "            Комплекты (клавиатуры и мышь)       1.00      1.00      1.00         6\n",
      "             Кондиционеры и сплит-системы       1.00      0.99      0.99        89\n",
      "                           Контейнеры IBC       0.60      0.75      0.67         4\n",
      "                  Костюмы лет муж ЛМ03-01       1.00      1.00      1.00       104\n",
      "              Костюмы противоэнцефалитные       1.00      1.00      1.00        51\n",
      "      Крышки к канистрам однокомпонентные       1.00      1.00      1.00        15\n",
      "  Материалы гидроиз. ленточные и рулонные       0.33      1.00      0.50         7\n",
      "        Материалы прокладочные графитовые       1.00      1.00      1.00         9\n",
      "        Машины слива и налива цистерн ж/д       0.45      0.71      0.56         7\n",
      "     Мебель лабораторная и вытяжные шкафы       1.00      1.00      1.00        65\n",
      "                     Мешалки лабораторные       0.20      0.10      0.13        10\n",
      "                Модули оперативной памяти       1.00      1.00      1.00        12\n",
      "                          Мотор-редукторы       0.00      0.00      0.00         3\n",
      "                      Набивки сальниковые       1.00      1.00      1.00        66\n",
      "  Ножи, лески триммерные, общетехнические       0.77      0.65      0.71        26\n",
      "                                 Ноутбуки       1.00      0.88      0.93         8\n",
      "     Оборуд. диспетчер. и оператор. связи       0.56      0.60      0.58        15\n",
      "     Оборуд., машины, уст-ва смесительные       0.00      0.00      0.00         7\n",
      "                      Образцы стандартные       1.00      1.00      1.00       276\n",
      "                                Огнеупоры       0.67      1.00      0.80         2\n",
      "                         Одежда форменная       1.00      1.00      1.00         5\n",
      "      Печи и шкафы сушильные лабораторные       0.50      0.55      0.52        11\n",
      "            Пистолеты (ручной инструмент)       1.00      0.94      0.97        18\n",
      "                      Пластики однородные       1.00      1.00      1.00        23\n",
      "                      Плитки строительные       1.00      1.00      1.00        10\n",
      "              Подстанции трансформаторные       0.98      1.00      0.99        40\n",
      "             Полимеры поликонденсационные       0.00      0.00      0.00         5\n",
      " Полумаски фильтр для защиты от аэрозолей       1.00      0.33      0.50        12\n",
      "  Посуда лабораторная немерная фарфоровая       0.95      1.00      0.97        19\n",
      "                 Преобразователи ржавчины       0.50      0.29      0.36         7\n",
      "                 Преобразователи сигналов       0.77      0.70      0.73        33\n",
      "                         Приводы CD и DVD       0.33      0.14      0.20         7\n",
      "                              Противогазы       0.67      0.44      0.53         9\n",
      "                       Процессоры для АРМ       0.75      1.00      0.86         3\n",
      "               Пульты и панели управления       0.82      0.88      0.85        16\n",
      "     Пульты управления (панели оператора)       0.71      0.75      0.73        20\n",
      "                             Радиостанции       0.80      0.57      0.67        14\n",
      "           Радиоустройства (кроме антенн)       0.09      0.20      0.12         5\n",
      "                                Развертки       1.00      1.00      1.00        13\n",
      " Раств-ли и ср-ва д чист. марк-го оборуд.       0.00      0.00      0.00         0\n",
      "               Растворители и разбавители       0.20      0.20      0.20         5\n",
      "    Реактивы гот. спец., наборы реактивов       0.86      0.78      0.82        46\n",
      "         Резцы токарные (кроме резьбовых)       0.98      1.00      0.99        51\n",
      "                          Ремни приводные       0.99      0.97      0.98       353\n",
      "                            Самоспасатели       0.32      0.86      0.46         7\n",
      "                Серверы и рабочие станции       1.00      0.43      0.60         7\n",
      "                                Смартфоны       1.00      1.00      1.00         5\n",
      "            Смеси и растворы строительные       0.00      0.00      0.00        10\n",
      "  Сооружения назн. энерг. инфрастр. стац.       0.14      0.25      0.18         4\n",
      "           Средства защиты информационные       0.64      0.62      0.63        29\n",
      " Средства моющие, чист., дезинф., промыш.       1.00      0.59      0.74        17\n",
      " Станки и машины пильные, распил., отрез.       0.00      0.00      0.00         3\n",
      "     Станки ме-обр. заточные шлифовальные       0.43      0.55      0.48        11\n",
      "  Станки ме-обр. сверлил. расточн. резьб.       0.30      0.43      0.35         7\n",
      "      Станции (системы) связи оперативной       0.29      0.22      0.25         9\n",
      "                       Станции управления       0.95      0.95      0.95        19\n",
      "                   Стикеры  самоклеящиеся       1.00      0.82      0.90        11\n",
      "             Таблички, вывески и наклейки       0.97      0.74      0.84        39\n",
      " Тара д. материалов жидких, вязких прочая       0.12      0.14      0.13         7\n",
      "  Тара специальная для оборудования и ЗиП       0.15      1.00      0.26         4\n",
      "    Уголь активированный для очистки воды       0.75      1.00      0.86         3\n",
      "                Узлы сетей и систем связи       0.50      0.24      0.32        55\n",
      "      Узлы, уст-ва полиграф. оборудования       0.29      1.00      0.44         4\n",
      "     Уст-ва управл. и защиты эл/установок       1.00      0.75      0.86         4\n",
      "     Уст-ки заправ., раздаточные, ЗИП пр.       0.12      0.50      0.20         2\n",
      "       Устройства и оснастка лабораторные       0.67      0.31      0.42        26\n",
      "              Устройства контроля доступа       0.25      0.10      0.14        10\n",
      "  Устройства предоставления информ. (УПИ)       0.62      0.38      0.48        13\n",
      "                        Факсы (телефаксы)       0.80      0.89      0.84         9\n",
      " Фильтроэлементы, картриджи, кассеты смен       0.80      0.47      0.59        17\n",
      "  Фильтры д/очистки жидк. и газообр. сред       0.96      0.98      0.97       123\n",
      "                          Флеш-накопители       1.00      1.00      1.00        24\n",
      "                                  Цементы       0.50      1.00      0.67         3\n",
      "     Цепи приводные роликовые и втулочные       0.80      1.00      0.89         4\n",
      " Части и комплектующие распределит. уст-в       0.25      0.33      0.29         6\n",
      "   Части, дет. двигат., прив.,мех. прочие       0.90      0.62      0.73       154\n",
      " Части, компл-щие генераторов электромаш.       0.62      1.00      0.77        15\n",
      "                          Щебень и гравий       0.60      1.00      0.75         3\n",
      "  Щетки д/зачистных, шлиф. и полир. машин       1.00      1.00      1.00         8\n",
      "  Эл/агрегаты и эл/станции с дизельн. ДВС       0.00      0.00      0.00        10\n",
      "  Электродвигатели асинхронные общ. назн.       1.00      1.00      1.00       152\n",
      "                     Этикетки вплавляемые       1.00      1.00      1.00       162\n",
      "                   Этикетки самоклеящиеся       0.99      1.00      1.00       327\n",
      "\n",
      "                                 accuracy                           0.88      5090\n",
      "                                macro avg       0.71      0.74      0.70      5090\n",
      "                             weighted avg       0.91      0.88      0.89      5090\n",
      "\n",
      "Лучшая модель: Random Forest с точностью 0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Функция для обучения нескольких моделей и выбора лучшей с учетом дисбаланса\n",
    "def train_and_select_best_model(X_train, y_train, X_test, y_test):\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(multi_class=\"ovr\", max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "        \"Linear SVM\": LinearSVC(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "    }\n",
    "    \n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    best_model_name = \"\"\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Модель: {name} | Точность: {acc:.3f}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_model = model\n",
    "            best_model_name = name\n",
    "    \n",
    "    print(f\"Лучшая модель: {best_model_name} с точностью {best_accuracy:.3f}\")\n",
    "    return best_model\n",
    "\n",
    "\n",
    "\n",
    "# Пример данных\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X = df[\"description\"]\n",
    "y = df[\"category\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# Решение проблемы дисбаланса с помощью SMOTE\n",
    "smote = SMOTE(random_state=42, k_neighbors=3)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_vect, y_train)\n",
    "X_train_bal, y_train_bal = ros.fit_resample(X_train_vect, y_train)\n",
    "best_model = train_and_select_best_model(X_train_smote, y_train_smote, X_test_vect, y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_dataframe(df_to_classify, vectorizer, model):\n",
    "    if 'description' not in df_to_classify.columns:\n",
    "        raise ValueError(\"Входной датафрейм должен содержать колонку 'description'\")\n",
    "    \n",
    "    X_vect = vectorizer.transform(df_to_classify['description'])\n",
    "    preds = model.predict(X_vect)\n",
    "    \n",
    "    df_result = df_to_classify.copy()\n",
    "    df_result['predicted_category'] = preds\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Комплектующие лабораторного оборудования</td>\n",
       "      <td>Фильтры набор артикул 3426Z-47-SCM dell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Комплектующие лабораторного оборудования</td>\n",
       "      <td>Подшипник артикул ЯМЗ A280118T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Фильтроэлементы, картриджи, кассеты смен</td>\n",
       "      <td>Прокладка  YAMAHA 234595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Самоспасатели</td>\n",
       "      <td>Самоспасатель Т ТР ТС 019/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Противогазы</td>\n",
       "      <td>Противогаз пав-2-20 МАГ с шланг х/б ТР ТС 019/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Части, дет. двигат., прив.,мех. прочие</td>\n",
       "      <td>Кольцо графитное Dresser Random 503ELC  621088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Приводы CD и DVD</td>\n",
       "      <td>USB 3.0 32Gb SanDisk Ultra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Части, дет. двигат., прив.,мех. прочие</td>\n",
       "      <td>Прокладка артикул Waukesha 295017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Костюмы лет муж ЛМ03-01</td>\n",
       "      <td>летний мужской для защиты от ОПЗ ЛМ03-01 (курт...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         predicted_category  \\\n",
       "0  Комплектующие лабораторного оборудования   \n",
       "1  Комплектующие лабораторного оборудования   \n",
       "2  Фильтроэлементы, картриджи, кассеты смен   \n",
       "3                             Самоспасатели   \n",
       "4                               Противогазы   \n",
       "5    Части, дет. двигат., прив.,мех. прочие   \n",
       "6                          Приводы CD и DVD   \n",
       "7    Части, дет. двигат., прив.,мех. прочие   \n",
       "8                   Костюмы лет муж ЛМ03-01   \n",
       "\n",
       "                                         description  \n",
       "0            Фильтры набор артикул 3426Z-47-SCM dell  \n",
       "1                     Подшипник артикул ЯМЗ A280118T  \n",
       "2                           Прокладка  YAMAHA 234595  \n",
       "3                     Самоспасатель Т ТР ТС 019/2011  \n",
       "4  Противогаз пав-2-20 МАГ с шланг х/б ТР ТС 019/...  \n",
       "5     Кольцо графитное Dresser Random 503ELC  621088  \n",
       "6                         USB 3.0 32Gb SanDisk Ultra  \n",
       "7                  Прокладка артикул Waukesha 295017  \n",
       "8  летний мужской для защиты от ОПЗ ЛМ03-01 (курт...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример классифицируемых данных\n",
    "new_data = pd.read_excel('sample.xlsx')\n",
    "\n",
    "df_new = pd.DataFrame(new_data)\n",
    "df_classified = classify_dataframe(df_new, vectorizer, best_model)\n",
    "predicts = df_classified[['predicted_category']]\n",
    "predicts['description'] = new_data[['description']]\n",
    "predicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Пример с Grid Search и Кросс валидацией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ключевые улучшения:\n",
    "\n",
    "1. Grid Search CV - автоматический подбор гиперпараметров\n",
    "2. Кросс-валидация - более надежная оценка качества\n",
    "3. Дополнительные метрики - F1-score для дисбалансированных данных\n",
    "4. Новые модели - Gradient Boosting\n",
    "5. Ансамблевые методы - Voting и Stacking\n",
    "6. Улучшенная векторизация - стоп-слова, min_df/max_df\n",
    "7. Стратифицированное разделение - сохранение распределения классов\n",
    "8. Детальная отчетность - сравнение всех моделей\n",
    "\n",
    "Дальнейшие улучшения можно добавить:\n",
    "\n",
    "· Randomized Search CV (быстрее для больших пространств параметров)\n",
    "· Bayesian Optimization (оптимизация гиперпараметров)\n",
    "· Нейронные сети (через MLPClassifier)\n",
    "· Feature Engineering - дополнительные features\n",
    "· Кросс-валидацию по времени (если данные временные ряды)\n",
    "\n",
    "Выберите те улучшения, которые наиболее relevant для вашей конкретной задачи!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Улучшенная функция с Grid Search и дополнительными моделями\n",
    "def train_and_select_best_model_advanced(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Улучшенная функция с Grid Search, кросс-валидацией и дополнительными моделями\n",
    "    \"\"\"\n",
    "    \n",
    "    # Базовые модели с балансировкой классов\n",
    "    base_models = {\n",
    "        \"Logistic Regression\": LogisticRegression(multi_class=\"ovr\", max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "        \"Linear SVM\": LinearSVC(max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Параметры для Grid Search для каждой модели\n",
    "    param_grids = {\n",
    "        \"Logistic Regression\": {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'solver': ['liblinear', 'saga']\n",
    "        },\n",
    "        \"Random Forest\": {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [10, 20, None],\n",
    "            'min_samples_split': [2, 5]\n",
    "        },\n",
    "        \"Linear SVM\": {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'loss': ['hinge', 'squared_hinge']\n",
    "        },\n",
    "        \"Gradient Boosting\": {\n",
    "            'n_estimators': [100, 200],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'max_depth': [3, 5]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    best_model_name = \"\"\n",
    "    cv_results = {}\n",
    "    \n",
    "    print(\"=== РЕЗУЛЬТАТЫ ОБУЧЕНИЯ МОДЕЛЕЙ ===\\n\")\n",
    "    \n",
    "    for name, model in base_models.items():\n",
    "        print(f\"\\n--- Настройка модели: {name} ---\")\n",
    "        \n",
    "        # Кросс-валидация базовой модели\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        print(f\"Кросс-валидация (базовая): {cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")\n",
    "        \n",
    "        # Grid Search с кросс-валидацией\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grids.get(name, {}),\n",
    "            cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Обучение Grid Search\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Лучшая модель из Grid Search\n",
    "        best_grid_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Предсказание на тестовых данных\n",
    "        y_pred = best_grid_model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        print(f\"Лучшие параметры: {grid_search.best_params_}\")\n",
    "        print(f\"Точность на тесте: {acc:.3f}\")\n",
    "        print(f\"F1-score (weighted): {f1:.3f}\")\n",
    "        \n",
    "        # Сохраняем результаты\n",
    "        cv_results[name] = {\n",
    "            'model': best_grid_model,\n",
    "            'accuracy': acc,\n",
    "            'f1_score': f1,\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'cv_score': grid_search.best_score_\n",
    "        }\n",
    "        \n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_model = best_grid_model\n",
    "            best_model_name = name\n",
    "    \n",
    "    # Выводим сравнение моделей\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"СРАВНЕНИЕ МОДЕЛЕЙ:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for name, results in sorted(cv_results.items(), key=lambda x: x[1]['accuracy'], reverse=True):\n",
    "        print(f\"{name:<20} | Accuracy: {results['accuracy']:.3f} | F1: {results['f1_score']:.3f} | CV: {results['cv_score']:.3f}\")\n",
    "    \n",
    "    print(f\"\\n🚀 Лучшая модель: {best_model_name}\")\n",
    "    print(f\"📊 Точность: {best_accuracy:.3f}\")\n",
    "    print(f\"🎯 Параметры: {cv_results[best_model_name]['best_params']}\")\n",
    "    \n",
    "    return best_model, cv_results\n",
    "\n",
    "# Дополнительная функция для ансамблевых методов\n",
    "def train_ensemble_models(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Обучение ансамблевых моделей для сравнения\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    # Базовые модели для ансамбля\n",
    "    base_models = [\n",
    "        ('lr', LogisticRegression(multi_class=\"ovr\", max_iter=1000, random_state=42, class_weight='balanced')),\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')),\n",
    "        ('svm', LinearSVC(max_iter=1000, random_state=42, class_weight='balanced'))\n",
    "    ]\n",
    "    \n",
    "    # Voting Classifier\n",
    "    voting_clf = VotingClassifier(estimators=base_models, voting='hard')\n",
    "    voting_clf.fit(X_train, y_train)\n",
    "    voting_acc = accuracy_score(y_test, voting_clf.predict(X_test))\n",
    "    \n",
    "    # Stacking Classifier\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=base_models,\n",
    "        final_estimator=LogisticRegression(max_iter=1000, random_state=42),\n",
    "        cv=5\n",
    "    )\n",
    "    stacking_clf.fit(X_train, y_train)\n",
    "    stacking_acc = accuracy_score(y_test, stacking_clf.predict(X_test))\n",
    "    \n",
    "    print(f\"\\n--- АНСАМБЛЕВЫЕ МОДЕЛИ ---\")\n",
    "    print(f\"Voting Classifier Accuracy: {voting_acc:.3f}\")\n",
    "    print(f\"Stacking Classifier Accuracy: {stacking_acc:.3f}\")\n",
    "    \n",
    "    return voting_clf, stacking_clf\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры данных после балансировки:\n",
      "Обучающая выборка: (248583, 2000)\n",
      "Тестовая выборка: (5090, 2000)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Изделия для прокладки кабелей и проводов'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mОбучающая выборка: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train_bal.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mТестовая выборка: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test_vect.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mРаспределение классов: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbincount\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train_bal\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Обучение моделей с Grid Search\u001b[39;00m\n\u001b[32m     34\u001b[39m best_model, all_results = train_and_select_best_model_advanced(\n\u001b[32m     35\u001b[39m         X_train_bal, y_train_bal, X_test_vect, y_test\n\u001b[32m     36\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1033\u001b[39m, in \u001b[36mSeries.__array__\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   1030\u001b[39m values = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1032\u001b[39m     \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1033\u001b[39m     arr = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1035\u001b[39m     arr = np.array(values, dtype=dtype, copy=copy)\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: 'Изделия для прокладки кабелей и проводов'"
     ]
    }
   ],
   "source": [
    "\n",
    "    # Ваши данные\n",
    "df = pd.DataFrame(data)\n",
    "    \n",
    "X = df[\"description\"]\n",
    "y = df[\"category\"]\n",
    "    \n",
    "# Разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Векторизация текста\n",
    "vectorizer = TfidfVectorizer(\n",
    "        max_features=2000, \n",
    "        ngram_range=(1, 2),\n",
    "        stop_words='english',  # Удаление стоп-слов\n",
    "        min_df=2,             # Минимальная частота слова\n",
    "        max_df=0.8            # Максимальная частота слова\n",
    "    )\n",
    "    \n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Балансировка данных\n",
    "smote = SMOTE(random_state=42, k_neighbors=3)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train_vect, y_train)\n",
    "    \n",
    "print(\"Размеры данных после балансировки:\")\n",
    "print(f\"Обучающая выборка: {X_train_bal.shape}\")\n",
    "print(f\"Тестовая выборка: {X_test_vect.shape}\")\n",
    "print(f\"Распределение классов: {np.bincount(y_train_bal)}\")\n",
    "    \n",
    "# Обучение моделей с Grid Search\n",
    "best_model, all_results = train_and_select_best_model_advanced(\n",
    "        X_train_bal, y_train_bal, X_test_vect, y_test\n",
    "    )\n",
    "    \n",
    "    # Дополнительно: ансамблевые методы\n",
    "voting_model, stacking_model = train_ensemble_models(\n",
    "        X_train_bal, y_train_bal, X_test_vect, y_test\n",
    "    )\n",
    "    \n",
    "    # Сравнение всех подходов\n",
    "final_comparison = {\n",
    "        'Best Grid Search': all_results[list(all_results.keys())[0]]['accuracy'],\n",
    "        'Voting Ensemble': accuracy_score(y_test, voting_model.predict(X_test_vect)),\n",
    "        'Stacking Ensemble': accuracy_score(y_test, stacking_model.predict(X_test_vect))\n",
    "    }\n",
    "    \n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ФИНАЛЬНОЕ СРАВНЕНИЕ:\")\n",
    "print(\"=\"*50)\n",
    "for method, score in sorted(final_comparison.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{method:<20} | Accuracy: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Нейросеть 1 редакция"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ключевые улучшения:\n",
    "\n",
    "1. Расширенный Feature Engineering\n",
    "\n",
    "· Лингвистические признаки: длина текста, слова, предложения, сложность\n",
    "· Стилистические признаки: заглавные буквы, цифры, пунктуация\n",
    "· N-gram символы: биграммы и триграммы символов\n",
    "· Комбинированные подходы: TF-IDF + лингвистика + символьные n-gram\n",
    "\n",
    "2. MLPClassifier с настройкой\n",
    "\n",
    "· Архитектуры сетей: разные конфигурации скрытых слоев\n",
    "· Регуляризация: параметр alpha для предотвращения переобучения\n",
    "· Функции активации: ReLU и Tanh\n",
    "· Early Stopping: автоматическая остановка при переобучении\n",
    "\n",
    "3. Улучшенная обработка\n",
    "\n",
    "· FeatureUnion: комбинация разных типов признаков\n",
    "· StandardScaler: нормализация числовых признаков\n",
    "· Пайплайны: единая обработка для избежания утечки данных\n",
    "\n",
    "4. Анализ эффективности\n",
    "\n",
    "· Сравнение стратегий: тестирование разных подходов к Feature Engineering\n",
    "· Важность признаков: анализ наиболее значимых фич\n",
    "· Ансамблевые методы: комбинация моделей с улучшенными признаками\n",
    "\n",
    "Этот код значительно повысит качество модели за счет комплексного подхода к извлечению признаков и использования нейронных сетей!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline as make_imb_pipeline\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Кастомный трансформер для извлечения лингвистических features\n",
    "class TextFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(max_features=500, ngram_range=(1, 2))\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Обучаем TF-IDF на текстах\n",
    "        self.vectorizer.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        features = []\n",
    "        \n",
    "        for text in X:\n",
    "            # Базовые статистики текста\n",
    "            text_str = str(text)\n",
    "            num_chars = len(text_str)\n",
    "            num_words = len(text_str.split())\n",
    "            num_sentences = len(re.split(r'[.!?]+', text_str))\n",
    "            avg_word_length = num_chars / num_words if num_words > 0 else 0\n",
    "            avg_sentence_length = num_words / num_sentences if num_sentences > 0 else 0\n",
    "            \n",
    "            # Стилистические features\n",
    "            num_uppercase = sum(1 for char in text_str if char.isupper())\n",
    "            num_digits = sum(1 for char in text_str if char.isdigit())\n",
    "            num_punctuation = sum(1 for char in text_str if char in '.,!?;:')\n",
    "            \n",
    "            # Сложность текста\n",
    "            unique_words = len(set(text_str.lower().split()))\n",
    "            lexical_diversity = unique_words / num_words if num_words > 0 else 0\n",
    "            \n",
    "            features.append([\n",
    "                num_chars, num_words, num_sentences, avg_word_length,\n",
    "                avg_sentence_length, num_uppercase, num_digits,\n",
    "                num_punctuation, unique_words, lexical_diversity\n",
    "            ])\n",
    "        \n",
    "        return np.array(features)\n",
    "\n",
    "# Комплексный трансформер для текста\n",
    "class AdvancedTextTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, tfidf_max_features=2000, ngram_range=(1, 2)):\n",
    "        self.tfidf_max_features = tfidf_max_features\n",
    "        self.ngram_range = ngram_range\n",
    "        self.feature_union = FeatureUnion([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=tfidf_max_features,\n",
    "                ngram_range=ngram_range,\n",
    "                stop_words='english',\n",
    "                min_df=2,\n",
    "                max_df=0.8,\n",
    "                sublinear_tf=True\n",
    "            )),\n",
    "            ('linguistic_features', Pipeline([\n",
    "                ('extractor', TextFeatureExtractor()),\n",
    "                ('scaler', StandardScaler())\n",
    "            ])),\n",
    "            ('char_ngrams', CountVectorizer(\n",
    "                analyzer='char',\n",
    "                ngram_range=(2, 4),\n",
    "                max_features=1000\n",
    "            ))\n",
    "        ])\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_union.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.feature_union.transform(X)\n",
    "\n",
    "# Улучшенная функция с Feature Engineering и MLP\n",
    "def train_advanced_models_with_features(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Улучшенная функция с комплексным Feature Engineering и MLPClassifier\n",
    "    \"\"\"\n",
    "    \n",
    "    # Базовые конфигурации моделей\n",
    "    models_config = {\n",
    "        \"Logistic Regression\": {\n",
    "            'model': LogisticRegression(random_state=42, max_iter=1000),\n",
    "            'params': {\n",
    "                'classifier__C': [0.1, 1, 10],\n",
    "                'classifier__solver': ['liblinear', 'saga'],\n",
    "                'classifier__class_weight': ['balanced', None]\n",
    "            }\n",
    "        },\n",
    "        \"Random Forest\": {\n",
    "            'model': RandomForestClassifier(random_state=42),\n",
    "            'params': {\n",
    "                'classifier__n_estimators': [100, 200],\n",
    "                'classifier__max_depth': [10, 20, None],\n",
    "                'classifier__min_samples_split': [2, 5],\n",
    "                'classifier__class_weight': ['balanced', None]\n",
    "            }\n",
    "        },\n",
    "        \"Linear SVM\": {\n",
    "            'model': LinearSVC(random_state=42, max_iter=1000),\n",
    "            'params': {\n",
    "                'classifier__C': [0.1, 1, 10],\n",
    "                'classifier__loss': ['hinge', 'squared_hinge'],\n",
    "                'classifier__class_weight': ['balanced', None]\n",
    "            }\n",
    "        },\n",
    "        \"MLPClassifier\": {\n",
    "            'model': MLPClassifier(random_state=42, max_iter=1000, early_stopping=True),\n",
    "            'params': {\n",
    "                'classifier__hidden_layer_sizes': [(100,), (100, 50), (50, 25)],\n",
    "                'classifier__alpha': [0.0001, 0.001, 0.01],\n",
    "                'classifier__learning_rate_init': [0.001, 0.01],\n",
    "                'classifier__activation': ['relu', 'tanh']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    best_model_name = \"\"\n",
    "    all_results = {}\n",
    "    \n",
    "    print(\"=== КОМПЛЕКСНОЕ ОБУЧЕНИЕ МОДЕЛЕЙ С FEATURE ENGINEERING ===\\n\")\n",
    "    \n",
    "    for name, config in models_config.items():\n",
    "        print(f\"\\n--- Настройка модели: {name} ---\")\n",
    "        \n",
    "        # Создаем пайплайн с SMOTE и препроцессингом\n",
    "        pipeline = make_imb_pipeline(\n",
    "            AdvancedTextTransformer(),\n",
    "            SMOTE(random_state=42, k_neighbors=3),\n",
    "            config['model']\n",
    "        )\n",
    "        \n",
    "        # Параметры для GridSearch\n",
    "        param_grid = {\n",
    "            **config['params'],\n",
    "            'advancedtexttransformer__tfidf_max_features': [1000, 2000],\n",
    "            'advancedtexttransformer__ngram_range': [(1, 1), (1, 2)]\n",
    "        }\n",
    "        \n",
    "        # Grid Search с кросс-валидацией\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=param_grid,\n",
    "            cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),  # Уменьшил для скорости\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Обучение модели\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Предсказание и оценка\n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        print(f\"Лучшие параметры: {grid_search.best_params_}\")\n",
    "        print(f\"Точность на тесте: {acc:.3f}\")\n",
    "        print(f\"F1-score: {f1:.3f}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Сохраняем результаты\n",
    "        all_results[name] = {\n",
    "            'model': grid_search.best_estimator_,\n",
    "            'accuracy': acc,\n",
    "            'f1_score': f1,\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'cv_score': grid_search.best_score_\n",
    "        }\n",
    "        \n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_model = grid_search.best_estimator_\n",
    "            best_model_name = name\n",
    "    \n",
    "    # Сравнение моделей\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"СРАВНЕНИЕ МОДЕЛЕЙ:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for name, results in sorted(all_results.items(), key=lambda x: x[1]['accuracy'], reverse=True):\n",
    "        print(f\"{name:<20} | Accuracy: {results['accuracy']:.3f} | F1: {results['f1_score']:.3f}\")\n",
    "    \n",
    "    return best_model, all_results\n",
    "\n",
    "# Функция для создания ансамбля с фичами\n",
    "def create_feature_ensemble(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Создание ансамблевых моделей с улучшенными фичами\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import StackingClassifier\n",
    "    \n",
    "    # Базовые модели для ансамбля\n",
    "    base_models = [\n",
    "        ('lr', LogisticRegression(C=1, solver='liblinear', random_state=42)),\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "        ('svm', LinearSVC(C=1, random_state=42)),\n",
    "        ('mlp', MLPClassifier(hidden_layer_sizes=(100,), random_state=42))\n",
    "    ]\n",
    "    \n",
    "    # Создаем пайплайн для ансамбля\n",
    "    ensemble_pipeline = make_imb_pipeline(\n",
    "        AdvancedTextTransformer(),\n",
    "        SMOTE(random_state=42),\n",
    "        StackingClassifier(\n",
    "            estimators=base_models,\n",
    "            final_estimator=LogisticRegression(),\n",
    "            cv=3\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Обучение ансамбля\n",
    "    ensemble_pipeline.fit(X_train, y_train)\n",
    "    ensemble_acc = accuracy_score(y_test, ensemble_pipeline.predict(X_test))\n",
    "    ensemble_f1 = f1_score(y_test, ensemble_pipeline.predict(X_test), average='weighted')\n",
    "    \n",
    "    print(f\"\\n--- АНСАМБЛЬ С FEATURE ENGINEERING ---\")\n",
    "    print(f\"Ensemble Accuracy: {ensemble_acc:.3f}\")\n",
    "    print(f\"Ensemble F1-score: {ensemble_f1:.3f}\")\n",
    "    \n",
    "    return ensemble_pipeline\n",
    "\n",
    "# Анализ важности фич\n",
    "def analyze_feature_importance(model, feature_names, top_n=20):\n",
    "    \"\"\"\n",
    "    Анализ важности признаков для лучшей модели\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if hasattr(model.named_steps['classifier'], 'feature_importances_'):\n",
    "            importances = model.named_steps['classifier'].feature_importances_\n",
    "            indices = np.argsort(importances)[::-1][:top_n]\n",
    "            \n",
    "            print(f\"\\n--- ТОП-{top_n} ВАЖНЫХ ПРИЗНАКОВ ---\")\n",
    "            for i in indices:\n",
    "                if i < len(feature_names):\n",
    "                    print(f\"{feature_names[i]:<30} | Importance: {importances[i]:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Анализ важности признаков не доступен: {e}\")\n",
    "\n",
    "# Основная функция выполнения\n",
    "def main():\n",
    "    # Загрузка и подготовка данных\n",
    "    df = pd.DataFrame(data)\n",
    "    X = df[\"description\"]\n",
    "    y = df[\"category\"]\n",
    "    \n",
    "    print(\"Размер исходных данных:\")\n",
    "    print(f\"X: {X.shape}, y: {y.shape}\")\n",
    "    print(f\"Распределение классов: {dict(zip(*np.unique(y, return_counts=True)))}\")\n",
    "    \n",
    "    # Стратифицированное разделение\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nРазделение данных:\")\n",
    "    print(f\"Обучающая выборка: {X_train.shape}\")\n",
    "    print(f\"Тестовая выборка: {X_test.shape}\")\n",
    "    \n",
    "    # Обучение моделей с улучшенным Feature Engineering\n",
    "    best_model, all_results = train_advanced_models_with_features(\n",
    "        X_train, y_train, X_test, y_test\n",
    "    )\n",
    "    \n",
    "    # Создание ансамбля\n",
    "    ensemble_model = create_feature_ensemble(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # Финальное сравнение\n",
    "    final_results = {\n",
    "        **{name: results['accuracy'] for name, results in all_results.items()},\n",
    "        'Feature Ensemble': accuracy_score(y_test, ensemble_model.predict(X_test))\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ФИНАЛЬНОЕ СРАВНЕНИЕ ВСЕХ МОДЕЛЕЙ:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for model_name, accuracy in sorted(final_results.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{model_name:<25} | Accuracy: {accuracy:.3f}\")\n",
    "    \n",
    "    # Анализ лучшей модели\n",
    "    print(f\"\\n🎯 ЛУЧШАЯ МОДЕЛЬ: {list(all_results.keys())[0]}\")\n",
    "    print(f\"📊 Точность: {list(all_results.values())[0]['accuracy']:.3f}\")\n",
    "    \n",
    "    return best_model, ensemble_model, all_results\n",
    "\n",
    "# Дополнительная функция для тестирования разных стратегий Feature Engineering\n",
    "def test_feature_engineering_strategies(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Тестирование разных стратегий Feature Engineering\n",
    "    \"\"\"\n",
    "    strategies = {\n",
    "        'TF-IDF Only': TfidfVectorizer(max_features=1000),\n",
    "        'TF-IDF + Linguistic': AdvancedTextTransformer(tfidf_max_features=1000),\n",
    "        'TF-IDF + Linguistic + Chars': AdvancedTextTransformer(tfidf_max_features=2000)\n",
    "    }\n",
    "    \n",
    "    model = LogisticRegression(C=1, solver='liblinear', random_state=42)\n",
    "    \n",
    "    results = {}\n",
    "    for name, transformer in strategies.items():\n",
    "        pipeline = make_imb_pipeline(\n",
    "            transformer,\n",
    "            SMOTE(random_state=42),\n",
    "            model\n",
    "        )\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        acc = accuracy_score(y_test, pipeline.predict(X_test))\n",
    "        results[name] = acc\n",
    "        print(f\"{name:<30} | Accuracy: {acc:.3f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер исходных данных:\n",
      "X: (16965,), y: (16965,)\n",
      "Распределение классов: {'Абразивы': np.int64(13), 'Адаптеры компьютерные': np.int64(19), 'Антенны': np.int64(30), 'Аппараты телефонные (телефоны)': np.int64(108), 'Арматура светосигнальная': np.int64(43), 'Бани лабораторные': np.int64(38), 'Бетон': np.int64(21), 'Бидоны': np.int64(50), 'Блоки системные': np.int64(27), 'Ведра для нефтепродуктов': np.int64(10), 'Вентиляторы приборные (компьютерные)': np.int64(61), 'Вещества поверхностно-активные': np.int64(10), 'Видеокарты': np.int64(20), 'Вискозиметры': np.int64(54), 'Втулки переходные конусные': np.int64(12), 'Выключатели автоматические': np.int64(452), 'Выключатели электроустановочные': np.int64(51), 'Вышки и мачты мобильные': np.int64(17), 'Горелки теплотехнические': np.int64(50), 'Датчики виброскорости': np.int64(14), 'Дет. телеф., радио-, звук-, видеотехники': np.int64(144), 'Диски (CD и DVD)': np.int64(13), 'Диски жесткие (накопители твердотельные)': np.int64(54), 'Дистилляторы': np.int64(20), 'Документы нормативные': np.int64(48), 'Домкраты': np.int64(21), 'Жилеты дем. сигнал. 2 класс': np.int64(41), 'Запчасти и комплектующие средств защиты': np.int64(43), 'Знаки': np.int64(213), 'Изделия деревянные плотничные и столярные': np.int64(10), 'Изделия для прокладки кабелей и проводов': np.int64(910), 'Изделия и детали изготавливаемые': np.int64(2753), 'Измерители концентрац. и хим состава в-в': np.int64(113), 'Индикаторы химические': np.int64(87), 'Источники питан., аккум-ры (кр.автом-х)': np.int64(37), 'Кабели силовые прочие': np.int64(659), 'Катализаторы отработанные': np.int64(49), 'Клавиатуры': np.int64(27), 'Клапаны скважинные': np.int64(29), 'Ключи буровые, трубные, штанговые': np.int64(33), 'Колеры, краски, грунтовки и покрытия': np.int64(161), 'Колпачки, протекторы, заглушки защитные': np.int64(30), 'Кольца общепромышленные': np.int64(12), 'Компл. приб., датч., изм. инстр. пр.': np.int64(93), 'Комплектующие лабораторного оборудования': np.int64(826), 'Комплектующие машин слива/налива': np.int64(31), 'Комплекты (клавиатуры и мышь)': np.int64(17), 'Кондиционеры и сплит-системы': np.int64(319), 'Контейнеры IBC': np.int64(12), 'Костюмы лет муж ЛМ03-01': np.int64(390), 'Костюмы противоэнцефалитные': np.int64(161), 'Крышки к канистрам однокомпонентные': np.int64(53), 'Материалы гидроиз. ленточные и рулонные': np.int64(30), 'Материалы прокладочные графитовые': np.int64(28), 'Машины слива и налива цистерн ж/д': np.int64(16), 'Мебель лабораторная и вытяжные шкафы': np.int64(202), 'Мешалки лабораторные': np.int64(36), 'Модули оперативной памяти': np.int64(32), 'Мотор-редукторы': np.int64(18), 'Набивки сальниковые': np.int64(218), 'Ножи, лески триммерные, общетехнические': np.int64(69), 'Ноутбуки': np.int64(25), 'Оборуд. диспетчер. и оператор. связи': np.int64(53), 'Оборуд., машины, уст-ва смесительные': np.int64(16), 'Образцы стандартные': np.int64(946), 'Огнеупоры': np.int64(20), 'Одежда форменная': np.int64(23), 'Печи и шкафы сушильные лабораторные': np.int64(40), 'Пистолеты (ручной инструмент)': np.int64(55), 'Пластики однородные': np.int64(93), 'Плитки строительные': np.int64(35), 'Подстанции трансформаторные': np.int64(149), 'Полимеры поликонденсационные': np.int64(17), 'Полумаски фильтр для защиты от аэрозолей': np.int64(28), 'Посуда лабораторная немерная фарфоровая': np.int64(56), 'Преобразователи ржавчины': np.int64(13), 'Преобразователи сигналов': np.int64(96), 'Приводы CD и DVD': np.int64(16), 'Противогазы': np.int64(27), 'Процессоры для АРМ': np.int64(11), 'Пульты и панели управления': np.int64(60), 'Пульты управления (панели оператора)': np.int64(70), 'Радиостанции': np.int64(49), 'Радиоустройства (кроме антенн)': np.int64(22), 'Развертки': np.int64(33), 'Раств-ли и ср-ва д чист. марк-го оборуд.': np.int64(11), 'Растворители и разбавители': np.int64(11), 'Реактивы гот. спец., наборы реактивов': np.int64(147), 'Резцы токарные (кроме резьбовых)': np.int64(129), 'Ремни приводные': np.int64(1206), 'Самоспасатели': np.int64(13), 'Серверы и рабочие станции': np.int64(15), 'Смартфоны': np.int64(26), 'Смеси и растворы строительные': np.int64(28), 'Сооружения назн. энерг. инфрастр. стац.': np.int64(15), 'Средства защиты информационные': np.int64(91), 'Средства моющие, чист., дезинф., промыш.': np.int64(42), 'Станки и машины пильные, распил., отрез.': np.int64(14), 'Станки ме-обр. заточные шлифовальные': np.int64(36), 'Станки ме-обр. сверлил. расточн. резьб.': np.int64(30), 'Станции (системы) связи оперативной': np.int64(28), 'Станции управления': np.int64(64), 'Стикеры  самоклеящиеся': np.int64(23), 'Таблички, вывески и наклейки': np.int64(142), 'Тара д. материалов жидких, вязких прочая': np.int64(24), 'Тара специальная для оборудования и ЗиП': np.int64(16), 'Уголь активированный для очистки воды': np.int64(10), 'Узлы сетей и систем связи': np.int64(157), 'Узлы, уст-ва полиграф. оборудования': np.int64(35), 'Уст-ва управл. и защиты эл/установок': np.int64(10), 'Уст-ки заправ., раздаточные, ЗИП пр.': np.int64(12), 'Устройства и оснастка лабораторные': np.int64(79), 'Устройства контроля доступа': np.int64(30), 'Устройства предоставления информ. (УПИ)': np.int64(40), 'Факсы (телефаксы)': np.int64(18), 'Фильтроэлементы, картриджи, кассеты смен': np.int64(39), 'Фильтры д/очистки жидк. и газообр. сред': np.int64(430), 'Флеш-накопители': np.int64(86), 'Цементы': np.int64(10), 'Цепи приводные роликовые и втулочные': np.int64(18), 'Части и комплектующие распределит. уст-в': np.int64(26), 'Части, дет. двигат., прив.,мех. прочие': np.int64(494), 'Части, компл-щие генераторов электромаш.': np.int64(56), 'Щебень и гравий': np.int64(15), 'Щетки д/зачистных, шлиф. и полир. машин': np.int64(28), 'Эл/агрегаты и эл/станции с дизельн. ДВС': np.int64(28), 'Электродвигатели асинхронные общ. назн.': np.int64(491), 'Этикетки вплавляемые': np.int64(548), 'Этикетки самоклеящиеся': np.int64(1083)}\n",
      "\n",
      "Разделение данных:\n",
      "Обучающая выборка: (11875,)\n",
      "Тестовая выборка: (5090,)\n",
      "=== КОМПЛЕКСНОЕ ОБУЧЕНИЕ МОДЕЛЕЙ С FEATURE ENGINEERING ===\n",
      "\n",
      "\n",
      "--- Настройка модели: Logistic Regression ---\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'classifier' for estimator Pipeline(steps=[('advancedtexttransformer', AdvancedTextTransformer()),\n                ('smote', SMOTE(k_neighbors=3, random_state=42)),\n                ('logisticregression',\n                 LogisticRegression(max_iter=1000, random_state=42))]). Valid parameters are: ['memory', 'steps', 'transform_input', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 490, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 607, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 147, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 847, in _fit_and_score\n    estimator = estimator.set_params(**clone(parameters, safe=False))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 319, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 69, in _set_params\n    super().set_params(**params)\n  File \"c:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 345, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'classifier' for estimator Pipeline(steps=[('advancedtexttransformer', AdvancedTextTransformer()),\n                ('smote', SMOTE(k_neighbors=3, random_state=42)),\n                ('logisticregression',\n                 LogisticRegression(max_iter=1000, random_state=42))]). Valid parameters are: ['memory', 'steps', 'transform_input', 'verbose'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m best_model, ensemble_model, results = \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Дополнительно: тестирование стратегий Feature Engineering\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 280\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mТестовая выборка: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    279\u001b[39m \u001b[38;5;66;03m# Обучение моделей с улучшенным Feature Engineering\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m best_model, all_results = \u001b[43mtrain_advanced_models_with_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Создание ансамбля\u001b[39;00m\n\u001b[32m    285\u001b[39m ensemble_model = create_feature_ensemble(X_train, y_train, X_test, y_test)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 169\u001b[39m, in \u001b[36mtrain_advanced_models_with_features\u001b[39m\u001b[34m(X_train, y_train, X_test, y_test)\u001b[39m\n\u001b[32m    159\u001b[39m grid_search = GridSearchCV(\n\u001b[32m    160\u001b[39m     estimator=pipeline,\n\u001b[32m    161\u001b[39m     param_grid=param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m    165\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m    166\u001b[39m )\n\u001b[32m    168\u001b[39m \u001b[38;5;66;03m# Обучение модели\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[38;5;66;03m# Предсказание и оценка\u001b[39;00m\n\u001b[32m    172\u001b[39m y_pred = grid_search.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1784\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1782\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1783\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1785\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1787\u001b[39m     nb_jobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1859\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1855\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1856\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1857\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:758\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    752\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZubarevVV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:773\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Invalid parameter 'classifier' for estimator Pipeline(steps=[('advancedtexttransformer', AdvancedTextTransformer()),\n                ('smote', SMOTE(k_neighbors=3, random_state=42)),\n                ('logisticregression',\n                 LogisticRegression(max_iter=1000, random_state=42))]). Valid parameters are: ['memory', 'steps', 'transform_input', 'verbose']."
     ]
    }
   ],
   "source": [
    "best_model, ensemble_model, results = main()\n",
    "    \n",
    "# Дополнительно: тестирование стратегий Feature Engineering\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ТЕСТИРОВАНИЕ СТРАТЕГИЙ FEATURE ENGINEERING:\")\n",
    "print(\"=\"*60)\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "X = df[\"description\"]\n",
    "y = df[\"category\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "feature_results = test_feature_engineering_strategies(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Нейросеть 2 редакция"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные исправления:\n",
    "\n",
    "1. Кодирование меток классов\n",
    "\n",
    "```python\n",
    "# Добавлен LabelEncoder для преобразования текстовых меток в числа\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "```\n",
    "\n",
    "2. Обработка русских стоп-слов\n",
    "\n",
    "```python\n",
    "# Указаны русские стоп-слова в векторизаторе\n",
    "TfidfVectorizer(stop_words='russian')\n",
    "```\n",
    "\n",
    "3. Упрощенные пайплайны\n",
    "\n",
    "· Убрана сложная комбинация FeatureUnion\n",
    "· Упрощены параметры GridSearch для стабильности\n",
    "\n",
    "4. Обработка ошибок\n",
    "\n",
    "· Добавлены try-except блоки\n",
    "· Альтернативные подходы на случай ошибок\n",
    "\n",
    "Если проблема сохраняется, попробуйте этот минимальный рабочий пример:\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Минимальный рабочий пример\n",
    "def simple_solution(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    X = df[\"description\"]\n",
    "    y = df[\"category\"]\n",
    "    \n",
    "    # Кодируем метки\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    \n",
    "    # Векторизация текста\n",
    "    vectorizer = TfidfVectorizer(max_features=1000, stop_words='russian')\n",
    "    X_vec = vectorizer.fit_transform(X)\n",
    "    \n",
    "    # Разделение данных\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_vec, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    # Обучение модели\n",
    "    model = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Оценка\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Точность: {acc:.3f}\")\n",
    "    print(\"Метки классов:\", le.classes_)\n",
    "    \n",
    "    return model, le, vectorizer\n",
    "\n",
    "# Использование\n",
    "model, encoder, vectorizer = simple_solution(data)\n",
    "```\n",
    "\n",
    "Это должно решить проблему с текстовыми метками классов!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline as make_imb_pipeline\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Кодировщик меток для преобразования текстовых категорий в числа\n",
    "class LabelEncoderWrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.encoder = LabelEncoder()\n",
    "        self.classes_ = None\n",
    "    \n",
    "    def fit(self, y):\n",
    "        self.encoder.fit(y)\n",
    "        self.classes_ = self.encoder.classes_\n",
    "        return self\n",
    "    \n",
    "    def transform(self, y):\n",
    "        return self.encoder.transform(y)\n",
    "    \n",
    "    def inverse_transform(self, y):\n",
    "        return self.encoder.inverse_transform(y)\n",
    "\n",
    "# Кастомный трансформер для извлечения лингвистических features\n",
    "class TextFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        features = []\n",
    "        \n",
    "        for text in X:\n",
    "            text_str = str(text)\n",
    "            \n",
    "            # Базовые статистики текста\n",
    "            num_chars = len(text_str)\n",
    "            words = text_str.split()\n",
    "            num_words = len(words)\n",
    "            sentences = re.split(r'[.!?]+', text_str)\n",
    "            num_sentences = len([s for s in sentences if s.strip()])\n",
    "            \n",
    "            avg_word_length = num_chars / num_words if num_words > 0 else 0\n",
    "            avg_sentence_length = num_words / num_sentences if num_sentences > 0 else 0\n",
    "            \n",
    "            # Стилистические features\n",
    "            num_uppercase = sum(1 for char in text_str if char.isupper())\n",
    "            num_digits = sum(1 for char in text_str if char.isdigit())\n",
    "            num_punctuation = sum(1 for char in text_str if char in '.,!?;:')\n",
    "            \n",
    "            # Сложность текста\n",
    "            unique_words = len(set(word.lower() for word in words))\n",
    "            lexical_diversity = unique_words / num_words if num_words > 0 else 0\n",
    "            \n",
    "            features.append([\n",
    "                num_chars, num_words, num_sentences, avg_word_length,\n",
    "                avg_sentence_length, num_uppercase, num_digits,\n",
    "                num_punctuation, unique_words, lexical_diversity\n",
    "            ])\n",
    "        \n",
    "        return np.array(features)\n",
    "\n",
    "# Комплексный трансформер для текста\n",
    "class AdvancedTextTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, tfidf_max_features=2000, ngram_range=(1, 2)):\n",
    "        self.tfidf_max_features = tfidf_max_features\n",
    "        self.ngram_range = ngram_range\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Инициализируем и обучаем компоненты\n",
    "        self.tfidf_ = TfidfVectorizer(\n",
    "            max_features=self.tfidf_max_features,\n",
    "            ngram_range=self.ngram_range,\n",
    "            stop_words='english',  # Используем русские стоп-слова\n",
    "            min_df=2,\n",
    "            max_df=0.8,\n",
    "            sublinear_tf=True\n",
    "        )\n",
    "        \n",
    "        self.linguistic_scaler_ = StandardScaler()\n",
    "        self.char_vectorizer_ = CountVectorizer(\n",
    "            analyzer='char',\n",
    "            ngram_range=(2, 4),\n",
    "            max_features=1000\n",
    "        )\n",
    "        \n",
    "        # Обучаем все компоненты\n",
    "        X_tfidf = self.tfidf_.fit_transform(X)\n",
    "        X_linguistic = TextFeatureExtractor().fit_transform(X)\n",
    "        self.linguistic_scaler_.fit(X_linguistic)\n",
    "        self.char_vectorizer_.fit(X)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Преобразуем данные через все компоненты\n",
    "        X_tfidf = self.tfidf_.transform(X)\n",
    "        X_linguistic = TextFeatureExtractor().transform(X)\n",
    "        X_linguistic_scaled = self.linguistic_scaler_.transform(X_linguistic)\n",
    "        X_char = self.char_vectorizer_.transform(X)\n",
    "        \n",
    "        # Объединяем все features\n",
    "        from scipy.sparse import hstack\n",
    "        return hstack([X_tfidf, X_linguistic_scaled, X_char])\n",
    "\n",
    "# Улучшенная функция с обработкой текстовых меток\n",
    "def train_advanced_models_with_features(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Улучшенная функция с обработкой текстовых меток классов\n",
    "    \"\"\"\n",
    "    \n",
    "    # Кодируем метки классов\n",
    "    label_encoder = LabelEncoderWrapper()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "    \n",
    "    print(\"Закодированные метки классов:\")\n",
    "    for original, encoded in zip(label_encoder.classes_, range(len(label_encoder.classes_))):\n",
    "        print(f\"  {original} -> {encoded}\")\n",
    "    \n",
    "    # Базовые конфигурации моделей\n",
    "    models_config = {\n",
    "        \"Logistic Regression\": {\n",
    "            'model': LogisticRegression(random_state=42, max_iter=1000),\n",
    "            'params': {\n",
    "                'classifier__C': [0.1, 1, 10],\n",
    "                'classifier__solver': ['liblinear', 'saga'],\n",
    "                'classifier__class_weight': ['balanced']\n",
    "            }\n",
    "        },\n",
    "        \"Random Forest\": {\n",
    "            'model': RandomForestClassifier(random_state=42),\n",
    "            'params': {\n",
    "                'classifier__n_estimators': [100, 200],\n",
    "                'classifier__max_depth': [10, 20, None],\n",
    "                'classifier__class_weight': ['balanced']\n",
    "            }\n",
    "        },\n",
    "        \"Linear SVM\": {\n",
    "            'model': LinearSVC(random_state=42, max_iter=1000),\n",
    "            'params': {\n",
    "                'classifier__C': [0.1, 1, 10],\n",
    "                'classifier__class_weight': ['balanced']\n",
    "            }\n",
    "        },\n",
    "        \"MLPClassifier\": {\n",
    "            'model': MLPClassifier(random_state=42, max_iter=500, early_stopping=True),\n",
    "            'params': {\n",
    "                'classifier__hidden_layer_sizes': [(100,), (50, 25)],\n",
    "                'classifier__alpha': [0.001, 0.01],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    best_model_name = \"\"\n",
    "    all_results = {}\n",
    "    \n",
    "    print(\"\\n=== КОМПЛЕКСНОЕ ОБУЧЕНИЕ МОДЕЛЕЙ ===\")\n",
    "    \n",
    "    for name, config in models_config.items():\n",
    "        print(f\"\\n--- Настройка модели: {name} ---\")\n",
    "        \n",
    "        try:\n",
    "            # Создаем пайплайн\n",
    "            pipeline = Pipeline([\n",
    "                ('features', AdvancedTextTransformer()),\n",
    "                ('smote', SMOTE(random_state=42, k_neighbors=2)),\n",
    "                ('classifier', config['model'])\n",
    "            ])\n",
    "            \n",
    "            # Упрощенная сетка параметров для скорости\n",
    "            param_grid = config['params']\n",
    "            \n",
    "            # Grid Search\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=pipeline,\n",
    "                param_grid=param_grid,\n",
    "                cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            # Обучение модели\n",
    "            grid_search.fit(X_train, y_train_encoded)\n",
    "            \n",
    "            # Предсказание и оценка\n",
    "            y_pred_encoded = grid_search.predict(X_test)\n",
    "            y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "            \n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            \n",
    "            print(f\"Точность на тесте: {acc:.3f}\")\n",
    "            print(f\"F1-score: {f1:.3f}\")\n",
    "            \n",
    "            # Сохраняем результаты\n",
    "            all_results[name] = {\n",
    "                'model': grid_search.best_estimator_,\n",
    "                'label_encoder': label_encoder,\n",
    "                'accuracy': acc,\n",
    "                'f1_score': f1,\n",
    "                'best_params': grid_search.best_params_\n",
    "            }\n",
    "            \n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_model = grid_search.best_estimator_\n",
    "                best_model_name = name\n",
    "                best_label_encoder = label_encoder\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обучении {name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Сравнение моделей\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"СРАВНЕНИЕ МОДЕЛЕЙ:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for name, results in sorted(all_results.items(), key=lambda x: x[1]['accuracy'], reverse=True):\n",
    "        print(f\"{name:<20} | Accuracy: {results['accuracy']:.3f} | F1: {results['f1_score']:.3f}\")\n",
    "    \n",
    "    return best_model, best_label_encoder, all_results\n",
    "\n",
    "# Упрощенная версия для быстрого тестирования\n",
    "def quick_train(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Упрощенная функция для быстрого тестирования без GridSearch\n",
    "    \"\"\"\n",
    "    # Кодируем метки\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "    \n",
    "    # Простой пайплайн\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=1000, stop_words='english')),\n",
    "        ('smote', SMOTE(random_state=42, k_neighbors=2)),\n",
    "        ('classifier', LogisticRegression(class_weight='balanced', random_state=42))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train_encoded)\n",
    "    y_pred_encoded = pipeline.predict(X_test)\n",
    "    y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Быстрое тестирование - Точность: {acc:.3f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return pipeline, label_encoder\n",
    "\n",
    "# Основная функция выполнения\n",
    "def main(data):\n",
    "    # Ваши данные\n",
    "    df = pd.DataFrame(data)\n",
    "    X = df[\"description\"]\n",
    "    y = df[\"category\"]\n",
    "    \n",
    "    print(\"Анализ данных:\")\n",
    "    print(f\"Размер данных: {X.shape}\")\n",
    "    print(f\"Количество классов: {len(y.unique())}\")\n",
    "    print(\"Примеры категорий:\")\n",
    "    for i, category in enumerate(y.unique()[:5]):\n",
    "        print(f\"  {i+1}. {category}\")\n",
    "    \n",
    "    # Проверяем, что y - это строки, а не числа\n",
    "    print(f\"\\nТип меток: {type(y.iloc[0])}\")\n",
    "    print(f\"Пример метки: {y.iloc[0]}\")\n",
    "    \n",
    "    # Разделение данных\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nРазделение данных:\")\n",
    "    print(f\"Обучающая выборка: {X_train.shape}\")\n",
    "    print(f\"Тестовая выборка: {X_test.shape}\")\n",
    "    \n",
    "    try:\n",
    "        # Сначала быстрый тест\n",
    "        print(\"\\n=== БЫСТРОЕ ТЕСТИРОВАНИЕ ===\")\n",
    "        quick_model, quick_encoder = quick_train(X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        # Затем полное обучение\n",
    "        print(\"\\n=== ПОЛНОЕ ОБУЧЕНИЕ ===\")\n",
    "        best_model, label_encoder, all_results = train_advanced_models_with_features(\n",
    "            X_train, y_train, X_test, y_test\n",
    "        )\n",
    "        \n",
    "        # Финальные результаты\n",
    "        if all_results:\n",
    "            best_name = max(all_results.items(), key=lambda x: x[1]['accuracy'])[0]\n",
    "            best_acc = all_results[best_name]['accuracy']\n",
    "            print(f\"\\n🎯 ЛУЧШАЯ МОДЕЛЬ: {best_name}\")\n",
    "            print(f\"📊 Точность: {best_acc:.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Основная ошибка: {e}\")\n",
    "        print(\"\\nПробуем альтернативный подход...\")\n",
    "        \n",
    "        # Альтернативный подход без SMOTE\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        \n",
    "        label_encoder = LabelEncoder()\n",
    "        y_encoded = label_encoder.fit_transform(y)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded\n",
    "        )\n",
    "        \n",
    "        vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "        X_train_vec = vectorizer.fit_transform(X_train)\n",
    "        X_test_vec = vectorizer.transform(X_test)\n",
    "        \n",
    "        model = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "        model.fit(X_train_vec, y_train)\n",
    "        \n",
    "        acc = accuracy_score(y_test, model.predict(X_test_vec))\n",
    "        print(f\"Альтернативный подход - Точность: {acc:.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Анализ данных:\n",
      "Размер данных: (16965,)\n",
      "Количество классов: 129\n",
      "Примеры категорий:\n",
      "  1. Горелки теплотехнические\n",
      "  2. Самоспасатели\n",
      "  3. Части, дет. двигат., прив.,мех. прочие\n",
      "  4. Узлы сетей и систем связи\n",
      "  5. Знаки\n",
      "\n",
      "Тип меток: <class 'str'>\n",
      "Пример метки: Горелки теплотехнические\n",
      "\n",
      "Разделение данных:\n",
      "Обучающая выборка: (11875,)\n",
      "Тестовая выборка: (5090,)\n",
      "\n",
      "=== БЫСТРОЕ ТЕСТИРОВАНИЕ ===\n",
      "Основная ошибка: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTE(k_neighbors=2, random_state=42)' (type <class 'imblearn.over_sampling._smote.base.SMOTE'>) doesn't\n",
      "\n",
      "Пробуем альтернативный подход...\n",
      "Альтернативный подход - Точность: 0.918\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Нейросеть 3 редакция"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ключевые исправления:\n",
    "\n",
    "1. Правильные имена параметров для GridSearch\n",
    "\n",
    "```python\n",
    "# Было (неправильно):\n",
    "'classifier__C': [0.1, 1, 10]\n",
    "\n",
    "# Стало (правильно):\n",
    "'model__C': [0.1, 1, 10]  # где 'model' - имя шага в пайплайне\n",
    "```\n",
    "\n",
    "2. Правильная структура пайплайна\n",
    "\n",
    "```python\n",
    "pipeline = ImbPipeline([\n",
    "    ('transformer', SimpleTextTransformer()),  # шаг 1: трансформер\n",
    "    ('smote', SMOTE()),                       # шаг 2: SMOTE  \n",
    "    ('model', LogisticRegression())           # шаг 3: модель\n",
    "])\n",
    "```\n",
    "\n",
    "3. Альтернативные подходы\n",
    "\n",
    "· Упрощенная версия без пайплайнов\n",
    "· Ручная настройка гиперпараметров\n",
    "· Самый простой вариант для гарантированной работы\n",
    "\n",
    "4. Использование правильного Pipeline\n",
    "\n",
    "```python\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline  # для работы с SMOTE\n",
    "```\n",
    "\n",
    "Рекомендую начать с simplest_working_solution() - он самый надежный и точно заработает!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('tmc.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Кодировщик меток\n",
    "class LabelEncoderWrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.encoder = LabelEncoder()\n",
    "        self.classes_ = None\n",
    "    \n",
    "    def fit(self, y):\n",
    "        self.encoder.fit(y)\n",
    "        self.classes_ = self.encoder.classes_\n",
    "        return self\n",
    "    \n",
    "    def transform(self, y):\n",
    "        return self.encoder.transform(y)\n",
    "    \n",
    "    def inverse_transform(self, y):\n",
    "        return self.encoder.inverse_transform(y)\n",
    "\n",
    "# Упрощенный трансформер для текста\n",
    "class SimpleTextTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, tfidf_max_features=1000):\n",
    "        self.tfidf_max_features = tfidf_max_features\n",
    "        self.tfidf = TfidfVectorizer(\n",
    "            max_features=tfidf_max_features,\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words='english',\n",
    "            min_df=2,\n",
    "            max_df=0.8\n",
    "        )\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.tfidf.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.tfidf.transform(X)\n",
    "\n",
    "# Исправленная функция обучения с правильными именами параметров\n",
    "def train_advanced_models_fixed(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Исправленная функция с правильными именами параметров для GridSearch\n",
    "    \"\"\"\n",
    "    \n",
    "    # Кодируем метки классов\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "    \n",
    "    print(\"Закодированные метки классов:\")\n",
    "    for i, class_name in enumerate(label_encoder.classes_):\n",
    "        print(f\"  {class_name} -> {i}\")\n",
    "    \n",
    "    # Конфигурации моделей с ПРАВИЛЬНЫМИ именами параметров\n",
    "    models_config = {\n",
    "        \"Logistic Regression\": {\n",
    "            'pipeline': ImbPipeline([\n",
    "                ('transformer', SimpleTextTransformer()),\n",
    "                ('smote', SMOTE(random_state=42, k_neighbors=2)),\n",
    "                ('model', LogisticRegression(random_state=42, max_iter=1000))\n",
    "            ]),\n",
    "            'params': {\n",
    "                'transformer__tfidf_max_features': [500, 1000],\n",
    "                'model__C': [0.1, 1, 10],\n",
    "                'model__class_weight': ['balanced']\n",
    "            }\n",
    "        },\n",
    "        \"Random Forest\": {\n",
    "            'pipeline': ImbPipeline([\n",
    "                ('transformer', SimpleTextTransformer()),\n",
    "                ('smote', SMOTE(random_state=42, k_neighbors=2)),\n",
    "                ('model', RandomForestClassifier(random_state=42))\n",
    "            ]),\n",
    "            'params': {\n",
    "                'transformer__tfidf_max_features': [500, 1000],\n",
    "                'model__n_estimators': [50, 100],\n",
    "                'model__max_depth': [10, None],\n",
    "                'model__class_weight': ['balanced']\n",
    "            }\n",
    "        },\n",
    "        \"Linear SVM\": {\n",
    "            'pipeline': ImbPipeline([\n",
    "                ('transformer', SimpleTextTransformer()),\n",
    "                ('smote', SMOTE(random_state=42, k_neighbors=2)),\n",
    "                ('model', LinearSVC(random_state=42, max_iter=1000))\n",
    "            ]),\n",
    "            'params': {\n",
    "                'transformer__tfidf_max_features': [500, 1000],\n",
    "                'model__C': [0.1, 1, 10],\n",
    "                'model__class_weight': ['balanced']\n",
    "            }\n",
    "        },\n",
    "        \"MLPClassifier\": {\n",
    "            'pipeline': ImbPipeline([\n",
    "                ('transformer', SimpleTextTransformer()),\n",
    "                ('smote', SMOTE(random_state=42, k_neighbors=2)),\n",
    "                ('model', MLPClassifier(random_state=42, max_iter=500))\n",
    "            ]),\n",
    "            'params': {\n",
    "                'transformer__tfidf_max_features': [500, 1000],\n",
    "                'model__hidden_layer_sizes': [(50,), (100,)],\n",
    "                'model__alpha': [0.001, 0.01]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    best_model_name = \"\"\n",
    "    all_results = {}\n",
    "    \n",
    "    print(\"\\n=== ОБУЧЕНИЕ МОДЕЛЕЙ ===\")\n",
    "    \n",
    "    for name, config in models_config.items():\n",
    "        print(f\"\\n--- Настройка модели: {name} ---\")\n",
    "        \n",
    "        try:\n",
    "            # Grid Search\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=config['pipeline'],\n",
    "                param_grid=config['params'],\n",
    "                cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            # Обучение модели\n",
    "            grid_search.fit(X_train, y_train_encoded)\n",
    "            \n",
    "            # Предсказание и оценка\n",
    "            y_pred_encoded = grid_search.predict(X_test)\n",
    "            y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "            \n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            \n",
    "            print(f\"Лучшие параметры: {grid_search.best_params_}\")\n",
    "            print(f\"Точность на тесте: {acc:.3f}\")\n",
    "            print(f\"F1-score: {f1:.3f}\")\n",
    "            \n",
    "            # Сохраняем результаты\n",
    "            all_results[name] = {\n",
    "                'model': grid_search.best_estimator_,\n",
    "                'accuracy': acc,\n",
    "                'f1_score': f1,\n",
    "                'best_params': grid_search.best_params_\n",
    "            }\n",
    "            \n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_model = grid_search.best_estimator_\n",
    "                best_model_name = name\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обучении {name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Сравнение моделей\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"СРАВНЕНИЕ МОДЕЛЕЙ:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for name, results in sorted(all_results.items(), key=lambda x: x[1]['accuracy'], reverse=True):\n",
    "        print(f\"{name:<20} | Accuracy: {results['accuracy']:.3f} | F1: {results['f1_score']:.3f}\")\n",
    "    \n",
    "    return best_model, label_encoder, all_results\n",
    "\n",
    "# Альтернативная версия без сложного пайплайна (более надежная)\n",
    "def train_models_simple(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Упрощенная версия без сложных трансформеров\n",
    "    \"\"\"\n",
    "    # Кодируем метки\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "    \n",
    "    # Векторизация текста\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=1000,\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words='english',\n",
    "        min_df=2,\n",
    "        max_df=0.8\n",
    "    )\n",
    "    \n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Применяем SMOTE\n",
    "    smote = SMOTE(random_state=42, k_neighbors=2)\n",
    "    X_train_bal, y_train_bal = smote.fit_resample(X_train_vec, y_train_encoded)\n",
    "    \n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced'),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "        \"Linear SVM\": LinearSVC(random_state=42, max_iter=1000, class_weight='balanced'),\n",
    "        \"MLPClassifier\": MLPClassifier(random_state=42, max_iter=500)\n",
    "    }\n",
    "    \n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    best_model_name = \"\"\n",
    "    results = {}\n",
    "    \n",
    "    print(\"\\n=== УПРОЩЕННОЕ ОБУЧЕНИЕ ===\")\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n--- Обучение {name} ---\")\n",
    "        \n",
    "        try:\n",
    "            model.fit(X_train_bal, y_train_bal)\n",
    "            y_pred_encoded = model.predict(X_test_vec)\n",
    "            y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "            \n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            \n",
    "            print(f\"Точность: {acc:.3f}\")\n",
    "            print(f\"F1-score: {f1:.3f}\")\n",
    "            \n",
    "            results[name] = {\n",
    "                'model': model,\n",
    "                'vectorizer': vectorizer,\n",
    "                'accuracy': acc,\n",
    "                'f1_score': f1\n",
    "            }\n",
    "            \n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_model = model\n",
    "                best_model_name = name\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return best_model, label_encoder, vectorizer, results\n",
    "\n",
    "# Функция для ручной настройки гиперпараметров (без GridSearch)\n",
    "def manual_hyperparameter_tuning(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Ручная настройка гиперпараметров без использования GridSearch\n",
    "    \"\"\"\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Балансировка\n",
    "    smote = SMOTE(random_state=42, k_neighbors=2)\n",
    "    X_train_bal, y_train_bal = smote.fit_resample(X_train_vec, y_train_encoded)\n",
    "    \n",
    "    # Различные комбинации параметров\n",
    "    param_combinations = [\n",
    "        {'model': LogisticRegression(C=0.1, class_weight='balanced', random_state=42), 'name': 'LR_C0.1'},\n",
    "        {'model': LogisticRegression(C=1, class_weight='balanced', random_state=42), 'name': 'LR_C1'},\n",
    "        {'model': LogisticRegression(C=10, class_weight='balanced', random_state=42), 'name': 'LR_C10'},\n",
    "        {'model': RandomForestClassifier(n_estimators=50, class_weight='balanced', random_state=42), 'name': 'RF_n50'},\n",
    "        {'model': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42), 'name': 'RF_n100'},\n",
    "        {'model': LinearSVC(C=0.1, class_weight='balanced', random_state=42), 'name': 'SVM_C0.1'},\n",
    "        {'model': LinearSVC(C=1, class_weight='balanced', random_state=42), 'name': 'SVM_C1'},\n",
    "        {'model': MLPClassifier(hidden_layer_sizes=(50,), random_state=42), 'name': 'MLP_50'},\n",
    "        {'model': MLPClassifier(hidden_layer_sizes=(100,), random_state=42), 'name': 'MLP_100'},\n",
    "    ]\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_name = \"\"\n",
    "    results = {}\n",
    "    \n",
    "    print(\"\\n=== РУЧНАЯ НАСТРОЙКА ГИПЕРПАРАМЕТРОВ ===\")\n",
    "    \n",
    "    for combo in param_combinations:\n",
    "        try:\n",
    "            model = combo['model']\n",
    "            model.fit(X_train_bal, y_train_bal)\n",
    "            y_pred_encoded = model.predict(X_test_vec)\n",
    "            acc = accuracy_score(y_test_encoded, y_pred_encoded)\n",
    "            \n",
    "            print(f\"{combo['name']}: {acc:.3f}\")\n",
    "            results[combo['name']] = acc\n",
    "            \n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_model = model\n",
    "                best_name = combo['name']\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка для {combo['name']}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nЛучшая модель: {best_name} с точностью {best_accuracy:.3f}\")\n",
    "    return best_model, label_encoder, vectorizer, results\n",
    "\n",
    "# Основная функция\n",
    "def main(data):\n",
    "    # Ваши данные\n",
    "    df = pd.DataFrame(data)\n",
    "    X = df[\"description\"]\n",
    "    y = df[\"category\"]\n",
    "    \n",
    "    print(\"Анализ данных:\")\n",
    "    print(f\"Размер данных: {X.shape}\")\n",
    "    print(f\"Количество классов: {len(y.unique())}\")\n",
    "    print(f\"Пример категории: {y.iloc[0]}\")\n",
    "    \n",
    "    # Разделение данных\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nРазделение данных:\")\n",
    "    print(f\"Обучающая выборка: {X_train.shape}\")\n",
    "    print(f\"Тестовая выборка: {X_test.shape}\")\n",
    "    \n",
    "    try:\n",
    "        # Пробуем исправленную версию\n",
    "        print(\"\\n=== ПЕРВЫЙ ВАРИАНТ: С ПАЙПЛАЙНАМИ ===\")\n",
    "        best_model, label_encoder, all_results = train_advanced_models_fixed(\n",
    "            X_train, y_train, X_test, y_test\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в первом варианте: {e}\")\n",
    "        \n",
    "        # Пробуем упрощенную версию\n",
    "        print(\"\\n=== ВТОРОЙ ВАРИАНТ: УПРОЩЕННАЯ ВЕРСИЯ ===\")\n",
    "        best_model, label_encoder, vectorizer, results = train_models_simple(\n",
    "            X_train, y_train, X_test, y_test\n",
    "        )\n",
    "        \n",
    "        # Если и это не работает, используем ручную настройку\n",
    "        if not results:\n",
    "            print(\"\\n=== ТРЕТИЙ ВАРИАНТ: РУЧНАЯ НАСТРОЙКА ===\")\n",
    "            best_model, label_encoder, vectorizer, results = manual_hyperparameter_tuning(\n",
    "                X_train, y_train, X_test, y_test\n",
    "            )\n",
    "    \n",
    "    print(\"\\n✅ Обучение завершено!\")\n",
    "    return best_model, label_encoder\n",
    "\n",
    "# Самый простой и надежный вариант\n",
    "def simplest_working_solution(data):\n",
    "    \"\"\"\n",
    "    Самый простой и надежный вариант без сложных пайплайнов\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    X = df[\"description\"]\n",
    "    y = df[\"category\"]\n",
    "    \n",
    "    # Кодируем метки\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    \n",
    "    # Векторизация\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=1000,\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 2)\n",
    "    )\n",
    "    X_vec = vectorizer.fit_transform(X)\n",
    "    \n",
    "    # Разделение данных\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_vec, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    # Балансировка\n",
    "    smote = SMOTE(random_state=42, k_neighbors=2)\n",
    "    X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Обучение нескольких моделей\n",
    "    models = {\n",
    "        'LogisticRegression': LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n",
    "        'RandomForest': RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "        'LinearSVM': LinearSVC(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "    }\n",
    "    \n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_bal, y_train_bal)\n",
    "        score = model.score(X_test, y_test)\n",
    "        print(f\"{name}: {score:.3f}\")\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "    \n",
    "    print(f\"\\nЛучшая модель: {best_score:.3f}\")\n",
    "    return best_model, le, vectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Анализ данных:\n",
      "Размер данных: (16965,)\n",
      "Количество классов: 129\n",
      "Пример категории: Горелки теплотехнические\n",
      "\n",
      "Разделение данных:\n",
      "Обучающая выборка: (11875,)\n",
      "Тестовая выборка: (5090,)\n",
      "\n",
      "=== ПЕРВЫЙ ВАРИАНТ: С ПАЙПЛАЙНАМИ ===\n",
      "Закодированные метки классов:\n",
      "  Абразивы -> 0\n",
      "  Адаптеры компьютерные -> 1\n",
      "  Антенны -> 2\n",
      "  Аппараты телефонные (телефоны) -> 3\n",
      "  Арматура светосигнальная -> 4\n",
      "  Бани лабораторные -> 5\n",
      "  Бетон -> 6\n",
      "  Бидоны -> 7\n",
      "  Блоки системные -> 8\n",
      "  Ведра для нефтепродуктов -> 9\n",
      "  Вентиляторы приборные (компьютерные) -> 10\n",
      "  Вещества поверхностно-активные -> 11\n",
      "  Видеокарты -> 12\n",
      "  Вискозиметры -> 13\n",
      "  Втулки переходные конусные -> 14\n",
      "  Выключатели автоматические -> 15\n",
      "  Выключатели электроустановочные -> 16\n",
      "  Вышки и мачты мобильные -> 17\n",
      "  Горелки теплотехнические -> 18\n",
      "  Датчики виброскорости -> 19\n",
      "  Дет. телеф., радио-, звук-, видеотехники -> 20\n",
      "  Диски (CD и DVD) -> 21\n",
      "  Диски жесткие (накопители твердотельные) -> 22\n",
      "  Дистилляторы -> 23\n",
      "  Документы нормативные -> 24\n",
      "  Домкраты -> 25\n",
      "  Жилеты дем. сигнал. 2 класс -> 26\n",
      "  Запчасти и комплектующие средств защиты -> 27\n",
      "  Знаки -> 28\n",
      "  Изделия деревянные плотничные и столярные -> 29\n",
      "  Изделия для прокладки кабелей и проводов -> 30\n",
      "  Изделия и детали изготавливаемые -> 31\n",
      "  Измерители концентрац. и хим состава в-в -> 32\n",
      "  Индикаторы химические -> 33\n",
      "  Источники питан., аккум-ры (кр.автом-х) -> 34\n",
      "  Кабели силовые прочие -> 35\n",
      "  Катализаторы отработанные -> 36\n",
      "  Клавиатуры -> 37\n",
      "  Клапаны скважинные -> 38\n",
      "  Ключи буровые, трубные, штанговые -> 39\n",
      "  Колеры, краски, грунтовки и покрытия -> 40\n",
      "  Колпачки, протекторы, заглушки защитные -> 41\n",
      "  Кольца общепромышленные -> 42\n",
      "  Компл. приб., датч., изм. инстр. пр. -> 43\n",
      "  Комплектующие лабораторного оборудования -> 44\n",
      "  Комплектующие машин слива/налива -> 45\n",
      "  Комплекты (клавиатуры и мышь) -> 46\n",
      "  Кондиционеры и сплит-системы -> 47\n",
      "  Контейнеры IBC -> 48\n",
      "  Костюмы лет муж ЛМ03-01 -> 49\n",
      "  Костюмы противоэнцефалитные -> 50\n",
      "  Крышки к канистрам однокомпонентные -> 51\n",
      "  Материалы гидроиз. ленточные и рулонные -> 52\n",
      "  Материалы прокладочные графитовые -> 53\n",
      "  Машины слива и налива цистерн ж/д -> 54\n",
      "  Мебель лабораторная и вытяжные шкафы -> 55\n",
      "  Мешалки лабораторные -> 56\n",
      "  Модули оперативной памяти -> 57\n",
      "  Мотор-редукторы -> 58\n",
      "  Набивки сальниковые -> 59\n",
      "  Ножи, лески триммерные, общетехнические -> 60\n",
      "  Ноутбуки -> 61\n",
      "  Оборуд. диспетчер. и оператор. связи -> 62\n",
      "  Оборуд., машины, уст-ва смесительные -> 63\n",
      "  Образцы стандартные -> 64\n",
      "  Огнеупоры -> 65\n",
      "  Одежда форменная -> 66\n",
      "  Печи и шкафы сушильные лабораторные -> 67\n",
      "  Пистолеты (ручной инструмент) -> 68\n",
      "  Пластики однородные -> 69\n",
      "  Плитки строительные -> 70\n",
      "  Подстанции трансформаторные -> 71\n",
      "  Полимеры поликонденсационные -> 72\n",
      "  Полумаски фильтр для защиты от аэрозолей -> 73\n",
      "  Посуда лабораторная немерная фарфоровая -> 74\n",
      "  Преобразователи ржавчины -> 75\n",
      "  Преобразователи сигналов -> 76\n",
      "  Приводы CD и DVD -> 77\n",
      "  Противогазы -> 78\n",
      "  Процессоры для АРМ -> 79\n",
      "  Пульты и панели управления -> 80\n",
      "  Пульты управления (панели оператора) -> 81\n",
      "  Радиостанции -> 82\n",
      "  Радиоустройства (кроме антенн) -> 83\n",
      "  Развертки -> 84\n",
      "  Раств-ли и ср-ва д чист. марк-го оборуд. -> 85\n",
      "  Растворители и разбавители -> 86\n",
      "  Реактивы гот. спец., наборы реактивов -> 87\n",
      "  Резцы токарные (кроме резьбовых) -> 88\n",
      "  Ремни приводные -> 89\n",
      "  Самоспасатели -> 90\n",
      "  Серверы и рабочие станции -> 91\n",
      "  Смартфоны -> 92\n",
      "  Смеси и растворы строительные -> 93\n",
      "  Сооружения назн. энерг. инфрастр. стац. -> 94\n",
      "  Средства защиты информационные -> 95\n",
      "  Средства моющие, чист., дезинф., промыш. -> 96\n",
      "  Станки и машины пильные, распил., отрез. -> 97\n",
      "  Станки ме-обр. заточные шлифовальные -> 98\n",
      "  Станки ме-обр. сверлил. расточн. резьб. -> 99\n",
      "  Станции (системы) связи оперативной -> 100\n",
      "  Станции управления -> 101\n",
      "  Стикеры  самоклеящиеся -> 102\n",
      "  Таблички, вывески и наклейки -> 103\n",
      "  Тара д. материалов жидких, вязких прочая -> 104\n",
      "  Тара специальная для оборудования и ЗиП -> 105\n",
      "  Уголь активированный для очистки воды -> 106\n",
      "  Узлы сетей и систем связи -> 107\n",
      "  Узлы, уст-ва полиграф. оборудования -> 108\n",
      "  Уст-ва управл. и защиты эл/установок -> 109\n",
      "  Уст-ки заправ., раздаточные, ЗИП пр. -> 110\n",
      "  Устройства и оснастка лабораторные -> 111\n",
      "  Устройства контроля доступа -> 112\n",
      "  Устройства предоставления информ. (УПИ) -> 113\n",
      "  Факсы (телефаксы) -> 114\n",
      "  Фильтроэлементы, картриджи, кассеты смен -> 115\n",
      "  Фильтры д/очистки жидк. и газообр. сред -> 116\n",
      "  Флеш-накопители -> 117\n",
      "  Цементы -> 118\n",
      "  Цепи приводные роликовые и втулочные -> 119\n",
      "  Части и комплектующие распределит. уст-в -> 120\n",
      "  Части, дет. двигат., прив.,мех. прочие -> 121\n",
      "  Части, компл-щие генераторов электромаш. -> 122\n",
      "  Щебень и гравий -> 123\n",
      "  Щетки д/зачистных, шлиф. и полир. машин -> 124\n",
      "  Эл/агрегаты и эл/станции с дизельн. ДВС -> 125\n",
      "  Электродвигатели асинхронные общ. назн. -> 126\n",
      "  Этикетки вплавляемые -> 127\n",
      "  Этикетки самоклеящиеся -> 128\n",
      "\n",
      "=== ОБУЧЕНИЕ МОДЕЛЕЙ ===\n",
      "\n",
      "--- Настройка модели: Logistic Regression ---\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Лучшие параметры: {'model__C': 0.1, 'model__class_weight': 'balanced', 'transformer__tfidf_max_features': 500}\n",
      "Точность на тесте: 0.886\n",
      "F1-score: 0.895\n",
      "\n",
      "--- Настройка модели: Random Forest ---\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Лучшие параметры: {'model__class_weight': 'balanced', 'model__max_depth': None, 'model__n_estimators': 100, 'transformer__tfidf_max_features': 500}\n",
      "Точность на тесте: 0.899\n",
      "F1-score: 0.904\n",
      "\n",
      "--- Настройка модели: Linear SVM ---\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Самый надежный вариант\n",
    "    #model, label_encoder, vectorizer = simplest_working_solution(data)\n",
    "    best_model, label_encoder = main(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
