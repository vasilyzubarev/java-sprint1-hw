{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫ –∏ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from rapidfuzz import process as rapid_process\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_keywords(text):\n",
    "    \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è\"\"\"\n",
    "    text = preprocess_text(text)\n",
    "    words = text.split()\n",
    "    stop_words = {'–¥–ª—è', '–∏–∑', '–≤', '–Ω–∞', '—Å', '–ø–æ', '–∏', '–∏–ª–∏', '–Ω–µ', '–æ—Ç', '–¥–æ', '–±–µ–∑', '–ø–æ–¥', '–Ω–∞–¥'}\n",
    "    keywords = [word for word in words if len(word) > 2 and word not in stop_words]\n",
    "    return set(keywords)\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    \"\"\"–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –ñ–∞–∫–∫–∞—Ä–∞\"\"\"\n",
    "    if not set1 or not set2:\n",
    "        return 0\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "def find_best_match_fuzzy(text, choices, threshold=80):\n",
    "    \"\"\"–ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º fuzzy matching\"\"\"\n",
    "    matches = process.extract(text, choices, scorer=fuzz.token_set_ratio, limit=5)\n",
    "    if matches and matches[0][1] >= threshold:\n",
    "        return matches[0]\n",
    "    else:\n",
    "        return (None, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –§—É–Ω–∫—Ü–∏–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_dataframes_fuzzy(tmc_df, sup_df, threshold=80):\n",
    "    \"\"\"–°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–≤–∞ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º fuzzy matching\"\"\"\n",
    "    sup_descriptions = sup_df['FULL_NAME/ru_RU'].tolist()\n",
    "    \n",
    "    results = []\n",
    "    total_records = len(tmc_df)\n",
    "    \n",
    "    print(\"–ó–∞–ø—É—Å–∫ Fuzzy Matching...\")\n",
    "    print(f\"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_records:,}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for idx in range(total_records):\n",
    "        row = tmc_df.iloc[idx]\n",
    "        tmc_desc = row['FULL_NAME/ru_RU']\n",
    "        \n",
    "        # –ü—Ä–æ—Å—Ç–æ–π –≤—ã–≤–æ–¥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∫–∞–∂–¥—ã–µ 100 –∑–∞–ø–∏—Å–µ–π\n",
    "        if idx % 100 == 0:\n",
    "            percent = (idx / total_records) * 100\n",
    "            print(f\"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {idx:,}/{total_records:,} ({percent:.1f}%)\")\n",
    "        \n",
    "        match_result = find_best_match_fuzzy(tmc_desc, sup_descriptions, threshold)\n",
    "        best_match, score = match_result\n",
    "        \n",
    "        if best_match:\n",
    "            sup_match = sup_df[sup_df['FULL_NAME/ru_RU'] == best_match]\n",
    "            if not sup_match.empty:\n",
    "                sup_row = sup_match.iloc[0]\n",
    "                results.append({\n",
    "                    'TMC_CSCD_ID': row['CSCD_ID'],\n",
    "                    'TMC_Description': tmc_desc,\n",
    "                    'SUP_CSCD_ID': sup_row['CSCD_ID'],\n",
    "                    'SUP_Description': best_match,\n",
    "                    'Match_Score': score\n",
    "                })\n",
    "    \n",
    "    print(f\"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_records:,}/{total_records:,} (100.0%)\")\n",
    "    print(\"-\" * 50)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def match_with_tfidf(tmc_df, sup_df, top_k=3, similarity_threshold=0.6):\n",
    "    \"\"\"–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º TF-IDF –∏ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞\"\"\"\n",
    "    \n",
    "    total_records = len(tmc_df)\n",
    "    print(\"–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤...\")\n",
    "    \n",
    "    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤\n",
    "    tmc_texts = []\n",
    "    for i in range(total_records):\n",
    "        desc = tmc_df.iloc[i]['FULL_NAME/ru_RU']\n",
    "        tmc_texts.append(preprocess_text(desc))\n",
    "        if i % 100 == 0:\n",
    "            print(f\"TMC: {i:,}/{total_records:,}\")\n",
    "    \n",
    "    sup_texts = []\n",
    "    sup_total = len(sup_df)\n",
    "    for i in range(sup_total):\n",
    "        desc = sup_df.iloc[i]['FULL_NAME/ru_RU']\n",
    "        sup_texts.append(preprocess_text(desc))\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"SUP: {i:,}/{sup_total:,}\")\n",
    "    \n",
    "    print(\"–°–æ–∑–¥–∞–Ω–∏–µ TF-IDF –º–∞—Ç—Ä–∏—Ü—ã...\")\n",
    "    vectorizer = TfidfVectorizer(min_df=1, max_df=0.8, ngram_range=(1, 2), max_features=10000)\n",
    "    all_texts = tmc_texts + sup_texts\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
    "    \n",
    "    tmc_tfidf = tfidf_matrix[:len(tmc_texts)]\n",
    "    sup_tfidf = tfidf_matrix[len(tmc_texts):]\n",
    "    \n",
    "    print(\"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ Nearest Neighbors...\")\n",
    "    nbrs = NearestNeighbors(n_neighbors=min(top_k, len(sup_texts)), metric='cosine')\n",
    "    nbrs.fit(sup_tfidf)\n",
    "    \n",
    "    print(\"–ü–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π...\")\n",
    "    distances, indices = nbrs.kneighbors(tmc_tfidf)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(len(tmc_texts)):\n",
    "        dist_list = distances[i]\n",
    "        idx_list = indices[i]\n",
    "        \n",
    "        tmc_desc = tmc_df.iloc[i]['FULL_NAME/ru_RU']\n",
    "        tmc_id = tmc_df.iloc[i]['CSCD_ID']\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            percent = (i / total_records) * 100\n",
    "            print(f\"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i:,}/{total_records:,} ({percent:.1f}%)\")\n",
    "        \n",
    "        for j in range(len(dist_list)):\n",
    "            dist = dist_list[j]\n",
    "            sup_idx = idx_list[j]\n",
    "            similarity = 1 - dist\n",
    "            \n",
    "            if similarity >= similarity_threshold and sup_idx < len(sup_df):\n",
    "                sup_row = sup_df.iloc[sup_idx]\n",
    "                results.append({\n",
    "                    'TMC_CSCD_ID': tmc_id,\n",
    "                    'TMC_Description': tmc_desc,\n",
    "                    'SUP_CSCD_ID': sup_row['CSCD_ID'],\n",
    "                    'SUP_Description': sup_row['FULL_NAME/ru_RU'],\n",
    "                    'Similarity_Score': similarity,\n",
    "                    'Rank': j + 1\n",
    "                })\n",
    "    \n",
    "    print(f\"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_records:,}/{total_records:,} (100.0%)\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def combined_matching(tmc_df, sup_df, weight_fuzzy=0.6, weight_jaccard=0.4, search_limit=500):\n",
    "    \"\"\"–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ—Ç—Ä–∏–∫\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    total_records = len(tmc_df)\n",
    "    \n",
    "    print(\"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö SUP...\")\n",
    "    sup_descriptions = sup_df['FULL_NAME/ru_RU'].tolist()\n",
    "    \n",
    "    # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –≤—ã—á–∏—Å–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è SUP\n",
    "    sup_keywords = []\n",
    "    actual_search_limit = min(search_limit, len(sup_df))\n",
    "    for i in range(actual_search_limit):\n",
    "        desc = sup_df.iloc[i]['FULL_NAME/ru_RU']\n",
    "        sup_keywords.append(extract_keywords(desc))\n",
    "        if i % 100 == 0:\n",
    "            print(f\"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ SUP: {i:,}/{actual_search_limit:,}\")\n",
    "    \n",
    "    print(\"–û–±—Ä–∞–±–æ—Ç–∫–∞ TMC –∑–∞–ø–∏—Å–µ–π...\")\n",
    "    \n",
    "    for idx in range(total_records):\n",
    "        tmc_row = tmc_df.iloc[idx]\n",
    "        tmc_desc = tmc_row['FULL_NAME/ru_RU']\n",
    "        tmc_keywords = extract_keywords(tmc_desc)\n",
    "        \n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        best_sup_idx = -1\n",
    "        \n",
    "        for sup_idx in range(actual_search_limit):\n",
    "            sup_row = sup_df.iloc[sup_idx]\n",
    "            sup_desc = sup_row['FULL_NAME/ru_RU']\n",
    "            \n",
    "            # Fuzzy matching score\n",
    "            fuzzy_score = fuzz.token_set_ratio(tmc_desc, sup_desc) / 100\n",
    "            \n",
    "            # Jaccard similarity\n",
    "            jaccard_score = jaccard_similarity(tmc_keywords, sup_keywords[sup_idx])\n",
    "            \n",
    "            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score\n",
    "            combined_score = (weight_fuzzy * fuzzy_score + \n",
    "                            weight_jaccard * jaccard_score)\n",
    "            \n",
    "            if combined_score > best_score:\n",
    "                best_score = combined_score\n",
    "                best_match = sup_row\n",
    "                best_sup_idx = sup_idx\n",
    "        \n",
    "        if idx % 100 == 0:\n",
    "            percent = (idx / total_records) * 100\n",
    "            matches_found = len(results)\n",
    "            print(f\"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {idx:,}/{total_records:,} ({percent:.1f}%), –Ω–∞–π–¥–µ–Ω–æ: {matches_found}\")\n",
    "        \n",
    "        if best_match is not None and best_score > 0.5:\n",
    "            results.append({\n",
    "                'TMC_CSCD_ID': tmc_row['CSCD_ID'],\n",
    "                'TMC_Description': tmc_desc,\n",
    "                'SUP_CSCD_ID': best_match['CSCD_ID'],\n",
    "                'SUP_Description': best_match['FULL_NAME/ru_RU'],\n",
    "                'Combined_Score': best_score,\n",
    "                'Fuzzy_Score': fuzz.token_set_ratio(tmc_desc, best_match['FULL_NAME/ru_RU']) / 100,\n",
    "                'Jaccard_Score': jaccard_similarity(tmc_keywords, sup_keywords[best_sup_idx])\n",
    "            })\n",
    "    \n",
    "    print(f\"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_records:,}/{total_records:,} (100.0%)\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def parallel_fuzzy_match(args):\n",
    "    \"\"\"–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "    tmc_chunk, sup_descriptions, threshold, chunk_id, total_chunks = args\n",
    "    results = []\n",
    "    \n",
    "    for tmc_desc in tmc_chunk:\n",
    "        match = rapid_process.extractOne(\n",
    "            tmc_desc, \n",
    "            sup_descriptions, \n",
    "            scorer=fuzz.token_set_ratio, \n",
    "            score_cutoff=threshold\n",
    "        )\n",
    "        if match:\n",
    "            results.append((tmc_desc, match[0], match[1]))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def parallel_matching(tmc_df, sup_df, threshold=75, n_workers=4):\n",
    "    \"\"\"–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\"\"\"\n",
    "    \n",
    "    tmc_descriptions = tmc_df['FULL_NAME/ru_RU'].tolist()\n",
    "    sup_descriptions = sup_df['FULL_NAME/ru_RU'].tolist()\n",
    "    total_records = len(tmc_descriptions)\n",
    "    \n",
    "    chunk_size = max(1, len(tmc_descriptions) // n_workers)\n",
    "    chunks = [tmc_descriptions[i:i + chunk_size] for i in range(0, len(tmc_descriptions), chunk_size)]\n",
    "    \n",
    "    chunk_args = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_args.append((chunk, sup_descriptions, threshold, i, len(chunks)))\n",
    "    \n",
    "    print(f\"–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å {n_workers} workers...\")\n",
    "    print(f\"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {total_records:,}\")\n",
    "    print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}\")\n",
    "    \n",
    "    all_results = []\n",
    "    with mp.Pool(n_workers) as pool:\n",
    "        for i, result in enumerate(pool.imap(parallel_fuzzy_match, chunk_args)):\n",
    "            all_results.append(result)\n",
    "            print(f\"–û–±—Ä–∞–±–æ—Ç–∞–Ω —á–∞–Ω–∫ {i+1}/{len(chunks)}\")\n",
    "    \n",
    "    flat_results = [item for sublist in all_results for item in sublist]\n",
    "    \n",
    "    print(\"–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ DataFrame...\")\n",
    "    results_df = []\n",
    "    \n",
    "    for tmc_desc, sup_desc, score in flat_results:\n",
    "        tmc_match = tmc_df[tmc_df['FULL_NAME/ru_RU'] == tmc_desc]\n",
    "        sup_match = sup_df[sup_df['FULL_NAME/ru_RU'] == sup_desc]\n",
    "        \n",
    "        if not tmc_match.empty and not sup_match.empty:\n",
    "            tmc_row = tmc_match.iloc[0]\n",
    "            sup_row = sup_match.iloc[0]\n",
    "            \n",
    "            results_df.append({\n",
    "                'TMC_CSCD_ID': tmc_row['CSCD_ID'],\n",
    "                'TMC_Description': tmc_desc,\n",
    "                'SUP_CSCD_ID': sup_row['CSCD_ID'],\n",
    "                'SUP_Description': sup_desc,\n",
    "                'Match_Score': score\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –§—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –º–µ—Ç–æ–¥–æ–≤ –∏ Excel —Ñ—É–Ω–∫—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_with_progress(tmc_df, sup_df, method='fuzzy', **kwargs):\n",
    "    \"\"\"\n",
    "    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –º–µ—Ç–æ–¥–æ–≤\n",
    "    \"\"\"\n",
    "    from time import time\n",
    "    start_time = time()\n",
    "    \n",
    "    total_tmc = len(tmc_df)\n",
    "    total_sup = len(sup_df)\n",
    "    \n",
    "    print(f\"–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_tmc:,} TMC –∑–∞–ø–∏—Å–µ–π vs {total_sup:,} SUP –∑–∞–ø–∏—Å–µ–π\")\n",
    "    print(f\"–ú–µ—Ç–æ–¥: {method}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if method == 'fuzzy':\n",
    "        results = match_dataframes_fuzzy(tmc_df, sup_df, **kwargs)\n",
    "    elif method == 'tfidf':\n",
    "        results = match_with_tfidf(tmc_df, sup_df, **kwargs)\n",
    "    elif method == 'combined':\n",
    "        results = combined_matching(tmc_df, sup_df, **kwargs)\n",
    "    elif method == 'parallel':\n",
    "        results = parallel_matching(tmc_df, sup_df, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥. –î–æ—Å—Ç—É–ø–Ω—ã–µ: 'fuzzy', 'tfidf', 'combined', 'parallel'\")\n",
    "    \n",
    "    end_time = time()\n",
    "    processing_time = end_time - start_time\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(\"–û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê\")\n",
    "    print(f\"–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f} —Å–µ–∫—É–Ω–¥\")\n",
    "    print(f\"–ù–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π: {len(results):,}\")\n",
    "    print(f\"–ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è: {len(results)/total_tmc*100:.1f}%\")\n",
    "    \n",
    "    if len(results) > 0:\n",
    "        score_column = results.columns[-1]\n",
    "        avg_score = results[score_column].mean()\n",
    "        max_score = results[score_column].max()\n",
    "        min_score = results[score_column].min()\n",
    "        print(f\"–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è: {avg_score:.3f}\")\n",
    "        print(f\"–õ—É—á—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {max_score:.3f}\")\n",
    "        print(f\"–•—É–¥—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {min_score:.3f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_results_to_excel(results, tmc_df, sup_df, filename, method_name):\n",
    "    \"\"\"\n",
    "    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–¥–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞ –≤ Excel —Ñ–∞–π–ª\n",
    "    \"\"\"\n",
    "    with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
    "        # –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "        results.to_excel(writer, sheet_name='–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è', index=False)\n",
    "        \n",
    "        if len(results) > 0:\n",
    "            score_column = results.columns[-1]\n",
    "            \n",
    "            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "            stats_data = {\n",
    "                '–ú–µ—Ç—Ä–∏–∫–∞': [\n",
    "                    '–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π TMC',\n",
    "                    '–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π SUP', \n",
    "                    '–ù–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π',\n",
    "                    '–ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è',\n",
    "                    '–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞',\n",
    "                    '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞',\n",
    "                    '–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞'\n",
    "                ],\n",
    "                '–ó–Ω–∞—á–µ–Ω–∏–µ': [\n",
    "                    len(tmc_df),\n",
    "                    len(sup_df),\n",
    "                    len(results),\n",
    "                    f\"{len(results)/len(tmc_df)*100:.2f}%\",\n",
    "                    f\"{results[score_column].mean():.3f}\",\n",
    "                    f\"{results[score_column].max():.3f}\",\n",
    "                    f\"{results[score_column].min():.3f}\"\n",
    "                ]\n",
    "            }\n",
    "            stats_df = pd.DataFrame(stats_data)\n",
    "            stats_df.to_excel(writer, sheet_name='–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', index=False)\n",
    "            \n",
    "            # –¢–æ–ø-10 –ª—É—á—à–∏—Ö —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π\n",
    "            top_10 = results.nlargest(10, score_column)\n",
    "            top_10.to_excel(writer, sheet_name='–¢–æ–ø-10 —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π', index=False)\n",
    "\n",
    "def create_summary_excel(all_results, tmc_df, sup_df):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞–µ—Ç —Å–≤–æ–¥–Ω—ã–π Excel —Ñ–∞–π–ª —Å–æ –≤—Å–µ–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –º–µ—Ç–æ–¥–æ–≤\n",
    "    \"\"\"\n",
    "    with pd.ExcelWriter('all_methods_comparison.xlsx', engine='openpyxl') as writer:\n",
    "        \n",
    "        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤\n",
    "        comparison_data = []\n",
    "        for method_name, results in all_results.items():\n",
    "            if len(results) > 0:\n",
    "                score_column = results.columns[-1]\n",
    "                comparison_data.append({\n",
    "                    '–ú–µ—Ç–æ–¥': method_name.upper(),\n",
    "                    '–í—Å–µ–≥–æ_—Å–æ–≤–ø–∞–¥–µ–Ω–∏–π': len(results),\n",
    "                    '–ü—Ä–æ—Ü–µ–Ω—Ç_—Å–æ–≤–ø–∞–¥–µ–Ω–∏–π': f\"{(len(results)/len(tmc_df)*100):.2f}%\",\n",
    "                    '–°—Ä–µ–¥–Ω—è—è_–æ—Ü–µ–Ω–∫–∞': f\"{results[score_column].mean():.3f}\",\n",
    "                    '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è_–æ—Ü–µ–Ω–∫–∞': f\"{results[score_column].max():.3f}\",\n",
    "                    '–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è_–æ—Ü–µ–Ω–∫–∞': f\"{results[score_column].min():.3f}\"\n",
    "                })\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        comparison_df.to_excel(writer, sheet_name='–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤', index=False)\n",
    "        \n",
    "        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞\n",
    "        for method_name, results in all_results.items():\n",
    "            sheet_name = method_name[:31]\n",
    "            results.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "        stats_summary = []\n",
    "        for method_name, results in all_results.items():\n",
    "            if len(results) > 0:\n",
    "                score_column = results.columns[-1]\n",
    "                stats_summary.append({\n",
    "                    '–ú–µ—Ç–æ–¥': method_name.upper(),\n",
    "                    '–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π TMC': len(tmc_df),\n",
    "                    '–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π SUP': len(sup_df),\n",
    "                    '–ù–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π': len(results),\n",
    "                    '–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞': f\"{(len(results)/len(tmc_df)*100):.2f}%\",\n",
    "                    '–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞': results[score_column].mean()\n",
    "                })\n",
    "        \n",
    "        stats_summary_df = pd.DataFrame(stats_summary)\n",
    "        stats_summary_df.to_excel(writer, sheet_name='–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "print(\"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "tmc_df = pd.read_excel('–û–ö–ü–î_1.xlsx')\n",
    "sup_df = pd.read_excel('–û–ö–ü–î_2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ –ó–ê–ü–£–°–ö –°–ò–°–¢–ï–ú–´ –°–†–ê–í–ù–ï–ù–ò–Ø –ù–û–ú–ï–ù–ö–õ–ê–¢–£–†\n",
      "======================================================================\n",
      "‚úÖ TMC –∑–∞–ø–∏—Å–µ–π: 351\n",
      "‚úÖ SUP –∑–∞–ø–∏—Å–µ–π: 15,064\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üîç –ó–ê–ü–£–°–ö –ú–ï–¢–û–î–ê: FUZZY\n",
      "======================================================================\n",
      "–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏: 351 TMC –∑–∞–ø–∏—Å–µ–π vs 15,064 SUP –∑–∞–ø–∏—Å–µ–π\n",
      "–ú–µ—Ç–æ–¥: fuzzy\n",
      "------------------------------------------------------------\n",
      "–ó–∞–ø—É—Å–∫ Fuzzy Matching...\n",
      "–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 351\n",
      "--------------------------------------------------\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 0/351 (0.0%)\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 100/351 (28.5%)\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 200/351 (57.0%)\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 300/351 (85.5%)\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 351/351 (100.0%)\n",
      "--------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "–û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê\n",
      "–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 67.07 —Å–µ–∫—É–Ω–¥\n",
      "–ù–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π: 262\n",
      "–ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è: 74.6%\n",
      "–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è: 91.275\n",
      "–õ—É—á—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: 100.000\n",
      "–•—É–¥—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: 81.000\n",
      "üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: fuzzy_matching_results.xlsx\n",
      "\n",
      "======================================================================\n",
      "üîç –ó–ê–ü–£–°–ö –ú–ï–¢–û–î–ê: TFIDF\n",
      "======================================================================\n",
      "–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏: 351 TMC –∑–∞–ø–∏—Å–µ–π vs 15,064 SUP –∑–∞–ø–∏—Å–µ–π\n",
      "–ú–µ—Ç–æ–¥: tfidf\n",
      "------------------------------------------------------------\n",
      "–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤...\n",
      "TMC: 0/351\n",
      "TMC: 100/351\n",
      "TMC: 200/351\n",
      "TMC: 300/351\n",
      "SUP: 0/15,064\n",
      "SUP: 1,000/15,064\n",
      "SUP: 2,000/15,064\n",
      "SUP: 3,000/15,064\n",
      "SUP: 4,000/15,064\n",
      "SUP: 5,000/15,064\n",
      "SUP: 6,000/15,064\n",
      "SUP: 7,000/15,064\n",
      "SUP: 8,000/15,064\n",
      "SUP: 9,000/15,064\n",
      "SUP: 10,000/15,064\n",
      "SUP: 11,000/15,064\n",
      "SUP: 12,000/15,064\n",
      "SUP: 13,000/15,064\n",
      "SUP: 14,000/15,064\n",
      "SUP: 15,000/15,064\n",
      "–°–æ–∑–¥–∞–Ω–∏–µ TF-IDF –º–∞—Ç—Ä–∏—Ü—ã...\n",
      "–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ Nearest Neighbors...\n",
      "–ü–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π...\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 0/351 (0.0%)\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 100/351 (28.5%)\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 200/351 (57.0%)\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 300/351 (85.5%)\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 351/351 (100.0%)\n",
      "------------------------------------------------------------\n",
      "–û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê\n",
      "–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 0.58 —Å–µ–∫—É–Ω–¥\n",
      "–ù–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π: 565\n",
      "–ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è: 161.0%\n",
      "–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è: 1.704\n",
      "–õ—É—á—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: 3.000\n",
      "–•—É–¥—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: 1.000\n",
      "üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: tfidf_matching_results.xlsx\n",
      "\n",
      "======================================================================\n",
      "üîç –ó–ê–ü–£–°–ö –ú–ï–¢–û–î–ê: COMBINED\n",
      "======================================================================\n",
      "–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏: 351 TMC –∑–∞–ø–∏—Å–µ–π vs 15,064 SUP –∑–∞–ø–∏—Å–µ–π\n",
      "–ú–µ—Ç–æ–¥: combined\n",
      "------------------------------------------------------------\n",
      "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö SUP...\n",
      "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ SUP: 0/200\n",
      "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ SUP: 100/200\n",
      "–û–±—Ä–∞–±–æ—Ç–∫–∞ TMC –∑–∞–ø–∏—Å–µ–π...\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 0/351 (0.0%), –Ω–∞–π–¥–µ–Ω–æ: 0\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 100/351 (28.5%), –Ω–∞–π–¥–µ–Ω–æ: 3\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 200/351 (57.0%), –Ω–∞–π–¥–µ–Ω–æ: 3\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 300/351 (85.5%), –Ω–∞–π–¥–µ–Ω–æ: 4\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 351/351 (100.0%)\n",
      "------------------------------------------------------------\n",
      "–û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê\n",
      "–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 2.43 —Å–µ–∫—É–Ω–¥\n",
      "–ù–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π: 4\n",
      "–ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è: 1.1%\n",
      "–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è: 0.424\n",
      "–õ—É—á—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: 0.500\n",
      "–•—É–¥—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: 0.250\n",
      "üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: combined_matching_results.xlsx\n",
      "\n",
      "üéâ –í–°–ï –ú–ï–¢–û–î–´ –ó–ê–í–ï–†–®–ï–ù–´!\n",
      "\n",
      "üìä –°–í–û–î–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:\n",
      "==================================================\n",
      "FUZZY        | –°–æ–≤–ø–∞–¥–µ–Ω–∏–π:    262 | –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: 91.275\n",
      "TFIDF        | –°–æ–≤–ø–∞–¥–µ–Ω–∏–π:    565 | –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: 1.704\n",
      "COMBINED     | –°–æ–≤–ø–∞–¥–µ–Ω–∏–π:      4 | –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: 0.424\n",
      "\n",
      "üìä –°–û–ó–î–ê–ù–ò–ï –°–í–û–î–ù–û–ì–û –û–¢–ß–ï–¢–ê...\n",
      "üíæ –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: all_methods_comparison.xlsx\n",
      "\n",
      "üí° –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –º–µ—Ç–æ–¥–æ–≤: 3 –∏–∑ 3\n"
     ]
    }
   ],
   "source": [
    "# –û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç\n",
    "print(\"üöÄ –ó–ê–ü–£–°–ö –°–ò–°–¢–ï–ú–´ –°–†–ê–í–ù–ï–ù–ò–Ø –ù–û–ú–ï–ù–ö–õ–ê–¢–£–†\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"‚úÖ TMC –∑–∞–ø–∏—Å–µ–π: {len(tmc_df):,}\")\n",
    "print(f\"‚úÖ SUP –∑–∞–ø–∏—Å–µ–π: {len(sup_df):,}\")\n",
    "print()\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–æ–¥—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "methods = [\n",
    "    ('fuzzy', {'threshold': 80}),\n",
    "    ('tfidf', {'top_k': 3, 'similarity_threshold': 0.5}),\n",
    "    ('combined', {'search_limit': 200, 'weight_fuzzy': 0.7, 'weight_jaccard': 0.3})\n",
    "]\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for method_name, params in methods:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"üîç –ó–ê–ü–£–°–ö –ú–ï–¢–û–î–ê: {method_name.upper()}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    try:\n",
    "        results = match_with_progress(tmc_df, sup_df, method=method_name, **params)\n",
    "        all_results[method_name] = results\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ Excel\n",
    "        filename = f'{method_name}_matching_results.xlsx'\n",
    "        save_results_to_excel(results, tmc_df, sup_df, filename, method_name)\n",
    "        print(f\"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {filename}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –≤ –º–µ—Ç–æ–¥–µ {method_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "print(\"\\nüéâ –í–°–ï –ú–ï–¢–û–î–´ –ó–ê–í–ï–†–®–ï–ù–´!\")\n",
    "\n",
    "# –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "print(\"\\nüìä –°–í–û–î–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for method_name, results in all_results.items():\n",
    "    if len(results) > 0:\n",
    "        score_column = results.columns[-1]\n",
    "        avg_score = results[score_column].mean()\n",
    "        print(f\"{method_name.upper():<12} | –°–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(results):>6,} | –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {avg_score:.3f}\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞\n",
    "if all_results:\n",
    "    print(f\"\\nüìä –°–û–ó–î–ê–ù–ò–ï –°–í–û–î–ù–û–ì–û –û–¢–ß–ï–¢–ê...\")\n",
    "    create_summary_excel(all_results, tmc_df, sup_df)\n",
    "    print(\"üíæ –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: all_methods_comparison.xlsx\")\n",
    "\n",
    "print(f\"\\nüí° –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –º–µ—Ç–æ–¥–æ–≤: {len(all_results)} –∏–∑ {len(methods)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –§—É–Ω–∫—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã –°–†–ê–í–ù–ï–ù–ò–ï –ú–ï–¢–û–î–û–í:\n",
      "================================================================================\n",
      "  Method  Total_Matches  Match_Rate_Percent  Average_Score  Best_Match  Worst_Match\n",
      "   FUZZY            262              74.644         91.275     100.000       81.000\n",
      "   TFIDF            565             160.969          1.704       3.000        1.000\n",
      "COMBINED              4               1.140          0.424       0.500        0.250\n",
      "\n",
      "üíæ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: methods_comparison.xlsx\n",
      "\n",
      "üéØ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!\n"
     ]
    }
   ],
   "source": [
    "def compare_results(all_results, tmc_df):\n",
    "    \"\"\"–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–∑–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤\"\"\"\n",
    "    comparison_data = []\n",
    "    \n",
    "    for method_name, results in all_results.items():\n",
    "        if len(results) > 0:\n",
    "            score_column = results.columns[-1]\n",
    "            avg_score = results[score_column].mean()\n",
    "            match_rate = len(results) / len(tmc_df) * 100\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'Method': method_name.upper(),\n",
    "                'Total_Matches': len(results),\n",
    "                'Match_Rate_Percent': match_rate,\n",
    "                'Average_Score': avg_score,\n",
    "                'Best_Match': results[score_column].max(),\n",
    "                'Worst_Match': results[score_column].min()\n",
    "            })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(\"\\nüìã –°–†–ê–í–ù–ï–ù–ò–ï –ú–ï–¢–û–î–û–í:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(comparison_df.to_string(index=False, float_format='%.3f'))\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ\n",
    "    comparison_df.to_excel('methods_comparison.xlsx', index=False, engine='openpyxl')\n",
    "    print(f\"\\nüíæ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: methods_comparison.xlsx\")\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "if all_results:\n",
    "    comparison = compare_results(all_results, tmc_df)\n",
    "\n",
    "print(\"\\nüéØ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ–∏—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "print(\"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "tmc_df = pd.read_excel('TMC.xlsx')\n",
    "sup_df = pd.read_excel('SUP.xlsx')\n",
    "sup_df = pd.concat([tmc_df,sup_df],ignore_index=True)\n",
    "print(\"üì• –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ –ì–û–¢–û–í –ö –ü–û–ò–°–ö–£ –ö–û–ù–ö–†–ï–¢–ù–´–• –ù–û–ú–ï–ù–ö–õ–ê–¢–£–†!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def search_nomenclature_by_description(description, tmc_df, sup_df, threshold=70, top_k=5):\n",
    "    \"\"\"\n",
    "    –ò—â–µ—Ç –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—É –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é —Ç—Ä–µ–º—è –º–µ—Ç–æ–¥–∞–º–∏\n",
    "    \"\"\"\n",
    "    print(f\"üîç –ü–û–ò–°–ö –ù–û–ú–ï–ù–ö–õ–ê–¢–£–†–´: '{description}'\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    results = {\n",
    "        'fuzzy': [],\n",
    "        'tfidf': [],\n",
    "        'combined': []\n",
    "    }\n",
    "    \n",
    "    # –ú–µ—Ç–æ–¥ 1: Fuzzy Matching\n",
    "    print(\"\\n1. FUZZY MATCHING:\")\n",
    "    print(\"-\" * 40)\n",
    "    sup_descriptions = sup_df['FULL_NAME/ru_RU'].tolist()\n",
    "    fuzzy_matches = process.extract(description, sup_descriptions, scorer=fuzz.token_set_ratio, limit=top_k)\n",
    "    \n",
    "    for match_desc, score in fuzzy_matches:\n",
    "        if score >= threshold:\n",
    "            sup_match = sup_df[sup_df['FULL_NAME/ru_RU'] == match_desc]\n",
    "            if not sup_match.empty:\n",
    "                sup_row = sup_match.iloc[0]\n",
    "                results['fuzzy'].append({\n",
    "                    'SUP_CSCD_ID': sup_row['CSCD_ID'],\n",
    "                    'SUP_Description': match_desc,\n",
    "                    'Score': score,\n",
    "                    'Method': 'Fuzzy'\n",
    "                })\n",
    "                print(f\"   üìç –û—Ü–µ–Ω–∫–∞: {score:>3}% | ID: {sup_row['CSCD_ID']}\")\n",
    "                print(f\"      –û–ø–∏—Å–∞–Ω–∏–µ: {match_desc}\")\n",
    "    \n",
    "    # –ú–µ—Ç–æ–¥ 2: TF-IDF\n",
    "    print(\"\\n2. TF-IDF MATCHING:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤\n",
    "    search_text = preprocess_text(description)\n",
    "    sup_texts = [preprocess_text(desc) for desc in sup_df['FULL_NAME/ru_RU']]\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–Ω–∏–µ TF-IDF –º–∞—Ç—Ä–∏—Ü—ã\n",
    "    vectorizer = TfidfVectorizer(min_df=1, max_df=0.8, ngram_range=(1, 2))\n",
    "    all_texts = [search_text] + sup_texts\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
    "    \n",
    "    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã\n",
    "    search_tfidf = tfidf_matrix[0]\n",
    "    sup_tfidf = tfidf_matrix[1:]\n",
    "    \n",
    "    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    similarities = cosine_similarity(search_tfidf, sup_tfidf).flatten()\n",
    "    \n",
    "    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–ø-K —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    \n",
    "    for idx in top_indices:\n",
    "        similarity = similarities[idx]\n",
    "        if similarity >= 0.3:  # –ü–æ—Ä–æ–≥ –¥–ª—è TF-IDF\n",
    "            sup_row = sup_df.iloc[idx]\n",
    "            results['tfidf'].append({\n",
    "                'SUP_CSCD_ID': sup_row['CSCD_ID'],\n",
    "                'SUP_Description': sup_row['FULL_NAME/ru_RU'],\n",
    "                'Score': similarity * 100,\n",
    "                'Method': 'TF-IDF'\n",
    "            })\n",
    "            print(f\"   üìç –û—Ü–µ–Ω–∫–∞: {similarity*100:>5.1f}% | ID: {sup_row['CSCD_ID']}\")\n",
    "            print(f\"      –û–ø–∏—Å–∞–Ω–∏–µ: {sup_row['FULL_NAME/ru_RU']}\")\n",
    "    \n",
    "    # –ú–µ—Ç–æ–¥ 3: –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π\n",
    "    print(\"\\n3. COMBINED MATCHING:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    search_keywords = extract_keywords(description)\n",
    "    combined_results = []\n",
    "    \n",
    "    for idx, sup_row in sup_df.iterrows():\n",
    "        sup_desc = sup_row['FULL_NAME/ru_RU']\n",
    "        sup_keywords = extract_keywords(sup_desc)\n",
    "        \n",
    "        # Fuzzy score\n",
    "        fuzzy_score = fuzz.token_set_ratio(description, sup_desc) / 100\n",
    "        \n",
    "        # Jaccard similarity\n",
    "        jaccard_score = jaccard_similarity(search_keywords, sup_keywords)\n",
    "        \n",
    "        # Combined score (–≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ)\n",
    "        combined_score = (0.6 * fuzzy_score + 0.4 * jaccard_score) * 100\n",
    "        \n",
    "        if combined_score >= threshold:\n",
    "            combined_results.append({\n",
    "                'sup_row': sup_row,\n",
    "                'combined_score': combined_score,\n",
    "                'fuzzy_score': fuzzy_score * 100,\n",
    "                'jaccard_score': jaccard_score * 100\n",
    "            })\n",
    "    \n",
    "    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –±–µ—Ä–µ–º —Ç–æ–ø-K\n",
    "    combined_results.sort(key=lambda x: x['combined_score'], reverse=True)\n",
    "    \n",
    "    for i, result in enumerate(combined_results[:top_k]):\n",
    "        sup_row = result['sup_row']\n",
    "        results['combined'].append({\n",
    "            'SUP_CSCD_ID': sup_row['CSCD_ID'],\n",
    "            'SUP_Description': sup_row['FULL_NAME/ru_RU'],\n",
    "            'Score': result['combined_score'],\n",
    "            'Method': 'Combined',\n",
    "            'Fuzzy_Score': result['fuzzy_score'],\n",
    "            'Jaccard_Score': result['jaccard_score']\n",
    "        })\n",
    "        print(f\"   üìç –û—Ü–µ–Ω–∫–∞: {result['combined_score']:>5.1f}% | ID: {sup_row['CSCD_ID']}\")\n",
    "        print(f\"      Fuzzy: {result['fuzzy_score']:.1f}% | Jaccard: {result['jaccard_score']:.1f}%\")\n",
    "        print(f\"      –û–ø–∏—Å–∞–Ω–∏–µ: {sup_row['FULL_NAME/ru_RU']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_search_results_to_excel(search_description, results, filename):\n",
    "    \"\"\"\n",
    "    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ Excel —Ñ–∞–π–ª\n",
    "    \"\"\"\n",
    "    with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
    "        \n",
    "        # –°–≤–æ–¥–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–∏—Å–∫–µ\n",
    "        summary_data = {\n",
    "            '–ü–∞—Ä–∞–º–µ—Ç—Ä': ['–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å', '–î–∞—Ç–∞ –ø–æ–∏—Å–∫–∞', '–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ Fuzzy', '–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ TF-IDF', '–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ Combined'],\n",
    "            '–ó–Ω–∞—á–µ–Ω–∏–µ': [\n",
    "                search_description,\n",
    "                pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                len(results['fuzzy']),\n",
    "                len(results['tfidf']),\n",
    "                len(results['combined'])\n",
    "            ]\n",
    "        }\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_excel(writer, sheet_name='–°–≤–æ–¥–∫–∞', index=False)\n",
    "        \n",
    "        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã Fuzzy Matching\n",
    "        if results['fuzzy']:\n",
    "            fuzzy_df = pd.DataFrame(results['fuzzy'])\n",
    "            fuzzy_df.to_excel(writer, sheet_name='Fuzzy_Results', index=False)\n",
    "        \n",
    "        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã TF-IDF\n",
    "        if results['tfidf']:\n",
    "            tfidf_df = pd.DataFrame(results['tfidf'])\n",
    "            tfidf_df.to_excel(writer, sheet_name='TFIDF_Results', index=False)\n",
    "        \n",
    "        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã Combined\n",
    "        if results['combined']:\n",
    "            combined_df = pd.DataFrame(results['combined'])\n",
    "            combined_df.to_excel(writer, sheet_name='Combined_Results', index=False)\n",
    "        \n",
    "        # –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–º–µ—Å—Ç–µ\n",
    "        all_results = []\n",
    "        for method in ['fuzzy', 'tfidf', 'combined']:\n",
    "            for result in results[method]:\n",
    "                all_results.append(result)\n",
    "        \n",
    "        if all_results:\n",
    "            all_df = pd.DataFrame(all_results)\n",
    "            all_df.to_excel(writer, sheet_name='–í—Å–µ_—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã', index=False)\n",
    "            \n",
    "            # –¢–æ–ø-10 –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ –≤—Å–µ–º –º–µ—Ç–æ–¥–∞–º\n",
    "            top_10 = all_df.nlargest(10, 'Score')\n",
    "            top_10.to_excel(writer, sheet_name='–¢–æ–ø-10', index=False)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞\n",
    "def interactive_search():\n",
    "    \"\"\"\n",
    "    –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä\n",
    "    \"\"\"\n",
    "    print(\"üéØ –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ô –ü–û–ò–°–ö –ù–û–ú–ï–ù–ö–õ–ê–¢–£–†–´\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\n–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ (–∏–ª–∏ '–≤—ã—Ö–æ–¥' –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è):\")\n",
    "        search_query = input(\"> \").strip()\n",
    "        \n",
    "        if search_query.lower() in ['–≤—ã—Ö–æ–¥', 'exit', 'quit']:\n",
    "            print(\"–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...\")\n",
    "            break\n",
    "        \n",
    "        if not search_query:\n",
    "            print(\"‚ùå –ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nüîç –ü–æ–∏—Å–∫: '{search_query}'\")\n",
    "        print(\"‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞...\")\n",
    "        \n",
    "        try:\n",
    "            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫\n",
    "            results = search_nomenclature_by_description(search_query, tmc_df, sup_df, threshold=70, top_k=5)\n",
    "            \n",
    "            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "            timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
    "            filename = f'search_results_{timestamp}.xlsx'\n",
    "            save_search_results_to_excel(search_query, results, filename)\n",
    "            \n",
    "            print(f\"\\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {filename}\")\n",
    "            \n",
    "            # –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "            total_matches = len(results['fuzzy']) + len(results['tfidf']) + len(results['combined'])\n",
    "            print(f\"\\nüìä –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
    "            print(f\"   ‚Ä¢ Fuzzy Matching: {len(results['fuzzy'])} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π\")\n",
    "            print(f\"   ‚Ä¢ TF-IDF Matching: {len(results['tfidf'])} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π\")\n",
    "            print(f\"   ‚Ä¢ Combined Matching: {len(results['combined'])} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π\")\n",
    "            print(f\"   ‚Ä¢ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {total_matches} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞\n",
    "print(\"üéØ –ì–û–¢–û–í –ö –ü–û–ò–°–ö–£ –ö–û–ù–ö–†–ï–¢–ù–´–• –ù–û–ú–ï–ù–ö–õ–ê–¢–£–†!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_descriptions = [\n",
    "    \"–¢–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫ –∫–æ–∂—É—Ö–æ—Ç—Ä—É–±—á–∞—Ç—ã–π 500 –¢–ü–ì-4,0-–ú1/25–ì-3-–ö-2-–•–õ-–ò\",\n",
    "    \"–¢–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫ –∫–æ–∂—É—Ö–æ—Ç—Ä—É–±—á–∞—Ç—ã–π 1-EW-3001/1,2\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:\n",
      "   1. –¢–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫ –∫–æ–∂—É—Ö–æ—Ç—Ä—É–±—á–∞—Ç—ã–π 500 –¢–ü–ì-4,0-–ú1/25–ì-3-–ö-2-–•–õ-–ò\n",
      "   2. –¢–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫ –∫–æ–∂—É—Ö–æ—Ç—Ä—É–±—á–∞—Ç—ã–π 1-EW-3001/1,2\n",
      "\n",
      "–í—ã–±–µ—Ä–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç:\n",
      "1. –ó–∞–ø—É—Å—Ç–∏—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫\n",
      "2. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ '–¢—Ä—É–±–∞ –æ–±—Å–∞–¥–Ω–∞—è'\n",
      "3. –í–≤–µ—Å—Ç–∏ —Å–≤–æ–π –∑–∞–ø—Ä–æ—Å\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç –ü–û–ò–°–ö –ù–û–ú–ï–ù–ö–õ–ê–¢–£–†–´: '–ö–æ—Å—Ç—é–º –º—É–∂—Å–∫–æ–π —Ä–∞–∑–º–µ—Ä 50 –∑–∏–º–Ω–∏–π —É—Ç–µ–ø–ª–µ–Ω–Ω—ã–π'\n",
      "================================================================================\n",
      "\n",
      "1. FUZZY MATCHING:\n",
      "----------------------------------------\n",
      "   üìç –û—Ü–µ–Ω–∫–∞: 100% | ID: 2140291\n",
      "      –û–ø–∏—Å–∞–Ω–∏–µ: –ö–æ—Å—Ç—é–º –∑–∏–º–Ω–∏–π\n",
      "   üìç –û—Ü–µ–Ω–∫–∞: 100% | ID: 3316202\n",
      "      –û–ø–∏—Å–∞–Ω–∏–µ: –ö–û–°–¢–Æ–ú –£–¢–ï–ü–õ–ï–ù–ù–´–ô\n",
      "   üìç –û—Ü–µ–Ω–∫–∞:  91% | ID: 3267123\n",
      "      –û–ø–∏—Å–∞–Ω–∏–µ: –ö–æ—Å—Ç—é–º –∑–∏–º–Ω–∏–π –º—É–∂—Å–∫–æ–π –±/—É\n",
      "   üìç –û—Ü–µ–Ω–∫–∞:  91% | ID: 1527594\n",
      "      –û–ø–∏—Å–∞–Ω–∏–µ: –ö–æ—Å—Ç—é–º –∑–∏–º–Ω–∏–π –º—É–∂—Å–∫–æ–π –ú–ß–°\n",
      "   üìç –û—Ü–µ–Ω–∫–∞:  91% | ID: 3427670\n",
      "      –û–ø–∏—Å–∞–Ω–∏–µ: –ö–æ—Å—Ç—é–º –º—É–∂—Å–∫–æ–π –∑–∏–º–Ω–∏–π –ú–ß–°\n",
      "\n",
      "2. TF-IDF MATCHING:\n",
      "----------------------------------------\n",
      "   üìç –û—Ü–µ–Ω–∫–∞:  33.4% | ID: 3073156\n",
      "      –û–ø–∏—Å–∞–Ω–∏–µ: –ö–æ—Å—Ç—é–º —Ö/–± –º—É–∂—Å–∫–æ–π\n",
      "\n",
      "3. COMBINED MATCHING:\n",
      "----------------------------------------\n",
      "   üìç –û—Ü–µ–Ω–∫–∞:  78.6% | ID: 3267123\n",
      "      Fuzzy: 91.0% | Jaccard: 60.0%\n",
      "      –û–ø–∏—Å–∞–Ω–∏–µ: –ö–æ—Å—Ç—é–º –∑–∏–º–Ω–∏–π –º—É–∂—Å–∫–æ–π –±/—É\n",
      "   üìç –û—Ü–µ–Ω–∫–∞:  77.4% | ID: 3052822\n",
      "      Fuzzy: 89.0% | Jaccard: 60.0%\n",
      "      –û–ø–∏—Å–∞–Ω–∏–µ: –ö–æ—Å—Ç—é–º –º—É–∂—Å–∫–æ–π –∑–∏–º–Ω–∏–π –ï-40\n",
      "   üìç –û—Ü–µ–Ω–∫–∞:  76.0% | ID: 2140291\n",
      "      Fuzzy: 100.0% | Jaccard: 40.0%\n",
      "      –û–ø–∏—Å–∞–Ω–∏–µ: –ö–æ—Å—Ç—é–º –∑–∏–º–Ω–∏–π\n",
      "   üìç –û—Ü–µ–Ω–∫–∞:  76.0% | ID: 3316202\n",
      "      Fuzzy: 100.0% | Jaccard: 40.0%\n",
      "      –û–ø–∏—Å–∞–Ω–∏–µ: –ö–û–°–¢–Æ–ú –£–¢–ï–ü–õ–ï–ù–ù–´–ô\n",
      "   üìç –û—Ü–µ–Ω–∫–∞:  74.6% | ID: 1527594\n",
      "      Fuzzy: 91.0% | Jaccard: 50.0%\n",
      "      –û–ø–∏—Å–∞–Ω–∏–µ: –ö–æ—Å—Ç—é–º –∑–∏–º–Ω–∏–π –º—É–∂—Å–∫–æ–π –ú–ß–°\n",
      "\n",
      "üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: search_custom_20251014_175435.xlsx\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä –ø–æ–∏—Å–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã\n",
    "\n",
    "print(\"\\nüìã –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:\")\n",
    "for i, desc in enumerate(test_descriptions, 1):\n",
    "    print(f\"   {i}. {desc}\")\n",
    "\n",
    "print(\"\\n–í—ã–±–µ—Ä–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç:\")\n",
    "print(\"1. –ó–∞–ø—É—Å—Ç–∏—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫\")\n",
    "print(\"2. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ '–¢—Ä—É–±–∞ –æ–±—Å–∞–¥–Ω–∞—è'\")\n",
    "print(\"3. –í–≤–µ—Å—Ç–∏ —Å–≤–æ–π –∑–∞–ø—Ä–æ—Å\")\n",
    "\n",
    "choice = input(\"–í–∞—à –≤—ã–±–æ—Ä (1-3): \").strip()\n",
    "\n",
    "if choice == \"1\":\n",
    "    interactive_search()\n",
    "elif choice == \"2\":\n",
    "    search_query = \"–¢—Ä—É–±–∞ –æ–±—Å–∞–¥–Ω–∞—è\"\n",
    "    print(f\"\\nüîç –¢–ï–°–¢–û–í–´–ô –ü–û–ò–°–ö: '{search_query}'\")\n",
    "    results = search_nomenclature_by_description(search_query, tmc_df, sup_df, threshold=70, top_k=5)\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "    filename = f'search_example_{pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")}.xlsx'\n",
    "    save_search_results_to_excel(search_query, results, filename)\n",
    "    print(f\"\\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {filename}\")\n",
    "    \n",
    "elif choice == \"3\":\n",
    "    custom_query = input(\"–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞: \").strip()\n",
    "    if custom_query:\n",
    "        results = search_nomenclature_by_description(custom_query, tmc_df, sup_df, threshold=70, top_k=5)\n",
    "        filename = f'search_custom_{pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")}.xlsx'\n",
    "        save_search_results_to_excel(custom_query, results, filename)\n",
    "        print(f\"\\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {filename}\")\n",
    "    else:\n",
    "        print(\"‚ùå –ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å.\")\n",
    "else:\n",
    "    print(\"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è –ø–æ–∏—Å–∫–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ –ë–´–°–¢–†–´–ô –ü–û–ò–°–ö - –¢–ï–°–¢–û–í–´–ï –ü–†–ò–ú–ï–†–´\n",
      "==================================================\n",
      "\n",
      "üîç –ë–´–°–¢–†–´–ô –ü–û–ò–°–ö: '–¢–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫ –∫–æ–∂—É—Ö–æ—Ç—Ä—É–±—á–∞—Ç—ã–π –¢-119'\n",
      "============================================================\n",
      "üéØ –õ–£–ß–®–ò–ï –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø:\n",
      "\n",
      "1. üìç –û—Ü–µ–Ω–∫–∞: 100%\n",
      "   ID: 2211674\n",
      "   –û–ø–∏—Å–∞–Ω–∏–µ: –¢–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫\n",
      "   ‚úÖ –ï—Å—Ç—å –≤ TMC: 1 –∑–∞–ø–∏—Å–µ–π\n",
      "\n",
      "2. üìç –û—Ü–µ–Ω–∫–∞: 100%\n",
      "   ID: 2218819\n",
      "   –û–ø–∏—Å–∞–Ω–∏–µ: –¢–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫ –∫–æ–∂—É—Ö–æ—Ç—Ä—É–±—á–∞—Ç—ã–π\n",
      "   ‚úÖ –ï—Å—Ç—å –≤ TMC: 1 –∑–∞–ø–∏—Å–µ–π\n",
      "\n",
      "3. üìç –û—Ü–µ–Ω–∫–∞: 97%\n",
      "   ID: 1471209\n",
      "   –û–ø–∏—Å–∞–Ω–∏–µ: –¢–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫ –∫–æ–∂—É—Ö–æ—Ç—Ä—É–±—á–∞—Ç—ã–π –¢-131\n",
      "   ‚úÖ –ï—Å—Ç—å –≤ TMC: 1 –∑–∞–ø–∏—Å–µ–π\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "üîç –ë–´–°–¢–†–´–ô –ü–û–ò–°–ö: '–¢—Ä—É–±–∞ –æ–±—Å–∞–¥–Ω–∞—è 114'\n",
      "============================================================\n",
      "üéØ –õ–£–ß–®–ò–ï –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø:\n",
      "\n",
      "1. üìç –û—Ü–µ–Ω–∫–∞: 100%\n",
      "   ID: 3189715\n",
      "   –û–ø–∏—Å–∞–Ω–∏–µ: –¢—Ä—É–±–∞ –æ–±—Å–∞–¥–Ω–∞—è –û–¢–¢–ú 114,3—Ö6,35-–î—Å –¢–£ 14-3–†-30-2015 —Å –º—É—Ñ—Ç–∞–º–∏\n",
      "   ‚ùå –ù–µ—Ç –≤ TMC\n",
      "\n",
      "2. üìç –û—Ü–µ–Ω–∫–∞: 100%\n",
      "   ID: 3012205\n",
      "   –û–ø–∏—Å–∞–Ω–∏–µ: –¢—Ä—É–±–∞ –æ–±—Å–∞–¥–Ω–∞—è BC 114,3—Ö7,37-–ï—Å –¢–£ 14-3–†-30-2015 —Å –º—É—Ñ—Ç–∞–º–∏\n",
      "   ‚ùå –ù–µ—Ç –≤ TMC\n",
      "\n",
      "3. üìç –û—Ü–µ–Ω–∫–∞: 100%\n",
      "   ID: 2313907\n",
      "   –û–ø–∏—Å–∞–Ω–∏–µ: –¢—Ä—É–±–∞ –æ–±—Å–∞–¥–Ω–∞—è 114,3—Ö7,37-R3-N80 —Ç–∏–ø Q-S-PSL-1 –ì–û–°–¢ 31446-2017\n",
      "   ‚ùå –ù–µ—Ç –≤ TMC\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "üéØ –î–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é interactive_search()\n"
     ]
    }
   ],
   "source": [
    "def quick_search(description, top_k=3):\n",
    "    \"\"\"\n",
    "    –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ –æ–¥–Ω–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é —Å –≤—ã–≤–æ–¥–æ–º –≤ –∫–æ–Ω—Å–æ–ª—å\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç –ë–´–°–¢–†–´–ô –ü–û–ò–°–ö: '{description}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    sup_descriptions = sup_df['FULL_NAME/ru_RU'].tolist()\n",
    "    \n",
    "    # –ü—Ä–æ—Å—Ç–æ–π Fuzzy search\n",
    "    matches = process.extract(description, sup_descriptions, scorer=fuzz.token_set_ratio, limit=top_k)\n",
    "    \n",
    "    print(\"üéØ –õ–£–ß–®–ò–ï –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø:\")\n",
    "    for i, (match_desc, score) in enumerate(matches, 1):\n",
    "        sup_match = sup_df[sup_df['FULL_NAME/ru_RU'] == match_desc]\n",
    "        if not sup_match.empty:\n",
    "            sup_row = sup_match.iloc[0]\n",
    "            print(f\"\\n{i}. üìç –û—Ü–µ–Ω–∫–∞: {score}%\")\n",
    "            print(f\"   ID: {sup_row['CSCD_ID']}\")\n",
    "            print(f\"   –û–ø–∏—Å–∞–Ω–∏–µ: {match_desc}\")\n",
    "            \n",
    "            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤ TMC\n",
    "            tmc_match = tmc_df[tmc_df['FULL_NAME/ru_RU'].str.contains(description, case=False, na=False)]\n",
    "            if not tmc_match.empty:\n",
    "                print(f\"   ‚úÖ –ï—Å—Ç—å –≤ TMC: {len(tmc_match)} –∑–∞–ø–∏—Å–µ–π\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå –ù–µ—Ç –≤ TMC\")\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä—ã –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞\n",
    "print(\"üöÄ –ë–´–°–¢–†–´–ô –ü–û–ò–°–ö - –¢–ï–°–¢–û–í–´–ï –ü–†–ò–ú–ï–†–´\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_queries = [\n",
    "    \"–¢–µ–ø–ª–æ–æ–±–º–µ–Ω–Ω–∏–∫ –∫–æ–∂—É—Ö–æ—Ç—Ä—É–±—á–∞—Ç—ã–π –¢-119\",\n",
    "    \"–¢—Ä—É–±–∞ –æ–±—Å–∞–¥–Ω–∞—è 114\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    quick_search(query)\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "\n",
    "print(\"\\nüéØ –î–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é interactive_search()\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
