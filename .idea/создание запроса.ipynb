{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL QWERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_example = \"\"\"\n",
    "<entry>\n",
    "  <s1245>\n",
    "    <n2821><![CDATA[6058964]]></n2821>\n",
    "    <n2870><![CDATA[2316202]]></n2870>\n",
    "    <n2889>false</n2889>\n",
    "    <n2864>true</n2864>\n",
    "    <n2874>\n",
    "      <n2807/>\n",
    "      <n2797/>\n",
    "      <n2754><![CDATA[Горелка газ.ГБ-351.71.080 ВО]]></n2754>\n",
    "      <n2778/>\n",
    "      <n2729/>\n",
    "      <n2799/>\n",
    "      <n2707/>\n",
    "    </n2874>\n",
    "    <n2815><![CDATA[Горелка газ.ГБ-351.71.080 ВО]]></n2815>\n",
    "    <n2832><![CDATA[<Вид продукции> <Тип> <Обозначение><Чертеж>]]></n2832>\n",
    "    <n2860>\n",
    "      <n2710/>\n",
    "      <n2706/>\n",
    "      <n2766><![CDATA[Горелка газовая чертежГБ-351.71.080 ВО]]></n2766>\n",
    "      <n2740/>\n",
    "      <n2771/>\n",
    "      <n2789/>\n",
    "      <n2752/>\n",
    "    </n2860>\n",
    "    <n2869><![CDATA[Горелка газовая чертежГБ-351.71.080 ВО]]></n2869>\n",
    "    <n2845><![CDATA[<Вид продукции> <Тип> <Тип идентификатора> <Обозначение><Чертеж>]]></n2845>\n",
    "    <n27679>\n",
    "      <n27680/>\n",
    "      <n27686/>\n",
    "      <n27682/>\n",
    "      <n27684/>\n",
    "      <n27683/>\n",
    "      <n27685/>\n",
    "      <n27681/>\n",
    "    </n27679>\n",
    "    <n2837>\n",
    "      <n2801/>\n",
    "      <n2765/>\n",
    "      <n2744/>\n",
    "      <n2714/>\n",
    "      <n2716/>\n",
    "      <n2804/>\n",
    "      <n2732/>\n",
    "    </n2837>\n",
    "    <n2847/>\n",
    "    <n28396>\n",
    "      <n28417/>\n",
    "      <n28418/>\n",
    "      <n28411/>\n",
    "      <n28414/>\n",
    "      <n28412/>\n",
    "      <n28421/>\n",
    "      <n28416/>\n",
    "    </n28396>\n",
    "    <n2851 container=\"Единицы измерения\">108</n2851>\n",
    "    <n2862/>\n",
    "    <n2872>false</n2872>\n",
    "    <n2853><![CDATA[7445]]></n2853>\n",
    "    <n96004/>\n",
    "    <n2884><![CDATA[15167]]></n2884>\n",
    "    <n5726/>\n",
    "    <n5727/>\n",
    "    <n2882/>\n",
    "    <n2846><![CDATA[8949]]></n2846>\n",
    "    <n46383/>\n",
    "    <n31804/>\n",
    "    <n2852/>\n",
    "    <n2844/>\n",
    "    <n28399/>\n",
    "    <n31402/>\n",
    "    <n2810/>\n",
    "    <n2824/>\n",
    "    <n2848/>\n",
    "    <n28400/>\n",
    "    <n91269/>\n",
    "    <n91270/>\n",
    "    <n2857/>\n",
    "    <n2826/>\n",
    "    <n28401>false</n28401>\n",
    "    <n2858/>\n",
    "    <n2861/>\n",
    "    <n30404/>\n",
    "    <n2856/>\n",
    "    <n4960/>\n",
    "    <n2817/>\n",
    "    <n2877/>\n",
    "    <n4961/>\n",
    "    <n2829/>\n",
    "    <n2888><![CDATA[4078]]></n2888>\n",
    "    <n2827/>\n",
    "    <n34306><![CDATA[<table style='border: 1px solid'><tr><td style='width: 13%'><b>Код КССС ТРУ:</b></td><td>2317»3»317. Узлы теплообменного и котельного оборудования</td></tr><tr><td><b>№ п/п ТРУ:</b></td><td>317</td></tr><tr><td><b>Перечень ТРУ:</b></td><td>3</td></tr><tr><td><hr /><td><hr /></tr></table>]]></n34306>\n",
    "    <n52205/>\n",
    "    <n34300/>\n",
    "    <n2822 container=\"Номенклатурные группы затрат\">51</n2822>\n",
    "    <n2867/>\n",
    "    <n5404 container=\"Классификатор видов деятельности\">413</n5404>\n",
    "    <n5405/>\n",
    "    <n37429/>\n",
    "    <n2838/>\n",
    "    <n2866/>\n",
    "    <n5724 occ=\"57234276\">\n",
    "      <n5759>false</n5759>\n",
    "      <n5758><![CDATA[31.12.9999]]></n5758>\n",
    "      <n5757><![CDATA[31.12.9999]]></n5757>\n",
    "      <n5756/>\n",
    "    </n5724>\n",
    "    <n51402>false</n51402>\n",
    "    <n2811 occ=\"28107189\">\n",
    "      <n2783>false</n2783>\n",
    "      <n2709><![CDATA[31.12.9999]]></n2709>\n",
    "      <n2746><![CDATA[31.12.9999]]></n2746>\n",
    "      <n2762/>\n",
    "      <n2770/>\n",
    "    </n2811>\n",
    "    <n28422/>\n",
    "    <n2830/>\n",
    "    <n2840/>\n",
    "    <n2865 occ=\"66497824\"><![CDATA[2]]></n2865>\n",
    "    <n2865 occ=\"66497825\"><![CDATA[3]]></n2865>\n",
    "    <n2865 occ=\"66497826\"><![CDATA[4]]></n2865>\n",
    "    <n2841><![CDATA[8973]]></n2841>\n",
    "    <n4882/>\n",
    "    <n2855>false</n2855>\n",
    "    <n99750/>\n",
    "    <n91305>false</n91305>\n",
    "    <n2820>false</n2820>\n",
    "    <n28388/>\n",
    "    <n30450/>\n",
    "    <n28405/>\n",
    "    <n28406/>\n",
    "    <n30449><![CDATA[Эталонная запись]]></n30449>\n",
    "    <n2873>\n",
    "      <n2730/>\n",
    "      <n2725/>\n",
    "      <n2788><![CDATA[Горелка газ.ГБ-351.71.080 ВО]]></n2788>\n",
    "      <n2761/>\n",
    "      <n2808/>\n",
    "      <n2717/>\n",
    "      <n2722/>\n",
    "    </n2873>\n",
    "    <n2881><![CDATA[zubarevvv]]></n2881>\n",
    "    <n2880>1751894596000</n2880>\n",
    "    <n2813/>\n",
    "    <n30451>1751894596000</n30451>\n",
    "    <n32509 occ=\"6542844\">\n",
    "      <n32514><![CDATA[zubarevvv]]></n32514>\n",
    "      <n32510>1751894702737</n32510>\n",
    "      <n32512><![CDATA[zubarevvv]]></n32512>\n",
    "      <n32513>1751894702737</n32513>\n",
    "      <n32511><![CDATA[На изменение]]></n32511>\n",
    "    </n32509>\n",
    "    <n32509 occ=\"66504512\">\n",
    "      <n32514><![CDATA[zubarevvv]]></n32514>\n",
    "      <n32510>1751896603427</n32510>\n",
    "      <n32512><![CDATA[zubarevvv]]></n32512>\n",
    "      <n32513>1751896603427</n32513>\n",
    "      <n32511><![CDATA[На изменение]]></n32511>\n",
    "    </n32509>\n",
    "    <n39415><![CDATA[Нет]]></n39415>\n",
    "    <n35254>false</n35254>\n",
    "    <n35255/>\n",
    "    <n35256/>\n",
    "    <n35257/>\n",
    "    <n35258/>\n",
    "    <n2833 container=\"Шаблоны Классификатора ТМЦ и услуг\">102168</n2833>\n",
    "    <n35209><![CDATA[<table><tr><td><spaninput_placeholder=\"true\" style=\"height: auto; display: inline-block; overflow: hidden; min-height: 18px;\" tabindex=\"-1\">108»Штука</span></td></tr></table>]]></n35209>\n",
    "    <n2831 occ=\"28307169\">\n",
    "      <n2792/>\n",
    "    </n2831>\n",
    "    <n28397>false</n28397>\n",
    "    <n5402>false</n5402>\n",
    "    <n2849>\n",
    "      <n2727/>\n",
    "      <n2739/>\n",
    "      <n2784/>\n",
    "      <n2708/>\n",
    "      <n2806/>\n",
    "      <n2772/>\n",
    "      <n2774/>\n",
    "    </n2849>\n",
    "    <n5403>false</n5403>\n",
    "    <n52202>false</n52202>\n",
    "    <n52203/>\n",
    "    <n28398/>\n",
    "    <n2878/>\n",
    "    <n2876/>\n",
    "    <n2828/>\n",
    "    <n2890/>\n",
    "    <n27629/>\n",
    "    <n27630/>\n",
    "    <n2863/>\n",
    "    <n2814/>\n",
    "    <n2809/>\n",
    "    <n2875/>\n",
    "    <n2887/>\n",
    "    <n2823/>\n",
    "    <n2885/>\n",
    "    <n2843/>\n",
    "    <n2842/>\n",
    "    <n2839/>\n",
    "    <n28403/>\n",
    "    <n28404/>\n",
    "    <n37430 occ=\"66497823\">\n",
    "      <n37431><![CDATA[758757]]></n37431>\n",
    "    </n37430>\n",
    "    <n28402/>\n",
    "    <n31403>false</n31403>\n",
    "    <n31404>false</n31404>\n",
    "    <n28389 container=\"Балансовые единицы\">486</n28389>\n",
    "    <n31405><![CDATA[L000]]></n31405>\n",
    "    <n28390/>\n",
    "    <n31406/>\n",
    "    <n28391/>\n",
    "    <n28392/>\n",
    "    <n28393/>\n",
    "    <n2834/>\n",
    "    <n2819/>\n",
    "    <n2868 occ=\"66497831\">\n",
    "      <n91271><![CDATA[zubarevvv]]></n91271>\n",
    "      <n2791>1751894596606</n2791>\n",
    "      <n2719>1751894703847</n2719>\n",
    "      <n2777><![CDATA[Горелка[Тип ?][Тип идентификатора ?][Обозначение ?][Чертеж ?]]]></n2777>\n",
    "      <n2751><![CDATA[Горелка[Тип ?][Тип идентификатора ?][Обозначение ?][Чертеж ?]]]></n2751>\n",
    "      <n2712><![CDATA[102168»Горелки теплотехнические]]></n2712>\n",
    "      <n2767 occ=\"66497832\">\n",
    "        <n2695><![CDATA[S3_VID_PRODUKTSII]]></n2695>\n",
    "        <n2690><![CDATA[Горелка]]></n2690>\n",
    "      </n2767>\n",
    "    </n2868>\n",
    "    <n2868 occ=\"6542846\">\n",
    "      <n91271><![CDATA[zubarevvv]]></n91271>\n",
    "      <n2791>1751894703847</n2791>\n",
    "      <n2719>253402214400000</n2719>\n",
    "      <n2777><![CDATA[Горелка газ.ч.ГБ-351.71.080 ВО]]></n2777>\n",
    "      <n2751><![CDATA[Горелка газоваячертежГБ-351.71.080 ВО]]></n2751>\n",
    "      <n2712><![CDATA[102168»Горелки теплотехнические]]></n2712>\n",
    "      <n2767 occ=\"6542847\">\n",
    "        <n2695><![CDATA[S3_VID_PRODUKTSII]]></n2695>\n",
    "        <n2690><![CDATA[Горелка]]></n2690>\n",
    "      </n2767>\n",
    "      <n2767 occ=\"6542848\">\n",
    "        <n2695><![CDATA[S3_TIP]]></n2695>\n",
    "        <n2690><![CDATA[газовая]]></n2690>\n",
    "      </n2767>\n",
    "      <n2767 occ=\"6542849\">\n",
    "        <n2695><![CDATA[S3_TIP_IDENTIFIKATORA]]></n2695>\n",
    "        <n2690><![CDATA[чертеж]]></n2690>\n",
    "      </n2767>\n",
    "      <n2767 occ=\"6542850\">\n",
    "        <n2695><![CDATA[S3_OBOZNACHENIE]]></n2695>\n",
    "        <n2690><![CDATA[-]]></n2690>\n",
    "      </n2767>\n",
    "      <n2767 occ=\"6542851\">\n",
    "        <n2695><![CDATA[S3_CHERTEZH]]></n2695>\n",
    "        <n2690><![CDATA[ГБ-351.71.080 ВО]]></n2690>\n",
    "      </n2767>\n",
    "    </n2868>\n",
    "    <n2818/>\n",
    "    <n89306/>\n",
    "    <n2812/>\n",
    "    <n2816>false</n2816>\n",
    "    <n2850/>\n",
    "    <n56434/>\n",
    "  </s1245>\n",
    "  <s41619>\n",
    "    <n103530><![CDATA[Горелка]]></n103530>\n",
    "    <n103527><![CDATA[газовая]]></n103527>\n",
    "    <n103528><![CDATA[чертеж]]></n103528>\n",
    "    <n103529><![CDATA[-]]></n103529>\n",
    "    <n103526><![CDATA[ГБ-351.71.080 ВО]]></n103526>\n",
    "  </s41619>\n",
    "</entry>\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRACTVALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "def generate_extractvalue_sql(xml_string, alias_df, table_name):\n",
    "    \"\"\"\n",
    "    Генерирует SQL выражения EXTRACTVALUE из XML структуры с алиасами из датафрейма\n",
    "    \"\"\"\n",
    "    \n",
    "    def parse_xml_structure(element, current_path=\"\"):\n",
    "        paths = []\n",
    "        \n",
    "        if current_path:\n",
    "            element_path = f\"{current_path}/{element.tag}\"\n",
    "        else:\n",
    "            element_path = element.tag\n",
    "        \n",
    "        if element.text and element.text.strip():\n",
    "            paths.append(element_path)\n",
    "        \n",
    "        for child in element:\n",
    "            paths.extend(parse_xml_structure(child, element_path))\n",
    "        \n",
    "        return paths\n",
    "    \n",
    "    def get_alias_for_node(node_path):\n",
    "        \"\"\"\n",
    "        Получает алиас для узла из датафрейма с улучшенной обработкой\n",
    "        \"\"\"\n",
    "        # Извлекаем номер узла из последнего элемента пути\n",
    "        node_name = node_path.split('/')[-1]\n",
    "        \n",
    "        # Если узел начинается с 'n', извлекаем номер\n",
    "        if node_name.startswith('n'):\n",
    "            node_id = node_name[1:]  # Убираем 'n' в начале\n",
    "            \n",
    "            print(f\"Ищем алиас для узла: {node_name}, ID: {node_id}\")  # Отладочная информация\n",
    "            \n",
    "            # Проверяем датафрейм\n",
    "            if alias_df is None or alias_df.empty:\n",
    "                print(\"Датафрейм пустой или None\")\n",
    "                return node_name\n",
    "            \n",
    "            # Выводим информацию о датафрейме для отладки\n",
    "            print(f\"Колонки в датафрейме: {alias_df.columns.tolist()}\")\n",
    "            print(f\"Первые 5 строк датафрейма:\")\n",
    "            print(alias_df.head())\n",
    "            \n",
    "            # Преобразуем ID к строковому типу для сравнения\n",
    "            node_id_str = str(node_id)\n",
    "            \n",
    "            # Ищем в датафрейме разными способами\n",
    "            if 'NOD_ID' in alias_df.columns:\n",
    "                # Преобразуем колонку NOD_ID к строковому типу\n",
    "                alias_df['NOD_ID_STR'] = alias_df['NOD_ID'].astype(str)\n",
    "                match = alias_df[alias_df['NOD_ID_STR'] == node_id_str]\n",
    "                \n",
    "                if not match.empty:\n",
    "                    alias_value = match.iloc[0]['NOD_NAME']\n",
    "                    print(f\"Найден алиас: {alias_value}\")\n",
    "                    return alias_value\n",
    "                else:\n",
    "                    print(f\"Алиас не найден для ID: {node_id_str}\")\n",
    "            else:\n",
    "                print(\"Колонка NOD_ID не найдена в датафрейме\")\n",
    "        \n",
    "        return node_name\n",
    "    \n",
    "    try:\n",
    "        # Парсим XML\n",
    "        root = ET.fromstring(xml_string)\n",
    "        \n",
    "        # Получаем все пути к элементам с данными\n",
    "        xml_paths = parse_xml_structure(root)\n",
    "        \n",
    "        # Генерируем SQL выражения\n",
    "        sql_expressions = []\n",
    "        for path in xml_paths:\n",
    "            alias = get_alias_for_node(path)\n",
    "            sql_expr = f\"EXTRACTVALUE({table_name}, '{path}') as {alias}\"\n",
    "            sql_expressions.append(sql_expr)\n",
    "        \n",
    "        # Объединяем в итоговый SQL\n",
    "        sql_code = \",\\n    \".join(sql_expressions)\n",
    "        \n",
    "        return sql_code\n",
    "    \n",
    "    except ET.ParseError as e:\n",
    "        return f\"Ошибка парсинга XML: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"Ошибка: {e}\"\n",
    "\n",
    "# Альтернативная версия с более надежным поиском\n",
    "def generate_extractvalue_sql_advanced(xml_string, alias_df, table_name):\n",
    "    \"\"\"\n",
    "    Улучшенная версия с обработкой различных форматов данных\n",
    "    \"\"\"\n",
    "    \n",
    "    def parse_xml_structure(element, current_path=\"\"):\n",
    "        paths = []\n",
    "        \n",
    "        if current_path:\n",
    "            element_path = f\"{current_path}/{element.tag}\"\n",
    "        else:\n",
    "            element_path = element.tag\n",
    "        \n",
    "        if element.text and element.text.strip():\n",
    "            paths.append(element_path)\n",
    "        \n",
    "        for child in element:\n",
    "            paths.extend(parse_xml_structure(child, element_path))\n",
    "        \n",
    "        return paths\n",
    "    \n",
    "    def get_alias_for_node(node_path):\n",
    "        node_name = node_path.split('/')[-1]\n",
    "        \n",
    "        if node_name.startswith('n'):\n",
    "            node_id = node_name[1:]\n",
    "            \n",
    "            # Создаем копию датафрейма для безопасной работы\n",
    "            df = alias_df.copy()\n",
    "            \n",
    "            # Приводим все к строковому типу для сравнения\n",
    "            node_id_str = str(node_id).strip()\n",
    "            \n",
    "            # Пробуем разные варианты поиска\n",
    "            if 'NOD_ID' in df.columns:\n",
    "                # Вариант 1: прямое сравнение строк\n",
    "                df['NOD_ID_STR'] = df['NOD_ID'].astype(str).str.strip()\n",
    "                match = df[df['NOD_ID_STR'] == node_id_str]\n",
    "                \n",
    "                if not match.empty:\n",
    "                    return match.iloc[0]['NOD_NAME']\n",
    "                \n",
    "                # Вариант 2: поиск по числовому значению (если ID числа)\n",
    "                try:\n",
    "                    node_id_int = int(node_id)\n",
    "                    if 'NOD_ID' in df.columns:\n",
    "                        numeric_match = df[df['NOD_ID'] == node_id_int]\n",
    "                        if not numeric_match.empty:\n",
    "                            return numeric_match.iloc[0]['NOD_NAME']\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                \n",
    "                # Вариант 3: поиск по частичному совпадению\n",
    "                partial_match = df[df['NOD_ID_STR'].str.contains(node_id_str, na=False)]\n",
    "                if not partial_match.empty:\n",
    "                    return partial_match.iloc[0]['NOD_NAME']\n",
    "        \n",
    "        return node_name\n",
    "    \n",
    "    try:\n",
    "        root = ET.fromstring(xml_string)\n",
    "        xml_paths = parse_xml_structure(root)\n",
    "        \n",
    "        sql_expressions = []\n",
    "        for path in xml_paths:\n",
    "            alias = get_alias_for_node(path)\n",
    "            sql_expr = f\"EXTRACTVALUE({table_name}, '{path}') as {alias}\"\n",
    "            sql_expressions.append(sql_expr)\n",
    "        \n",
    "        return \",\\n    \".join(sql_expressions)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Ошибка: {e}\"\n",
    "\n",
    "# Функция для диагностики датафрейма\n",
    "def diagnose_dataframe(df, name=\"alias_df\"):\n",
    "    print(f\"\\n=== ДИАГНОСТИКА ДАТАФРЕЙМА {name} ===\")\n",
    "    print(f\"Размер: {df.shape}\")\n",
    "    print(f\"Колонки: {df.columns.tolist()}\")\n",
    "    print(f\"Типы данных:\")\n",
    "    print(df.dtypes)\n",
    "    print(f\"Первые 10 строк:\")\n",
    "    print(df.head(10))\n",
    "    print(f\"Уникальные значения NOD_ID: {df['NOD_ID'].unique()[:10] if 'NOD_ID' in df.columns else 'Колонка не найдена'}\")\n",
    "    print(\"====================\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ДИАГНОСТИКА ДАТАФРЕЙМА alias_df ===\n",
      "Размер: (82796, 2)\n",
      "Колонки: ['NOD_ID', 'NOD_NAME']\n",
      "Типы данных:\n",
      "NOD_ID      object\n",
      "NOD_NAME    object\n",
      "dtype: object\n",
      "Первые 10 строк:\n",
      "  NOD_ID            NOD_NAME\n",
      "0   1456  DISPLAY_NAME_ro_RO\n",
      "1   1457  DISPLAY_NAME_be_BY\n",
      "2   1458  DISPLAY_NAME_it_IT\n",
      "3   1459          NAME_ro_MD\n",
      "4   1460          NAME_en_US\n",
      "5   1461  DISPLAY_NAME_sr_RS\n",
      "6   1462          NAME_sr_RS\n",
      "7   1463          NAME_be_BY\n",
      "8   1464  DISPLAY_NAME_en_US\n",
      "9   1465            TAX_TYPE\n",
      "Уникальные значения NOD_ID: [1456 1457 1458 1459 1460 1461 1462 1463 1464 1465]\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "        # Пример загрузки из Excel\n",
    "    alias_df = pd.read_excel('attributes.xlsx')  # укажите ваш путь к файлу\n",
    "        # или из CSV\n",
    "        # alias_df = pd.read_csv('your_file.csv')\n",
    "        \n",
    "        # Диагностика датафрейма\n",
    "    diagnose_dataframe(alias_df)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Ошибка загрузки датафрейма: {e}\")\n",
    "        # Создаем тестовый датафрейм для демонстрации\n",
    "    alias_data = {\n",
    "            'NOD_ID': [1903, 1890, 1913, 1905, 1908, 1914, 1896],\n",
    "            'NOD_NAME': [\n",
    "                'DISPLAY_NAME/ro_RO',\n",
    "                'DISPLAY_NAME/be_BY', \n",
    "                'COUNTRY_NAME',\n",
    "                'REGION_INFO',\n",
    "                'IS_ACTIVE_FLAG',\n",
    "                'IS_VALID_FLAG',\n",
    "                'DISPLAY_NAME_RU'\n",
    "            ]\n",
    "        }\n",
    "    alias_df = pd.DataFrame(alias_data)\n",
    "    print(\"Используется тестовый датафрейм\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сгенерированный SQL код:\n",
      "EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2821') as CSCD_ID,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2870') as CSCD_ID_SEQUENCE,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2889') as ATTENTION_FLAG,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2864') as GENERATE_NAMES,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2874/n2754') as SHORT_NAME_ru_RU,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2815') as AUTO_SHORT_NAME,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2832') as PATTERN_SHORT_NAME,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2860/n2766') as FULL_NAME_ru_RU,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2869') as AUTO_FULL_NAME,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2845') as PATTERN_FULL_NAME,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2851') as BASE_UNIT,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2872') as LUKOIL_MATERIAL,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2853') as TMC_Stat,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2884') as TMC_Type,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2846') as EXCISE_GROUP,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n28401') as BRAND_OIL,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2888') as SIP_CODE,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n34306') as TRU,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2822') as COST_GROUP,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n5404') as TYPE_ACTIVITY,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n5724/n5759') as CONTROLLED_PRODUCTS_IS_CONTROLLED_PRODUCTS,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n5724/n5758') as CONTROLLED_PRODUCTS_CONTROLLED_PRODUCTS_DATE_FROM,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n5724/n5757') as CONTROLLED_PRODUCTS_CONTROLLED_PRODUCTS_DATE_TO,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n51402') as ACTUAL_MATERIAL_TRACEABILITY,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2811/n2783') as MATERIAL_TRACEABILITY_MATERIAL_TRACEABILITY,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2811/n2709') as MATERIAL_TRACEABILITY_TRACEABILITY_DATE_FROM,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2811/n2746') as MATERIAL_TRACEABILITY_TRACEABILITY_DATE_TO,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2865') as USER_SEGMENT,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2865') as USER_SEGMENT,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2865') as USER_SEGMENT,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2841') as ACTUAL_TAX_VALUE,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2855') as IS_RAW_MATERIAL,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n91305') as NO_SALE_MINOR,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2820') as IS_TMBT_MATERIAL,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n30449') as comments,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2873/n2788') as DISPLAY_NAME_ru_RU,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2881') as Item_creator,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2880') as Item_creation_date,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n30451') as TaskCreator_Date,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n32509/n32514') as Change_history_User_changed,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n32509/n32510') as Change_history_Date_changed,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n32509/n32512') as Change_history_Redactor,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n32509/n32513') as Change_history_Date_redactor,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n32509/n32511') as Change_history_Change_Type,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n32509/n32514') as Change_history_User_changed,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n32509/n32510') as Change_history_Date_changed,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n32509/n32512') as Change_history_Redactor,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n32509/n32513') as Change_history_Date_redactor,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n32509/n32511') as Change_history_Change_Type,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n39415') as Promptness,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n35254') as Promptness_S,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2833') as PATTERN,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n35209') as PATTERN_BASE_UNIT,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n28397') as SALE_MATERIAL,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n5402') as FRANCHISED_MATERIAL,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n5403') as EXCISE_GOODS_IN_CHECK,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n52202') as MAIN_PRODUCT,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n37430/n37431') as LIKARD_LOCAL_ATTRIBUTES_LIKARD_ID,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n31403') as IS_USED,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n31404') as REAGENT_FOR_EXTRACTION,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n28389') as BALANCE_UNITS_NGDO,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n31405') as BALANCE_UNITS_NGDO_OLD_APPLIED_CODE,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n91271') as History_Property_User_Changed,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2791') as History_Property_Date_Begin,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2719') as History_Property_Date_End,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2777') as History_Property_NameShort_Auto,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2751') as History_Property_NameFull_Auto,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2712') as History_Property_Pattern,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2767/n2695') as History_Property_Property_Property_Name,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2767/n2690') as History_Property_Property_Property_Value,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n91271') as History_Property_User_Changed,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2791') as History_Property_Date_Begin,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2719') as History_Property_Date_End,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2777') as History_Property_NameShort_Auto,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2751') as History_Property_NameFull_Auto,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2712') as History_Property_Pattern,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2767/n2695') as History_Property_Property_Property_Name,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2767/n2690') as History_Property_Property_Property_Value,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2767/n2695') as History_Property_Property_Property_Name,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2767/n2690') as History_Property_Property_Property_Value,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2767/n2695') as History_Property_Property_Property_Name,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2767/n2690') as History_Property_Property_Property_Value,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2767/n2695') as History_Property_Property_Property_Name,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2767/n2690') as History_Property_Property_Property_Value,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2767/n2695') as History_Property_Property_Property_Name,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2868/n2767/n2690') as History_Property_Property_Property_Value,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s1245/n2816') as ISDOUBLE,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s41619/n103530') as S3_VID_PRODUKTSII,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s41619/n103527') as S3_TIP,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s41619/n103528') as S3_TIP_IDENTIFIKATORA,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s41619/n103529') as S3_OBOZNACHENIE,\n",
      "    EXTRACTVALUE(itx_entry_content, 'entry/s41619/n103526') as S3_CHERTEZH\n"
     ]
    }
   ],
   "source": [
    "# Пример использования с реальным датафреймом\n",
    "if __name__ == \"__main__\":\n",
    "      \n",
    "    table_name = \"itx_entry_content\"\n",
    "    \n",
    "    # Используем улучшенную версию\n",
    "    sql_result = generate_extractvalue_sql_advanced(xml_example, alias_df, table_name)\n",
    "    \n",
    "    print(\"Сгенерированный SQL код:\")\n",
    "    print(sql_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML TABLE (простой)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def generate_simple_indexed_xmltable(xml_string, alias_df, table_name, xml_column_name='itx_entry_content'):\n",
    "    \"\"\"\n",
    "    Упрощенная версия с принудительным добавлением индексов [1] ко всем узлам\n",
    "    \"\"\"\n",
    "    \n",
    "    def parse_all_text_nodes(element, current_path=\"\"):\n",
    "        \"\"\"\n",
    "        Находит все текстовые узлы в XML\n",
    "        \"\"\"\n",
    "        nodes = []\n",
    "        \n",
    "        if current_path:\n",
    "            element_path = f\"{current_path}/{element.tag}\"\n",
    "        else:\n",
    "            element_path = element.tag\n",
    "        \n",
    "        if element.text and element.text.strip():\n",
    "            nodes.append(element_path)\n",
    "        \n",
    "        for child in element:\n",
    "            nodes.extend(parse_all_text_nodes(child, element_path))\n",
    "        \n",
    "        return nodes\n",
    "    \n",
    "    def get_unique_alias_simple(node_path, alias_counter):\n",
    "        \"\"\"\n",
    "        Создает уникальный алиас для узла\n",
    "        \"\"\"\n",
    "        node_name = node_path.split('/')[-1]\n",
    "        \n",
    "        if node_name.startswith('n'):\n",
    "            node_id = node_name[1:]\n",
    "            node_id_str = str(node_id).strip()\n",
    "            \n",
    "            if alias_df is not None and not alias_df.empty and 'NOD_ID' in alias_df.columns and 'NOD_NAME' in alias_df.columns:\n",
    "                df = alias_df.copy()\n",
    "                df['NOD_ID_STR'] = df['NOD_ID'].astype(str).str.strip()\n",
    "                match = df[df['NOD_ID_STR'] == node_id_str]\n",
    "                \n",
    "                if not match.empty:\n",
    "                    base_alias = match.iloc[0]['NOD_NAME']\n",
    "                else:\n",
    "                    base_alias = node_name\n",
    "            else:\n",
    "                base_alias = node_name\n",
    "        else:\n",
    "            base_alias = node_name\n",
    "        \n",
    "        # Учитываем повторения\n",
    "        alias_counter[base_alias] += 1\n",
    "        count = alias_counter[base_alias]\n",
    "        \n",
    "        if count > 1:\n",
    "            return f\"{base_alias}_{count}\"\n",
    "        return base_alias\n",
    "    \n",
    "    def add_indexes_to_xpath(xpath):\n",
    "        \"\"\"\n",
    "        Добавляет индексы [1] ко всем узлам в XPath\n",
    "        \"\"\"\n",
    "        parts = xpath.split('/')\n",
    "        indexed_parts = []\n",
    "        \n",
    "        for part in parts:\n",
    "            if part and '[' not in part and ']' not in part:\n",
    "                indexed_parts.append(f\"{part}[1]\")\n",
    "            else:\n",
    "                indexed_parts.append(part)\n",
    "        \n",
    "        return '/'.join(indexed_parts)\n",
    "    \n",
    "    try:\n",
    "        root = ET.fromstring(xml_string)\n",
    "        all_paths = parse_all_text_nodes(root)\n",
    "        \n",
    "        alias_counter = defaultdict(int)\n",
    "        column_definitions = []\n",
    "        \n",
    "        for path in all_paths:\n",
    "            relative_path = '/'.join(path.split('/')[1:])  # Убираем 'entry'\n",
    "            indexed_xpath = add_indexes_to_xpath(relative_path)\n",
    "            alias = get_unique_alias_simple(path, alias_counter)\n",
    "            \n",
    "            column_def = f\"        {alias} VARCHAR2(4000) PATH '{indexed_xpath}'\"\n",
    "            column_definitions.append(column_def)\n",
    "        \n",
    "        sql_code = f\"\"\"SELECT\n",
    "    itx_entry_id,\n",
    "    x.*\n",
    "FROM {table_name} t,\n",
    "XMLTABLE(\n",
    "    '/entry' PASSING t.{xml_column_name}\n",
    "    COLUMNS\n",
    "{',\\n'.join(column_definitions)}\n",
    ") x\n",
    "WHERE t.itx_container_id = '1839'\n",
    "FETCH FIRST 100 ROWS ONLY;\"\"\"\n",
    "        \n",
    "        return sql_code\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Ошибка: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== УПРОЩЕННАЯ ВЕРСИЯ С [1] ДЛЯ ВСЕХ УЗЛОВ ===\n",
      "SELECT\n",
      "    itx_entry_id,\n",
      "    x.*\n",
      "FROM tctg_itx_item_content t,\n",
      "XMLTABLE(\n",
      "    '/entry' PASSING t.itx_entry_content\n",
      "    COLUMNS\n",
      "        CSCD_ID VARCHAR2(4000) PATH 's1245[1]/n2821[1]',\n",
      "        CSCD_ID_SEQUENCE VARCHAR2(4000) PATH 's1245[1]/n2870[1]',\n",
      "        ATTENTION_FLAG VARCHAR2(4000) PATH 's1245[1]/n2889[1]',\n",
      "        GENERATE_NAMES VARCHAR2(4000) PATH 's1245[1]/n2864[1]',\n",
      "        SHORT_NAME_ru_RU VARCHAR2(4000) PATH 's1245[1]/n2874[1]/n2754[1]',\n",
      "        AUTO_SHORT_NAME VARCHAR2(4000) PATH 's1245[1]/n2815[1]',\n",
      "        PATTERN_SHORT_NAME VARCHAR2(4000) PATH 's1245[1]/n2832[1]',\n",
      "        FULL_NAME_ru_RU VARCHAR2(4000) PATH 's1245[1]/n2860[1]/n2766[1]',\n",
      "        AUTO_FULL_NAME VARCHAR2(4000) PATH 's1245[1]/n2869[1]',\n",
      "        PATTERN_FULL_NAME VARCHAR2(4000) PATH 's1245[1]/n2845[1]',\n",
      "        BASE_UNIT VARCHAR2(4000) PATH 's1245[1]/n2851[1]',\n",
      "        LUKOIL_MATERIAL VARCHAR2(4000) PATH 's1245[1]/n2872[1]',\n",
      "        TMC_Stat VARCHAR2(4000) PATH 's1245[1]/n2853[1]',\n",
      "        TMC_Type VARCHAR2(4000) PATH 's1245[1]/n2884[1]',\n",
      "        EXCISE_GROUP VARCHAR2(4000) PATH 's1245[1]/n2846[1]',\n",
      "        BRAND_OIL VARCHAR2(4000) PATH 's1245[1]/n28401[1]',\n",
      "        SIP_CODE VARCHAR2(4000) PATH 's1245[1]/n2888[1]',\n",
      "        TRU VARCHAR2(4000) PATH 's1245[1]/n34306[1]',\n",
      "        COST_GROUP VARCHAR2(4000) PATH 's1245[1]/n2822[1]',\n",
      "        TYPE_ACTIVITY VARCHAR2(4000) PATH 's1245[1]/n5404[1]',\n",
      "        CONTROLLED_PRODUCTS_IS_CONTROLLED_PRODUCTS VARCHAR2(4000) PATH 's1245[1]/n5724[1]/n5759[1]',\n",
      "        CONTROLLED_PRODUCTS_CONTROLLED_PRODUCTS_DATE_FROM VARCHAR2(4000) PATH 's1245[1]/n5724[1]/n5758[1]',\n",
      "        CONTROLLED_PRODUCTS_CONTROLLED_PRODUCTS_DATE_TO VARCHAR2(4000) PATH 's1245[1]/n5724[1]/n5757[1]',\n",
      "        ACTUAL_MATERIAL_TRACEABILITY VARCHAR2(4000) PATH 's1245[1]/n51402[1]',\n",
      "        MATERIAL_TRACEABILITY_MATERIAL_TRACEABILITY VARCHAR2(4000) PATH 's1245[1]/n2811[1]/n2783[1]',\n",
      "        MATERIAL_TRACEABILITY_TRACEABILITY_DATE_FROM VARCHAR2(4000) PATH 's1245[1]/n2811[1]/n2709[1]',\n",
      "        MATERIAL_TRACEABILITY_TRACEABILITY_DATE_TO VARCHAR2(4000) PATH 's1245[1]/n2811[1]/n2746[1]',\n",
      "        USER_SEGMENT VARCHAR2(4000) PATH 's1245[1]/n2865[1]',\n",
      "        USER_SEGMENT_2 VARCHAR2(4000) PATH 's1245[1]/n2865[1]',\n",
      "        USER_SEGMENT_3 VARCHAR2(4000) PATH 's1245[1]/n2865[1]',\n",
      "        ACTUAL_TAX_VALUE VARCHAR2(4000) PATH 's1245[1]/n2841[1]',\n",
      "        IS_RAW_MATERIAL VARCHAR2(4000) PATH 's1245[1]/n2855[1]',\n",
      "        NO_SALE_MINOR VARCHAR2(4000) PATH 's1245[1]/n91305[1]',\n",
      "        IS_TMBT_MATERIAL VARCHAR2(4000) PATH 's1245[1]/n2820[1]',\n",
      "        comments VARCHAR2(4000) PATH 's1245[1]/n30449[1]',\n",
      "        DISPLAY_NAME_ru_RU VARCHAR2(4000) PATH 's1245[1]/n2873[1]/n2788[1]',\n",
      "        Item_creator VARCHAR2(4000) PATH 's1245[1]/n2881[1]',\n",
      "        Item_creation_date VARCHAR2(4000) PATH 's1245[1]/n2880[1]',\n",
      "        TaskCreator_Date VARCHAR2(4000) PATH 's1245[1]/n30451[1]',\n",
      "        Change_history_User_changed VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32514[1]',\n",
      "        Change_history_Date_changed VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32510[1]',\n",
      "        Change_history_Redactor VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32512[1]',\n",
      "        Change_history_Date_redactor VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32513[1]',\n",
      "        Change_history_Change_Type VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32511[1]',\n",
      "        Change_history_User_changed_2 VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32514[1]',\n",
      "        Change_history_Date_changed_2 VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32510[1]',\n",
      "        Change_history_Redactor_2 VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32512[1]',\n",
      "        Change_history_Date_redactor_2 VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32513[1]',\n",
      "        Change_history_Change_Type_2 VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32511[1]',\n",
      "        Promptness VARCHAR2(4000) PATH 's1245[1]/n39415[1]',\n",
      "        Promptness_S VARCHAR2(4000) PATH 's1245[1]/n35254[1]',\n",
      "        PATTERN VARCHAR2(4000) PATH 's1245[1]/n2833[1]',\n",
      "        PATTERN_BASE_UNIT VARCHAR2(4000) PATH 's1245[1]/n35209[1]',\n",
      "        SALE_MATERIAL VARCHAR2(4000) PATH 's1245[1]/n28397[1]',\n",
      "        FRANCHISED_MATERIAL VARCHAR2(4000) PATH 's1245[1]/n5402[1]',\n",
      "        EXCISE_GOODS_IN_CHECK VARCHAR2(4000) PATH 's1245[1]/n5403[1]',\n",
      "        MAIN_PRODUCT VARCHAR2(4000) PATH 's1245[1]/n52202[1]',\n",
      "        LIKARD_LOCAL_ATTRIBUTES_LIKARD_ID VARCHAR2(4000) PATH 's1245[1]/n37430[1]/n37431[1]',\n",
      "        IS_USED VARCHAR2(4000) PATH 's1245[1]/n31403[1]',\n",
      "        REAGENT_FOR_EXTRACTION VARCHAR2(4000) PATH 's1245[1]/n31404[1]',\n",
      "        BALANCE_UNITS_NGDO VARCHAR2(4000) PATH 's1245[1]/n28389[1]',\n",
      "        BALANCE_UNITS_NGDO_OLD_APPLIED_CODE VARCHAR2(4000) PATH 's1245[1]/n31405[1]',\n",
      "        History_Property_User_Changed VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n91271[1]',\n",
      "        History_Property_Date_Begin VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2791[1]',\n",
      "        History_Property_Date_End VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2719[1]',\n",
      "        History_Property_NameShort_Auto VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2777[1]',\n",
      "        History_Property_NameFull_Auto VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2751[1]',\n",
      "        History_Property_Pattern VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2712[1]',\n",
      "        History_Property_Property_Property_Name VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2695[1]',\n",
      "        History_Property_Property_Property_Value VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2690[1]',\n",
      "        History_Property_User_Changed_2 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n91271[1]',\n",
      "        History_Property_Date_Begin_2 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2791[1]',\n",
      "        History_Property_Date_End_2 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2719[1]',\n",
      "        History_Property_NameShort_Auto_2 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2777[1]',\n",
      "        History_Property_NameFull_Auto_2 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2751[1]',\n",
      "        History_Property_Pattern_2 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2712[1]',\n",
      "        History_Property_Property_Property_Name_2 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2695[1]',\n",
      "        History_Property_Property_Property_Value_2 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2690[1]',\n",
      "        History_Property_Property_Property_Name_3 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2695[1]',\n",
      "        History_Property_Property_Property_Value_3 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2690[1]',\n",
      "        History_Property_Property_Property_Name_4 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2695[1]',\n",
      "        History_Property_Property_Property_Value_4 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2690[1]',\n",
      "        History_Property_Property_Property_Name_5 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2695[1]',\n",
      "        History_Property_Property_Property_Value_5 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2690[1]',\n",
      "        History_Property_Property_Property_Name_6 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2695[1]',\n",
      "        History_Property_Property_Property_Value_6 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2690[1]',\n",
      "        ISDOUBLE VARCHAR2(4000) PATH 's1245[1]/n2816[1]',\n",
      "        S3_VID_PRODUKTSII VARCHAR2(4000) PATH 's41619[1]/n103530[1]',\n",
      "        S3_TIP VARCHAR2(4000) PATH 's41619[1]/n103527[1]',\n",
      "        S3_TIP_IDENTIFIKATORA VARCHAR2(4000) PATH 's41619[1]/n103528[1]',\n",
      "        S3_OBOZNACHENIE VARCHAR2(4000) PATH 's41619[1]/n103529[1]',\n",
      "        S3_CHERTEZH VARCHAR2(4000) PATH 's41619[1]/n103526[1]'\n",
      ") x\n",
      "WHERE t.itx_container_id = '1839'\n",
      "FETCH FIRST 100 ROWS ONLY;\n"
     ]
    }
   ],
   "source": [
    "# Пример использования с XML, содержащим повторяющиеся узлы\n",
    "if __name__ == \"__main__\":\n",
    "   \n",
    "    \n",
    "    table_name = \"tctg_itx_item_content\"\n",
    "    \n",
    "    \n",
    "    print(\"=== УПРОЩЕННАЯ ВЕРСИЯ С [1] ДЛЯ ВСЕХ УЗЛОВ ===\")\n",
    "    sql2 = generate_simple_indexed_xmltable(xml_example, alias_df, table_name)\n",
    "    print(sql2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML TABLE (с индексами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def generate_xmltable_with_forced_indexes(xml_string, alias_df, table_name, xml_column_name='itx_entry_content'):\n",
    "    \"\"\"\n",
    "    Генерирует SQL с принудительным добавлением индексов ко всем узлам\n",
    "    \"\"\"\n",
    "    \n",
    "    def parse_xml_with_counts(element, current_path=\"\", level=0):\n",
    "        \"\"\"\n",
    "        Парсит XML и подсчитывает количество одинаковых узлов на каждом уровне\n",
    "        \"\"\"\n",
    "        nodes = []\n",
    "        \n",
    "        if current_path:\n",
    "            element_path = f\"{current_path}/{element.tag}\"\n",
    "        else:\n",
    "            element_path = element.tag\n",
    "        \n",
    "        # Добавляем текущий узел если есть текст\n",
    "        if element.text and element.text.strip():\n",
    "            nodes.append({\n",
    "                'path': element_path,\n",
    "                'tag': element.tag,\n",
    "                'level': level\n",
    "            })\n",
    "        \n",
    "        # Рекурсивно обрабатываем детей\n",
    "        for child in element:\n",
    "            nodes.extend(parse_xml_with_counts(child, element_path, level + 1))\n",
    "        \n",
    "        return nodes\n",
    "    \n",
    "    def count_node_occurrences(nodes):\n",
    "        \"\"\"\n",
    "        Подсчитывает количество вхождений каждого узла на каждом уровне пути\n",
    "        \"\"\"\n",
    "        # Словарь для подсчета: {уровень: {тег: количество}}\n",
    "        level_counts = defaultdict(lambda: defaultdict(int))\n",
    "        # Словарь для позиций: {полный_путь: позиция}\n",
    "        node_positions = {}\n",
    "        \n",
    "        for node in nodes:\n",
    "            path_parts = node['path'].split('/')\n",
    "            \n",
    "            # Подсчитываем вхождения на каждом уровне\n",
    "            current_path = \"\"\n",
    "            for i, part in enumerate(path_parts):\n",
    "                if current_path:\n",
    "                    current_path = f\"{current_path}/{part}\"\n",
    "                else:\n",
    "                    current_path = part\n",
    "                \n",
    "                level_counts[i][part] += 1\n",
    "            \n",
    "            # Определяем позицию для конечного узла\n",
    "            parent_path = '/'.join(path_parts[:-1])\n",
    "            tag = path_parts[-1]\n",
    "            \n",
    "            # Считаем сколько раз этот тег встречается под этим родителем\n",
    "            siblings_count = sum(1 for n in nodes \n",
    "                               if n['path'].startswith(parent_path + '/') \n",
    "                               and n['path'].split('/')[-1] == tag)\n",
    "            \n",
    "            if siblings_count > 1:\n",
    "                # Определяем позицию этого узла среди siblings\n",
    "                siblings = [n for n in nodes \n",
    "                           if n['path'].startswith(parent_path + '/') \n",
    "                           and n['path'].split('/')[-1] == tag]\n",
    "                \n",
    "                position = 1\n",
    "                for sibling in siblings:\n",
    "                    if sibling['path'] == node['path']:\n",
    "                        node_positions[node['path']] = position\n",
    "                        break\n",
    "                    position += 1\n",
    "            else:\n",
    "                node_positions[node['path']] = 1\n",
    "        \n",
    "        return level_counts, node_positions\n",
    "    \n",
    "    def build_indexed_xpath(node_path, node_positions, level_counts):\n",
    "        \"\"\"\n",
    "        Строит XPath с индексами для всех узлов\n",
    "        \"\"\"\n",
    "        path_parts = node_path.split('/')[1:]  # Убираем корневой элемент\n",
    "        \n",
    "        indexed_parts = []\n",
    "        current_path = \"\"\n",
    "        \n",
    "        for i, part in enumerate(path_parts):\n",
    "            # Строим путь до текущего уровня\n",
    "            if current_path:\n",
    "                current_path = f\"{current_path}/{part}\"\n",
    "            else:\n",
    "                current_path = part\n",
    "            \n",
    "            # Проверяем, нужно ли добавлять индекс\n",
    "            if level_counts[i+1][part] > 1:  # i+1 потому что убрали корневой элемент\n",
    "                # Находим позицию этого узла\n",
    "                position = 1\n",
    "                # Ищем все узлы с таким же путем до этого уровня\n",
    "                for path, pos in node_positions.items():\n",
    "                    if path.startswith(current_path) or path == current_path:\n",
    "                        if path.split('/')[-1] == part:\n",
    "                            if path == node_path:\n",
    "                                indexed_parts.append(f\"{part}[{position}]\")\n",
    "                                break\n",
    "                            position += 1\n",
    "            else:\n",
    "                indexed_parts.append(part)\n",
    "        \n",
    "        return '/'.join(indexed_parts)\n",
    "    \n",
    "    def get_unique_alias(node_info, alias_counter):\n",
    "        \"\"\"\n",
    "        Создает уникальный алиас для узла\n",
    "        \"\"\"\n",
    "        node_name = node_info['tag']\n",
    "        \n",
    "        if node_name.startswith('n'):\n",
    "            node_id = node_name[1:]\n",
    "            node_id_str = str(node_id).strip()\n",
    "            \n",
    "            if alias_df is not None and not alias_df.empty and 'NOD_ID' in alias_df.columns and 'NOD_NAME' in alias_df.columns:\n",
    "                df = alias_df.copy()\n",
    "                df['NOD_ID_STR'] = df['NOD_ID'].astype(str).str.strip()\n",
    "                match = df[df['NOD_ID_STR'] == node_id_str]\n",
    "                \n",
    "                if not match.empty:\n",
    "                    base_alias = match.iloc[0]['NOD_NAME']\n",
    "                else:\n",
    "                    base_alias = node_name\n",
    "            else:\n",
    "                base_alias = node_name\n",
    "        else:\n",
    "            base_alias = node_name\n",
    "        \n",
    "        # Учитываем повторения алиасов\n",
    "        alias_counter[base_alias] += 1\n",
    "        count = alias_counter[base_alias]\n",
    "        \n",
    "        if count > 1:\n",
    "            return f\"{base_alias}_{count}\"\n",
    "        return base_alias\n",
    "    \n",
    "    try:\n",
    "        root = ET.fromstring(xml_string)\n",
    "        all_nodes = parse_xml_with_counts(root)\n",
    "        \n",
    "        # Подсчитываем вхождения узлов\n",
    "        level_counts, node_positions = count_node_occurrences(all_nodes)\n",
    "        \n",
    "        # Создаем колонки\n",
    "        alias_counter = defaultdict(int)\n",
    "        column_definitions = []\n",
    "        \n",
    "        for node in all_nodes:\n",
    "            alias = get_unique_alias(node, alias_counter)\n",
    "            xpath = build_indexed_xpath(node['path'], node_positions, level_counts)\n",
    "            \n",
    "            column_def = f\"        {alias} VARCHAR2(4000) PATH '{xpath}'\"\n",
    "            column_definitions.append(column_def)\n",
    "        \n",
    "        sql_code = f\"\"\"SELECT\n",
    "    itx_entry_id,\n",
    "    x.*\n",
    "FROM {table_name} t,\n",
    "XMLTABLE(\n",
    "    '/entry' PASSING t.{xml_column_name}\n",
    "    COLUMNS\n",
    "{',\\n'.join(column_definitions)}\n",
    ") x\n",
    "WHERE t.itx_container_id = '1839'\n",
    "FETCH FIRST 100 ROWS ONLY;\"\"\"\n",
    "        \n",
    "        return sql_code\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Ошибка: {e}\"\n",
    "\n",
    "def generate_xmltable_simple_force_indexes(xml_string, alias_df, table_name, xml_column_name='itx_entry_content'):\n",
    "    \"\"\"\n",
    "    Простая версия с принудительными индексами [1] для всех узлов\n",
    "    \"\"\"\n",
    "    \n",
    "    def parse_all_nodes(element, current_path=\"\"):\n",
    "        \"\"\"\n",
    "        Находит все узлы с текстом\n",
    "        \"\"\"\n",
    "        nodes = []\n",
    "        \n",
    "        if current_path:\n",
    "            element_path = f\"{current_path}/{element.tag}\"\n",
    "        else:\n",
    "            element_path = element.tag\n",
    "        \n",
    "        if element.text and element.text.strip():\n",
    "            nodes.append(element_path)\n",
    "        \n",
    "        for child in element:\n",
    "            nodes.extend(parse_all_nodes(child, element_path))\n",
    "        \n",
    "        return nodes\n",
    "    \n",
    "    def get_unique_alias_simple(node_path, alias_counter):\n",
    "        \"\"\"\n",
    "        Создает уникальный алиас\n",
    "        \"\"\"\n",
    "        node_name = node_path.split('/')[-1]\n",
    "        \n",
    "        if node_name.startswith('n'):\n",
    "            node_id = node_name[1:]\n",
    "            node_id_str = str(node_id).strip()\n",
    "            \n",
    "            if alias_df is not None and not alias_df.empty and 'NOD_ID' in alias_df.columns and 'NOD_NAME' in alias_df.columns:\n",
    "                df = alias_df.copy()\n",
    "                df['NOD_ID_STR'] = df['NOD_ID'].astype(str).str.strip()\n",
    "                match = df[df['NOD_ID_STR'] == node_id_str]\n",
    "                \n",
    "                if not match.empty:\n",
    "                    base_alias = match.iloc[0]['NOD_NAME']\n",
    "                else:\n",
    "                    base_alias = node_name\n",
    "            else:\n",
    "                base_alias = node_name\n",
    "        else:\n",
    "            base_alias = node_name\n",
    "        \n",
    "        alias_counter[base_alias] += 1\n",
    "        count = alias_counter[base_alias]\n",
    "        \n",
    "        if count > 1:\n",
    "            return f\"{base_alias}_{count}\"\n",
    "        return base_alias\n",
    "    \n",
    "    def add_force_indexes(xpath):\n",
    "        \"\"\"\n",
    "        Добавляет [1] ко всем узлам в пути\n",
    "        \"\"\"\n",
    "        parts = xpath.split('/')\n",
    "        indexed_parts = []\n",
    "        \n",
    "        for part in parts:\n",
    "            if part and not part.endswith(']'):\n",
    "                indexed_parts.append(f\"{part}[1]\")\n",
    "            else:\n",
    "                indexed_parts.append(part)\n",
    "        \n",
    "        return '/'.join(indexed_parts)\n",
    "    \n",
    "    try:\n",
    "        root = ET.fromstring(xml_string)\n",
    "        all_paths = parse_all_nodes(root)\n",
    "        \n",
    "        # Группируем пути по их базовому пути (без индексов)\n",
    "        path_groups = defaultdict(list)\n",
    "        for path in all_paths:\n",
    "            # Извлекаем базовый путь без учета потенциальных индексов\n",
    "            base_path = '/'.join(part.split('[')[0] for part in path.split('/'))\n",
    "            path_groups[base_path].append(path)\n",
    "        \n",
    "        alias_counter = defaultdict(int)\n",
    "        column_definitions = []\n",
    "        \n",
    "        # Обрабатываем каждую группу путей\n",
    "        for base_path, paths in path_groups.items():\n",
    "            if len(paths) == 1:\n",
    "                # Один путь в группе\n",
    "                relative_path = '/'.join(paths[0].split('/')[1:])\n",
    "                indexed_xpath = add_force_indexes(relative_path)\n",
    "                alias = get_unique_alias_simple(paths[0], alias_counter)\n",
    "                column_def = f\"        {alias} VARCHAR2(4000) PATH '{indexed_xpath}'\"\n",
    "                column_definitions.append(column_def)\n",
    "            else:\n",
    "                # Несколько путей в группе - добавляем индексы\n",
    "                for i, path in enumerate(paths, 1):\n",
    "                    relative_path = '/'.join(path.split('/')[1:])\n",
    "                    # Заменяем последний элемент на версию с индексом\n",
    "                    parts = relative_path.split('/')\n",
    "                    parts[-1] = f\"{parts[-1].split('[')[0]}[{i}]\"\n",
    "                    indexed_xpath = add_force_indexes('/'.join(parts))\n",
    "                    alias = get_unique_alias_simple(path, alias_counter)\n",
    "                    column_def = f\"        {alias} VARCHAR2(4000) PATH '{indexed_xpath}'\"\n",
    "                    column_definitions.append(column_def)\n",
    "        \n",
    "        sql_code = f\"\"\"SELECT\n",
    "    itx_entry_id,\n",
    "    x.*\n",
    "FROM {table_name} t,\n",
    "XMLTABLE(\n",
    "    '/entry' PASSING t.{xml_column_name}\n",
    "    COLUMNS\n",
    "{',\\n'.join(column_definitions)}\n",
    ") x\n",
    "WHERE t.itx_container_id = '1839'\n",
    "FETCH FIRST 100 ROWS ONLY;\"\"\"\n",
    "        \n",
    "        return sql_code\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Ошибка: {e}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ВЕРСИЯ С ПРИНУДИТЕЛЬНЫМИ ИНДЕКСАМИ ===\n",
      "SELECT\n",
      "    itx_entry_id,\n",
      "    x.*\n",
      "FROM tctg_itx_item_content t,\n",
      "XMLTABLE(\n",
      "    '/entry' PASSING t.itx_entry_content\n",
      "    COLUMNS\n",
      "        CSCD_ID VARCHAR2(4000) PATH 's1245[1]/n2821[1]',\n",
      "        CSCD_ID_SEQUENCE VARCHAR2(4000) PATH 's1245[1]/n2870[1]',\n",
      "        ATTENTION_FLAG VARCHAR2(4000) PATH 's1245[1]/n2889[1]',\n",
      "        GENERATE_NAMES VARCHAR2(4000) PATH 's1245[1]/n2864[1]',\n",
      "        SHORT_NAME_ru_RU VARCHAR2(4000) PATH 's1245[1]/n2874[1]/n2754[1]',\n",
      "        AUTO_SHORT_NAME VARCHAR2(4000) PATH 's1245[1]/n2815[1]',\n",
      "        PATTERN_SHORT_NAME VARCHAR2(4000) PATH 's1245[1]/n2832[1]',\n",
      "        FULL_NAME_ru_RU VARCHAR2(4000) PATH 's1245[1]/n2860[1]/n2766[1]',\n",
      "        AUTO_FULL_NAME VARCHAR2(4000) PATH 's1245[1]/n2869[1]',\n",
      "        PATTERN_FULL_NAME VARCHAR2(4000) PATH 's1245[1]/n2845[1]',\n",
      "        BASE_UNIT VARCHAR2(4000) PATH 's1245[1]/n2851[1]',\n",
      "        LUKOIL_MATERIAL VARCHAR2(4000) PATH 's1245[1]/n2872[1]',\n",
      "        TMC_Stat VARCHAR2(4000) PATH 's1245[1]/n2853[1]',\n",
      "        TMC_Type VARCHAR2(4000) PATH 's1245[1]/n2884[1]',\n",
      "        EXCISE_GROUP VARCHAR2(4000) PATH 's1245[1]/n2846[1]',\n",
      "        BRAND_OIL VARCHAR2(4000) PATH 's1245[1]/n28401[1]',\n",
      "        SIP_CODE VARCHAR2(4000) PATH 's1245[1]/n2888[1]',\n",
      "        TRU VARCHAR2(4000) PATH 's1245[1]/n34306[1]',\n",
      "        COST_GROUP VARCHAR2(4000) PATH 's1245[1]/n2822[1]',\n",
      "        TYPE_ACTIVITY VARCHAR2(4000) PATH 's1245[1]/n5404[1]',\n",
      "        CONTROLLED_PRODUCTS_IS_CONTROLLED_PRODUCTS VARCHAR2(4000) PATH 's1245[1]/n5724[1]/n5759[1]',\n",
      "        CONTROLLED_PRODUCTS_CONTROLLED_PRODUCTS_DATE_FROM VARCHAR2(4000) PATH 's1245[1]/n5724[1]/n5758[1]',\n",
      "        CONTROLLED_PRODUCTS_CONTROLLED_PRODUCTS_DATE_TO VARCHAR2(4000) PATH 's1245[1]/n5724[1]/n5757[1]',\n",
      "        ACTUAL_MATERIAL_TRACEABILITY VARCHAR2(4000) PATH 's1245[1]/n51402[1]',\n",
      "        MATERIAL_TRACEABILITY_MATERIAL_TRACEABILITY VARCHAR2(4000) PATH 's1245[1]/n2811[1]/n2783[1]',\n",
      "        MATERIAL_TRACEABILITY_TRACEABILITY_DATE_FROM VARCHAR2(4000) PATH 's1245[1]/n2811[1]/n2709[1]',\n",
      "        MATERIAL_TRACEABILITY_TRACEABILITY_DATE_TO VARCHAR2(4000) PATH 's1245[1]/n2811[1]/n2746[1]',\n",
      "        USER_SEGMENT VARCHAR2(4000) PATH 's1245[1]/n2865[1]',\n",
      "        USER_SEGMENT_2 VARCHAR2(4000) PATH 's1245[1]/n2865[2]',\n",
      "        USER_SEGMENT_3 VARCHAR2(4000) PATH 's1245[1]/n2865[3]',\n",
      "        ACTUAL_TAX_VALUE VARCHAR2(4000) PATH 's1245[1]/n2841[1]',\n",
      "        IS_RAW_MATERIAL VARCHAR2(4000) PATH 's1245[1]/n2855[1]',\n",
      "        NO_SALE_MINOR VARCHAR2(4000) PATH 's1245[1]/n91305[1]',\n",
      "        IS_TMBT_MATERIAL VARCHAR2(4000) PATH 's1245[1]/n2820[1]',\n",
      "        comments VARCHAR2(4000) PATH 's1245[1]/n30449[1]',\n",
      "        DISPLAY_NAME_ru_RU VARCHAR2(4000) PATH 's1245[1]/n2873[1]/n2788[1]',\n",
      "        Item_creator VARCHAR2(4000) PATH 's1245[1]/n2881[1]',\n",
      "        Item_creation_date VARCHAR2(4000) PATH 's1245[1]/n2880[1]',\n",
      "        TaskCreator_Date VARCHAR2(4000) PATH 's1245[1]/n30451[1]',\n",
      "        Change_history_User_changed VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32514[1]',\n",
      "        Change_history_User_changed_2 VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32514[2]',\n",
      "        Change_history_Date_changed VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32510[1]',\n",
      "        Change_history_Date_changed_2 VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32510[2]',\n",
      "        Change_history_Redactor VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32512[1]',\n",
      "        Change_history_Redactor_2 VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32512[2]',\n",
      "        Change_history_Date_redactor VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32513[1]',\n",
      "        Change_history_Date_redactor_2 VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32513[2]',\n",
      "        Change_history_Change_Type VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32511[1]',\n",
      "        Change_history_Change_Type_2 VARCHAR2(4000) PATH 's1245[1]/n32509[1]/n32511[2]',\n",
      "        Promptness VARCHAR2(4000) PATH 's1245[1]/n39415[1]',\n",
      "        Promptness_S VARCHAR2(4000) PATH 's1245[1]/n35254[1]',\n",
      "        PATTERN VARCHAR2(4000) PATH 's1245[1]/n2833[1]',\n",
      "        PATTERN_BASE_UNIT VARCHAR2(4000) PATH 's1245[1]/n35209[1]',\n",
      "        SALE_MATERIAL VARCHAR2(4000) PATH 's1245[1]/n28397[1]',\n",
      "        FRANCHISED_MATERIAL VARCHAR2(4000) PATH 's1245[1]/n5402[1]',\n",
      "        EXCISE_GOODS_IN_CHECK VARCHAR2(4000) PATH 's1245[1]/n5403[1]',\n",
      "        MAIN_PRODUCT VARCHAR2(4000) PATH 's1245[1]/n52202[1]',\n",
      "        LIKARD_LOCAL_ATTRIBUTES_LIKARD_ID VARCHAR2(4000) PATH 's1245[1]/n37430[1]/n37431[1]',\n",
      "        IS_USED VARCHAR2(4000) PATH 's1245[1]/n31403[1]',\n",
      "        REAGENT_FOR_EXTRACTION VARCHAR2(4000) PATH 's1245[1]/n31404[1]',\n",
      "        BALANCE_UNITS_NGDO VARCHAR2(4000) PATH 's1245[1]/n28389[1]',\n",
      "        BALANCE_UNITS_NGDO_OLD_APPLIED_CODE VARCHAR2(4000) PATH 's1245[1]/n31405[1]',\n",
      "        History_Property_User_Changed VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n91271[1]',\n",
      "        History_Property_User_Changed_2 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n91271[2]',\n",
      "        History_Property_Date_Begin VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2791[1]',\n",
      "        History_Property_Date_Begin_2 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2791[2]',\n",
      "        History_Property_Date_End VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2719[1]',\n",
      "        History_Property_Date_End_2 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2719[2]',\n",
      "        History_Property_NameShort_Auto VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2777[1]',\n",
      "        History_Property_NameShort_Auto_2 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2777[2]',\n",
      "        History_Property_NameFull_Auto VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2751[1]',\n",
      "        History_Property_NameFull_Auto_2 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2751[2]',\n",
      "        History_Property_Pattern VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2712[1]',\n",
      "        History_Property_Pattern_2 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2712[2]',\n",
      "        History_Property_Property_Property_Name VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2695[1]',\n",
      "        History_Property_Property_Property_Name_2 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2695[2]',\n",
      "        History_Property_Property_Property_Name_3 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2695[3]',\n",
      "        History_Property_Property_Property_Name_4 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2695[4]',\n",
      "        History_Property_Property_Property_Name_5 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2695[5]',\n",
      "        History_Property_Property_Property_Name_6 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2695[6]',\n",
      "        History_Property_Property_Property_Value VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2690[1]',\n",
      "        History_Property_Property_Property_Value_2 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2690[2]',\n",
      "        History_Property_Property_Property_Value_3 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2690[3]',\n",
      "        History_Property_Property_Property_Value_4 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2690[4]',\n",
      "        History_Property_Property_Property_Value_5 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2690[5]',\n",
      "        History_Property_Property_Property_Value_6 VARCHAR2(4000) PATH 's1245[1]/n2868[1]/n2767[1]/n2690[6]',\n",
      "        ISDOUBLE VARCHAR2(4000) PATH 's1245[1]/n2816[1]',\n",
      "        S3_VID_PRODUKTSII VARCHAR2(4000) PATH 's41619[1]/n103530[1]',\n",
      "        S3_TIP VARCHAR2(4000) PATH 's41619[1]/n103527[1]',\n",
      "        S3_TIP_IDENTIFIKATORA VARCHAR2(4000) PATH 's41619[1]/n103528[1]',\n",
      "        S3_OBOZNACHENIE VARCHAR2(4000) PATH 's41619[1]/n103529[1]',\n",
      "        S3_CHERTEZH VARCHAR2(4000) PATH 's41619[1]/n103526[1]'\n",
      ") x\n",
      "WHERE t.itx_container_id = '1839'\n",
      "FETCH FIRST 100 ROWS ONLY;\n"
     ]
    }
   ],
   "source": [
    "# Тестовый пример с явными дубликатами\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \n",
    "    table_name = \"tctg_itx_item_content\"\n",
    "    \n",
    "    print(\"=== ВЕРСИЯ С ПРИНУДИТЕЛЬНЫМИ ИНДЕКСАМИ ===\")\n",
    "    sql1 = generate_xmltable_simple_force_indexes(xml_example, alias_df, table_name)\n",
    "    print(sql1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
