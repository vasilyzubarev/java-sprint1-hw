{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import spacy\n",
    "try:\n",
    "    nlp = spacy.load(\"ru_core_news_sm\")\n",
    "except OSError:\n",
    "    print(\"Установите русскую модель Spacy: python -m spacy download ru_core_news_sm\")\n",
    "    nlp = None\n",
    "\n",
    "import joblib\n",
    "from rapidfuzz import process, fuzz\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "\n",
    "class TextPreprocessor:\n",
    "    \"\"\"Класс для предварительной обработки текста\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.russian_stop_words = self._get_russian_stop_words()\n",
    "    \n",
    "    def _get_russian_stop_words(self) -> set:\n",
    "        \"\"\"Русские стоп-слова\"\"\"\n",
    "        return {\n",
    "            'и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', \n",
    "            'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', \n",
    "            'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', \n",
    "            'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', \n",
    "            'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', \n",
    "            'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', \n",
    "            'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', \n",
    "            'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', \n",
    "            'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'ж', 'тогда', 'кто', \n",
    "            'этот', 'того', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', \n",
    "            'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', \n",
    "            'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', \n",
    "            'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', \n",
    "            'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', \n",
    "            'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', \n",
    "            'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', \n",
    "            'всю', 'между'\n",
    "        }\n",
    "    \n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        \"\"\"Основная предобработка текста\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # Удаляем специальные символы, но сохраняем числа и единицы измерения\n",
    "        text = re.sub(r'[^\\w\\s\\d\\.\\,\\-\\+\\/\\±]', ' ', text)\n",
    "        \n",
    "        # Заменяем множественные пробелы на один\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def extract_units_and_numbers(self, text: str) -> Dict[str, List[Tuple]]:\n",
    "        \"\"\"Извлечение чисел с единицами измерения\"\"\"\n",
    "        patterns = {\n",
    "            'length': r'(\\d+[.,]?\\d*)\\s*(мм|см|м|метр|сантиметр|миллиметр)',\n",
    "            'weight': r'(\\d+[.,]?\\d*)\\s*(г|кг|тонн|грамм|килограмм)',\n",
    "            'voltage': r'(\\d+[.,]?\\d*)\\s*(в|вольт|кв|киловольт)',\n",
    "            'current': r'(\\d+[.,]?\\d*)\\s*(а|ампер|ка|килоампер)',\n",
    "            'power': r'(\\d+[.,]?\\d*)\\s*(вт|квт|ватт|киловатт)',\n",
    "            'diameter': r'(\\d+[.,]?\\d*)\\s*(мм|см|м)',\n",
    "            'temperature': r'(\\d+[.,]?\\d*)\\s*(°c|°f|с|градус)',\n",
    "        }\n",
    "        \n",
    "        results = {}\n",
    "        for unit_type, pattern in patterns.items():\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            if matches:\n",
    "                results[unit_type] = matches\n",
    "        return results\n",
    "\n",
    "class CharacteristicExtractor:\n",
    "    \"\"\"Класс для извлечения характеристик из текста\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.preprocessor = TextPreprocessor()\n",
    "        self.patterns = self._initialize_patterns()\n",
    "    \n",
    "    def _initialize_patterns(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"Инициализация паттернов для извлечения характеристик\"\"\"\n",
    "        return {\n",
    "            'сечение': ['сечение', 'сеч', 'площадь', 'мм2', 'мм²'],\n",
    "            'длина': ['длина', 'длинна', 'метраж'],\n",
    "            'напряжение': ['напряжение', 'вольтаж', 'u', 'v'],\n",
    "            'ток': ['ток', 'сила тока', 'ампераж', 'i', 'a'],\n",
    "            'мощность': ['мощность', 'p', 'w'],\n",
    "            'диаметр': ['диаметр', 'диам', 'ø'],\n",
    "            'вес': ['вес', 'масса'],\n",
    "            'цвет': ['цвет', 'окраска'],\n",
    "            'материал': ['материал', 'изготовлен', 'сделан'],\n",
    "            'производитель': ['производитель', 'бренд', 'фирма', 'марка'],\n",
    "            'температура': ['температура', 'темп', 't°'],\n",
    "            'защита': ['ip', 'защита', 'степень защиты'],\n",
    "        }\n",
    "    \n",
    "    def extract_with_patterns(self, text: str, characteristics: List[str]) -> Dict[str, str]:\n",
    "        \"\"\"Извлечение характеристик с помощью паттернов\"\"\"\n",
    "        results = {}\n",
    "        text_clean = self.preprocessor.preprocess_text(text)\n",
    "        \n",
    "        for char in characteristics:\n",
    "            if char not in self.patterns:\n",
    "                continue\n",
    "                \n",
    "            patterns = self.patterns[char]\n",
    "            found = False\n",
    "            \n",
    "            for pattern in patterns:\n",
    "                # Паттерн: характеристика: значение\n",
    "                match1 = re.search(rf'{pattern}[:\\s]+([^,.;]+?)(?=[,.;]|$)', text_clean)\n",
    "                # Паттерн: характеристика - значение\n",
    "                match2 = re.search(rf'{pattern}[\\s\\-]+([^,.;]+?)(?=[,.;]|$)', text_clean)\n",
    "                # Паттерн: значение характеристика\n",
    "                match3 = re.search(rf'([^,.;]+?)\\s+{pattern}(?=[,.;]|$)', text_clean)\n",
    "                \n",
    "                for match in [match1, match2, match3]:\n",
    "                    if match:\n",
    "                        value = match.group(1).strip()\n",
    "                        if value and len(value) < 50:  # Фильтр слишком длинных значений\n",
    "                            results[char] = value\n",
    "                            found = True\n",
    "                            break\n",
    "                if found:\n",
    "                    break\n",
    "        return results\n",
    "    \n",
    "    def extract_with_fuzzy_matching(self, text: str, characteristics: List[str], \n",
    "                                  threshold: int = 75) -> Dict[str, str]:\n",
    "        \"\"\"Извлечение с помощью нечеткого сопоставления\"\"\"\n",
    "        results = {}\n",
    "        text_clean = self.preprocessor.preprocess_text(text)\n",
    "        words = text_clean.split()\n",
    "        \n",
    "        for char in characteristics:\n",
    "            if char not in self.patterns:\n",
    "                continue\n",
    "                \n",
    "            patterns = self.patterns[char]\n",
    "            best_score = 0\n",
    "            best_value = None\n",
    "            \n",
    "            for pattern in patterns:\n",
    "                # Ищем похожие слова в тексте\n",
    "                for i, word in enumerate(words):\n",
    "                    score = fuzz.partial_ratio(pattern, word)\n",
    "                    if score > best_score and score >= threshold:\n",
    "                        best_score = score\n",
    "                        # Пытаемся извлечь значение после найденного слова\n",
    "                        if i + 1 < len(words):\n",
    "                            best_value = words[i + 1]\n",
    "            \n",
    "            if best_value:\n",
    "                results[char] = best_value\n",
    "                \n",
    "        return results\n",
    "    \n",
    "    def extract_advanced(self, text: str, characteristics: List[str]) -> Dict[str, str]:\n",
    "        \"\"\"Комплексное извлечение характеристик\"\"\"\n",
    "        # 1. Паттернный анализ\n",
    "        pattern_results = self.extract_with_patterns(text, characteristics)\n",
    "        \n",
    "        # 2. Нечеткое сопоставление\n",
    "        fuzzy_results = self.extract_with_fuzzy_matching(text, characteristics)\n",
    "        \n",
    "        # 3. Объединяем результаты\n",
    "        results = {**fuzzy_results, **pattern_results}  # pattern_results имеет приоритет\n",
    "        \n",
    "        # 4. Постобработка значений\n",
    "        cleaned_results = {}\n",
    "        for char, value in results.items():\n",
    "            # Очистка значения от лишних слов\n",
    "            value_clean = re.sub(r'^(и|или|на|в|с|по)\\s+', '', value)\n",
    "            value_clean = value_clean.strip()\n",
    "            if value_clean:\n",
    "                cleaned_results[char] = value_clean\n",
    "                \n",
    "        return cleaned_results\n",
    "\n",
    "class NomenclatureClassifier:\n",
    "    \"\"\"Классификатор номенклатуры по классам\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.vectorizer = TfidfVectorizer(max_features=2000, ngram_range=(1, 2))\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.is_trained = False\n",
    "    \n",
    "    def train(self, descriptions: List[str], classes: List[str]):\n",
    "        \"\"\"Обучение классификатора\"\"\"\n",
    "        # Предобработка текстов\n",
    "        preprocessor = TextPreprocessor()\n",
    "        cleaned_descriptions = [preprocessor.preprocess_text(desc) for desc in descriptions]\n",
    "        \n",
    "        # Векторизация\n",
    "        X = self.vectorizer.fit_transform(cleaned_descriptions)\n",
    "        y = self.label_encoder.fit_transform(classes)\n",
    "        \n",
    "        # Обучение модели\n",
    "        self.model = RandomForestClassifier(\n",
    "            n_estimators=100, \n",
    "            random_state=42,\n",
    "            class_weight='balanced'\n",
    "        )\n",
    "        self.model.fit(X, y)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(f\"Классификатор обучен на {len(descriptions)} примерах\")\n",
    "        print(f\"Количество классов: {len(self.label_encoder.classes_)}\")\n",
    "    \n",
    "    def predict(self, description: str) -> str:\n",
    "        \"\"\"Предсказание класса для описания\"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Классификатор не обучен\")\n",
    "        \n",
    "        cleaned_desc = TextPreprocessor().preprocess_text(description)\n",
    "        X = self.vectorizer.transform([cleaned_desc])\n",
    "        y_pred = self.model.predict(X)\n",
    "        return self.label_encoder.inverse_transform(y_pred)[0]\n",
    "    \n",
    "    def predict_proba(self, description: str) -> Dict[str, float]:\n",
    "        \"\"\"Предсказание с вероятностями\"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Классификатор не обучен\")\n",
    "        \n",
    "        cleaned_desc = TextPreprocessor().preprocess_text(description)\n",
    "        X = self.vectorizer.transform([cleaned_desc])\n",
    "        probabilities = self.model.predict_proba(X)[0]\n",
    "        \n",
    "        return {\n",
    "            class_name: prob \n",
    "            for class_name, prob in zip(self.label_encoder.classes_, probabilities)\n",
    "        }\n",
    "\n",
    "class NomenclatureProcessor:\n",
    "    \"\"\"Основной класс для обработки номенклатуры\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.classifier = NomenclatureClassifier()\n",
    "        self.extractor = CharacteristicExtractor()\n",
    "        self.class_characteristics = {}  # class -> list of characteristics\n",
    "        self.is_trained = False\n",
    "    \n",
    "    def load_training_data(self, normalized_data: pd.DataFrame, \n",
    "                         characteristics_data: pd.DataFrame):\n",
    "        \"\"\"Загрузка обучающих данных\"\"\"\n",
    "        \n",
    "        # Анализ характеристик по классам\n",
    "        self.class_characteristics = {}\n",
    "        for _, row in characteristics_data.iterrows():\n",
    "            class_name = row['class']\n",
    "            characteristic = row['characteristic']\n",
    "            \n",
    "            if class_name not in self.class_characteristics:\n",
    "                self.class_characteristics[class_name] = []\n",
    "            \n",
    "            if characteristic not in self.class_characteristics[class_name]:\n",
    "                self.class_characteristics[class_name].append(characteristic)\n",
    "        \n",
    "        # Обучение классификатора классов\n",
    "        descriptions = normalized_data['description'].tolist()\n",
    "        classes = normalized_data['class'].tolist()\n",
    "        \n",
    "        self.classifier.train(descriptions, classes)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(\"Данные загружены и модели обучены\")\n",
    "        print(\"Доступные классы:\", list(self.class_characteristics.keys()))\n",
    "    \n",
    "    def process_single_item(self, class_name: Optional[str], \n",
    "                          nomenclature: str, description: str) -> Dict[str, Any]:\n",
    "        \"\"\"Обработка одной позиции номенклатуры\"\"\"\n",
    "        \n",
    "        # Если класс не указан, пытаемся предсказать\n",
    "        if not class_name or pd.isna(class_name):\n",
    "            if self.is_trained:\n",
    "                class_name = self.classifier.predict(description)\n",
    "                predicted = True\n",
    "            else:\n",
    "                class_name = \"unknown\"\n",
    "                predicted = True\n",
    "        else:\n",
    "            predicted = False\n",
    "        \n",
    "        # Получаем характеристики для класса\n",
    "        characteristics_list = self.class_characteristics.get(class_name, [])\n",
    "        \n",
    "        # Извлекаем характеристики\n",
    "        if characteristics_list:\n",
    "            extracted_chars = self.extractor.extract_advanced(description, characteristics_list)\n",
    "        else:\n",
    "            extracted_chars = {}\n",
    "        \n",
    "        return {\n",
    "            'nomenclature': nomenclature,\n",
    "            'class': class_name,\n",
    "            'class_predicted': predicted,\n",
    "            'description': description,\n",
    "            'characteristics': extracted_chars,\n",
    "            'characteristics_list': characteristics_list\n",
    "        }\n",
    "    \n",
    "    def process_batch(self, unnormalized_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Пакетная обработка ненормализованных данных\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for _, row in unnormalized_data.iterrows():\n",
    "            class_name = row.get('class')\n",
    "            nomenclature = row.get('nomenclature')\n",
    "            description = row.get('description')\n",
    "            \n",
    "            if pd.isna(description):\n",
    "                print(f\"Пропущено: отсутствует описание для {nomenclature}\")\n",
    "                continue\n",
    "            \n",
    "            result = self.process_single_item(class_name, nomenclature, description)\n",
    "            results.append(result)\n",
    "        \n",
    "        # Создаем DataFrame с результатами\n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Разворачиваем характеристики в отдельные колонки\n",
    "        characteristics_df = result_df['characteristics'].apply(pd.Series)\n",
    "        final_df = pd.concat([result_df.drop('characteristics', axis=1), characteristics_df], axis=1)\n",
    "        \n",
    "        return final_df\n",
    "    \n",
    "    def save_model(self, filepath: str):\n",
    "        \"\"\"Сохранение модели\"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Модель не обучена\")\n",
    "        \n",
    "        model_data = {\n",
    "            'classifier': self.classifier,\n",
    "            'extractor': self.extractor,\n",
    "            'class_characteristics': self.class_characteristics,\n",
    "            'is_trained': self.is_trained\n",
    "        }\n",
    "        \n",
    "        joblib.dump(model_data, filepath)\n",
    "        print(f\"Модель сохранена в {filepath}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(cls, filepath: str) -> 'NomenclatureProcessor':\n",
    "        \"\"\"Загрузка модели\"\"\"\n",
    "        model_data = joblib.load(filepath)\n",
    "        \n",
    "        processor = cls()\n",
    "        processor.classifier = model_data['classifier']\n",
    "        processor.extractor = model_data['extractor']\n",
    "        processor.class_characteristics = model_data['class_characteristics']\n",
    "        processor.is_trained = model_data['is_trained']\n",
    "        \n",
    "        print(f\"Модель загружена из {filepath}\")\n",
    "        return processor\n",
    "\n",
    "# Пример использования\n",
    "def create_sample_data() -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Создание примеров данных для демонстрации\"\"\"\n",
    "    \n",
    "    # Нормализованные данные для обучения\n",
    "    normalized_data = pd.DataFrame({\n",
    "        'nomenclature': [\n",
    "            'Кабель ВВГ 3х2.5',\n",
    "            'Труба ПНД 32мм',\n",
    "            'Автомат 16А',\n",
    "            'Светильник LED 18W',\n",
    "            'Розетка Schneider Electric',\n",
    "            'Кабель ВВГнг 3х1.5',\n",
    "            'Труба ПВХ 20мм',\n",
    "            'Автомат 25А',\n",
    "            'Светильник накладной',\n",
    "            'Выключатель Legrand'\n",
    "        ],\n",
    "        'class': ['кабель', 'труба', 'автомат', 'светильник', 'розетка',\n",
    "                 'кабель', 'труба', 'автомат', 'светильник', 'розетка'],\n",
    "        'description': [\n",
    "            'Кабель силовой ВВГ 3х2.5 мм², длина 100м, напряжение 660В',\n",
    "            'Труба полиэтиленовая ПНД диаметр 32 мм, длина 2м, давление 10атм',\n",
    "            'Автоматический выключатель 16А, характеристика C, полюсов 1',\n",
    "            'Светильник светодиодный LED мощность 18W, цвет белый, IP65',\n",
    "            'Розетка электрическая Schneider Electric, 220В, тип C',\n",
    "            'Кабель ВВГнг 3х1.5 мм² негорючий, напряжение 0.66кВ',\n",
    "            'Труба ПВХ диаметр 20 мм для электропроводки, длина 3м',\n",
    "            'Автомат двухполюсный 25А, характеристика B',\n",
    "            'Светильник накладной для помещений, мощность 36W',\n",
    "            'Выключатель клавишный Legrand, 10А, белый'\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Характеристики для каждого класса\n",
    "    characteristics_data = pd.DataFrame({\n",
    "        'class': ['кабель', 'кабель', 'кабель', 'труба', 'труба', 'труба', \n",
    "                 'автомат', 'автомат', 'светильник', 'светильник', 'розетка', 'розетка'],\n",
    "        'characteristic': ['сечение', 'длина', 'напряжение', 'диаметр', 'длина', 'материал',\n",
    "                          'ток', 'характеристика', 'мощность', 'цвет', 'напряжение', 'производитель']\n",
    "    })\n",
    "    \n",
    "    # Ненормализованные данные для обработки\n",
    "    unnormalized_data = pd.DataFrame({\n",
    "        'class': [None, 'труба', None, 'светильник'],\n",
    "        'nomenclature': [\n",
    "            'Провод медный многожильный',\n",
    "            'Труба пластиковая для кабеля',\n",
    "            'Выключатель автоматический 25А',\n",
    "            'Лампа светодиодная уличная'\n",
    "        ],\n",
    "        'description': [\n",
    "            'Провод медный многожильный сечение 4мм² длина 50м напряжение 380В',\n",
    "            'Труба пластиковая диаметр 40мм длина 3м давление 8атм',\n",
    "            'Автоматический выключатель номинальный ток 25А характеристика B',\n",
    "            'Светильник светодиодный мощность 30W степень защиты IP67 цвет черный'\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    return normalized_data, characteristics_data, unnormalized_data\n",
    "\n",
    "def main():\n",
    "    \"\"\"Основная функция демонстрации\"\"\"\n",
    "    \n",
    "    print(\"=== СИСТЕМА ПАРСИНГА ХАРАКТЕРИСТИК НОМЕНКЛАТУРЫ ===\\n\")\n",
    "    \n",
    "    # Создаем пример данных\n",
    "    normalized_data, characteristics_data, unnormalized_data = create_sample_data()\n",
    "    \n",
    "    print(\"1. ДАННЫЕ ДЛЯ ОБУЧЕНИЯ:\")\n",
    "    print(\"Нормализованные данные:\")\n",
    "    print(normalized_data)\n",
    "    print(\"\\nХарактеристики по классам:\")\n",
    "    print(characteristics_data)\n",
    "    print(\"\\nДанные для обработки:\")\n",
    "    print(unnormalized_data)\n",
    "    \n",
    "    # Инициализация и обучение процессора\n",
    "    print(\"\\n2. ОБУЧЕНИЕ МОДЕЛЕЙ...\")\n",
    "    processor = NomenclatureProcessor()\n",
    "    processor.load_training_data(normalized_data, characteristics_data)\n",
    "    \n",
    "    # Обработка ненормализованных данных\n",
    "    print(\"\\n3. ОБРАБОТКА ДАННЫХ...\")\n",
    "    results = processor.process_batch(unnormalized_data)\n",
    "    \n",
    "    print(\"\\n4. РЕЗУЛЬТАТЫ ОБРАБОТКИ:\")\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 1000)\n",
    "    print(results)\n",
    "    \n",
    "    # Сохранение модели\n",
    "    print(\"\\n5. СОХРАНЕНИЕ МОДЕЛИ...\")\n",
    "    processor.save_model('nomenclature_processor.pkl')\n",
    "    \n",
    "    # Демонстрация загрузки и использования модели\n",
    "    print(\"\\n6. ТЕСТ ЗАГРУЗКИ МОДЕЛИ...\")\n",
    "    loaded_processor = NomenclatureProcessor.load_model('nomenclature_processor.pkl')\n",
    "    \n",
    "    # Тестирование на новых данных\n",
    "    test_data = pd.DataFrame({\n",
    "        'class': [None],\n",
    "        'nomenclature': ['Кабель силовой медный'],\n",
    "        'description': ['Кабель ВВГнг 3х6мм² длина 100м напряжение 0.66кВ']\n",
    "    })\n",
    "    \n",
    "    test_results = loaded_processor.process_batch(test_data)\n",
    "    print(\"\\nРезультаты теста:\")\n",
    "    print(test_results)\n",
    "    \n",
    "    return processor, results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processor, results = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7180024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from rapidfuzz import process, fuzz\n",
    "import joblib\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "class NomenclatureParser:\n",
    "    \"\"\"Парсер характеристик номенклатуры на основе нормализованных данных\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.category_classifier = None\n",
    "        self.vectorizer = None\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.category_characteristics = defaultdict(list)  # category -> list of characteristics\n",
    "        self.characteristic_patterns = defaultdict(dict)   # (category, characteristic) -> patterns\n",
    "        self.value_patterns = defaultdict(list)           # characteristic -> common value patterns\n",
    "        self.is_trained = False\n",
    "        \n",
    "    def load_normalized_data(self, file_path: str) -> pd.DataFrame:\n",
    "        \"\"\"Загрузка нормализованных данных из файла\"\"\"\n",
    "        try:\n",
    "            # Пробуем разные разделители\n",
    "            df = pd.read_csv(file_path, sep='\\t', encoding='utf-8')\n",
    "            if df.shape[1] == 1:\n",
    "                df = pd.read_csv(file_path, sep=',', encoding='utf-8')\n",
    "        except:\n",
    "            df = pd.read_csv(file_path, encoding='utf-8', sep=None, engine='python')\n",
    "        \n",
    "        # Проверяем наличие необходимых колонок\n",
    "        required_columns = ['nomenclature', 'category', 'description', 'characteristic', 'value']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        \n",
    "        if missing_columns:\n",
    "            raise ValueError(f\"Отсутствуют обязательные колонки: {missing_columns}\")\n",
    "        \n",
    "        print(f\"Загружено {len(df)} записей нормализованных данных\")\n",
    "        print(f\"Количество категорий: {df['category'].nunique()}\")\n",
    "        print(f\"Количество характеристик: {df['characteristic'].nunique()}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        \"\"\"Предобработка текста\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        text = str(text).lower()\n",
    "        # Удаляем специальные символы, но сохраняем числа и единицы измерения\n",
    "        text = re.sub(r'[^\\w\\s\\d\\.\\,\\-\\+\\/\\±]', ' ', text)\n",
    "        # Заменяем множественные пробелы на один\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    def analyze_characteristics(self, normalized_data: pd.DataFrame):\n",
    "        \"\"\"Анализ характеристик и их значений из нормализованных данных\"\"\"\n",
    "        \n",
    "        # Группируем по категориям и характеристикам\n",
    "        for category in normalized_data['category'].unique():\n",
    "            category_data = normalized_data[normalized_data['category'] == category]\n",
    "            \n",
    "            for char_name in category_data['characteristic'].unique():\n",
    "                char_data = category_data[category_data['characteristic'] == char_name]\n",
    "                \n",
    "                # Добавляем характеристику в список для категории\n",
    "                if char_name not in self.category_characteristics[category]:\n",
    "                    self.category_characteristics[category].append(char_name)\n",
    "                \n",
    "                # Анализируем значения характеристики для извлечения паттернов\n",
    "                values = char_data['value'].dropna().unique()\n",
    "                \n",
    "                for value in values:\n",
    "                    value_str = str(value).lower()\n",
    "                    \n",
    "                    # Извлекаем паттерны из значений\n",
    "                    patterns = self._extract_patterns_from_value(value_str)\n",
    "                    for pattern in patterns:\n",
    "                        if pattern not in self.value_patterns[char_name]:\n",
    "                            self.value_patterns[char_name].append(pattern)\n",
    "        \n",
    "        print(\"Анализ характеристик завершен:\")\n",
    "        for category, chars in self.category_characteristics.items():\n",
    "            print(f\"  {category}: {len(chars)} характеристик\")\n",
    "    \n",
    "    def _extract_patterns_from_value(self, value: str) -> List[str]:\n",
    "        \"\"\"Извлечение паттернов из значений характеристик\"\"\"\n",
    "        patterns = []\n",
    "        \n",
    "        # Числовые паттерны\n",
    "        number_patterns = [\n",
    "            r'\\d+[.,]?\\d*',  # числа с плавающей точкой\n",
    "            r'\\d+',          # целые числа\n",
    "        ]\n",
    "        \n",
    "        # Текстовые паттерны\n",
    "        text_patterns = [\n",
    "            r'[a-zа-я]+',    # слова\n",
    "            r'[a-zа-я]+\\s+[a-zа-я]+',  # словосочетания\n",
    "        ]\n",
    "        \n",
    "        # Специальные паттерны (коды, модели)\n",
    "        special_patterns = [\n",
    "            r'[a-zа-я]\\d+',           # буква + цифры\n",
    "            r'\\d+[a-zа-я]',           # цифры + буква\n",
    "            r'[a-zа-я]\\d+[a-zа-я]',   # буква + цифры + буква\n",
    "            r'\\d+-\\d+',               # числа через дефис\n",
    "            r'[a-zа-я]+-\\d+',         # буквы-числа\n",
    "        ]\n",
    "        \n",
    "        # Проверяем каждый паттерн\n",
    "        all_patterns = number_patterns + text_patterns + special_patterns\n",
    "        \n",
    "        for pattern in all_patterns:\n",
    "            matches = re.findall(pattern, value, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                if len(match) > 1 and match not in patterns:\n",
    "                    patterns.append(match)\n",
    "        \n",
    "        return patterns\n",
    "    \n",
    "    def train_category_classifier(self, normalized_data: pd.DataFrame):\n",
    "        \"\"\"Обучение классификатора категорий\"\"\"\n",
    "        \n",
    "        # Создаем уникальный набор описаний для обучения\n",
    "        unique_data = normalized_data.drop_duplicates(subset=['nomenclature', 'category', 'description'])\n",
    "        \n",
    "        if len(unique_data) == 0:\n",
    "            raise ValueError(\"Недостаточно данных для обучения классификатора\")\n",
    "        \n",
    "        descriptions = unique_data['description'].apply(self.preprocess_text).tolist()\n",
    "        categories = unique_data['category'].tolist()\n",
    "        \n",
    "        # Кодируем категории\n",
    "        categories_encoded = self.label_encoder.fit_transform(categories)\n",
    "        \n",
    "        # Векторизация текста\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=1000,\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words=None\n",
    "        )\n",
    "        \n",
    "        X = self.vectorizer.fit_transform(descriptions)\n",
    "        \n",
    "        # Обучение модели\n",
    "        self.category_classifier = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            class_weight='balanced'\n",
    "        )\n",
    "        \n",
    "        self.category_classifier.fit(X, categories_encoded)\n",
    "        \n",
    "        print(f\"Классификатор категорий обучен на {len(descriptions)} примерах\")\n",
    "        print(f\"Количество категорий: {len(self.label_encoder.classes_)}\")\n",
    "    \n",
    "    def predict_category(self, description: str) -> str:\n",
    "        \"\"\"Предсказание категории для описания\"\"\"\n",
    "        if self.category_classifier is None:\n",
    "            raise ValueError(\"Классификатор категорий не обучен\")\n",
    "        \n",
    "        text = self.preprocess_text(description)\n",
    "        X = self.vectorizer.transform([text])\n",
    "        y_pred = self.category_classifier.predict(X)\n",
    "        return self.label_encoder.inverse_transform(y_pred)[0]\n",
    "    \n",
    "    def extract_characteristics(self, category: str, description: str) -> Dict[str, str]:\n",
    "        \"\"\"Извлечение характеристик для указанной категории\"\"\"\n",
    "        if category not in self.category_characteristics:\n",
    "            return {}\n",
    "        \n",
    "        characteristics = {}\n",
    "        text = self.preprocess_text(description)\n",
    "        \n",
    "        for char_name in self.category_characteristics[category]:\n",
    "            value = self._extract_single_characteristic(char_name, text)\n",
    "            if value:\n",
    "                characteristics[char_name] = value\n",
    "        \n",
    "        return characteristics\n",
    "    \n",
    "    def _extract_single_characteristic(self, char_name: str, text: str) -> Optional[str]:\n",
    "        \"\"\"Извлечение значения одной характеристики\"\"\"\n",
    "        \n",
    "        # Паттерны для разных типов характеристик\n",
    "        patterns = {\n",
    "            'вид продукции': self._extract_product_type,\n",
    "            'тип горелки': self._extract_burner_type,\n",
    "            'тип самоспасателя': self._extract_respirator_type,\n",
    "            'модель': self._extract_model,\n",
    "        }\n",
    "        \n",
    "        # Используем специализированный метод если есть, иначе общий\n",
    "        if char_name.lower() in patterns:\n",
    "            return patterns[char_name.lower()](text)\n",
    "        else:\n",
    "            return self._extract_general_characteristic(char_name, text)\n",
    "    \n",
    "    def _extract_product_type(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Извлечение вида продукции\"\"\"\n",
    "        product_types = ['горелка', 'самоспасатель']\n",
    "        \n",
    "        for product_type in product_types:\n",
    "            if product_type in text:\n",
    "                return product_type.capitalize()\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _extract_burner_type(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Извлечение типа горелки\"\"\"\n",
    "        burner_types = ['газовая', 'электрическая']\n",
    "        \n",
    "        for burner_type in burner_types:\n",
    "            if burner_type in text:\n",
    "                return burner_type\n",
    "        \n",
    "        # Ищем по ключевым словам\n",
    "        if 'газ' in text:\n",
    "            return 'газовая'\n",
    "        elif 'электр' in text:\n",
    "            return 'электрическая'\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _extract_respirator_type(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Извлечение типа самоспасателя\"\"\"\n",
    "        respirator_types = ['изолирующий', 'фильтрующий']\n",
    "        \n",
    "        for resp_type in respirator_types:\n",
    "            if resp_type in text:\n",
    "                return resp_type\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _extract_model(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Извлечение модели/артикула\"\"\"\n",
    "        # Паттерны для моделей\n",
    "        model_patterns = [\n",
    "            r'[a-zа-я]{2,}\\s*[\\-\\s]*[a-zа-я]*\\s*\\d+[\\-\\s]*\\d*[a-zа-я]*',  # ЗСУ-ПИ-38-350\n",
    "            r'[a-zа-я]+\\s*\\d+[a-zа-я]*',                                  # R93A\n",
    "            r'[a-zа-я]+\\s*\\d+[\\s\\-]*[a-zа-я]*\\s*\\d*',                     # СПИ-20\n",
    "            r'[a-zа-я]+\\s*\\d+[a-zа-я]+\\s*\\d*',                           # ЗЕВС 30У\n",
    "        ]\n",
    "        \n",
    "        for pattern in model_patterns:\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            if matches:\n",
    "                # Берем самую длинную найденную модель (обычно это полное обозначение)\n",
    "                best_match = max(matches, key=len)\n",
    "                return best_match.upper()\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _extract_general_characteristic(self, char_name: str, text: str) -> Optional[str]:\n",
    "        \"\"\"Общий метод извлечения характеристик\"\"\"\n",
    "        # Используем нечеткое сравнение для поиска значений\n",
    "        if char_name in self.value_patterns:\n",
    "            for pattern in self.value_patterns[char_name]:\n",
    "                if pattern in text:\n",
    "                    return pattern\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def train(self, normalized_data: pd.DataFrame):\n",
    "        \"\"\"Полное обучение модели на нормализованных данных\"\"\"\n",
    "        print(\"=== ОБУЧЕНИЕ МОДЕЛИ ===\")\n",
    "        \n",
    "        # Анализ характеристик\n",
    "        self.analyze_characteristics(normalized_data)\n",
    "        \n",
    "        # Обучение классификатора категорий\n",
    "        self.train_category_classifier(normalized_data)\n",
    "        \n",
    "        self.is_trained = True\n",
    "        print(\"Модель успешно обучена\")\n",
    "    \n",
    "    def process_unnormalized_data(self, unnormalized_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Обработка ненормализованных данных\"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Модель не обучена. Сначала выполните обучение.\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for _, row in unnormalized_data.iterrows():\n",
    "            nomenclature = row.get('nomenclature', '')\n",
    "            category = row.get('category')\n",
    "            description = row.get('description', '')\n",
    "            \n",
    "            # Если категория не указана, предсказываем её\n",
    "            if pd.isna(category) or not category:\n",
    "                try:\n",
    "                    category = self.predict_category(description)\n",
    "                    predicted_category = True\n",
    "                except:\n",
    "                    category = \"unknown\"\n",
    "                    predicted_category = True\n",
    "            else:\n",
    "                predicted_category = False\n",
    "            \n",
    "            # Извлекаем характеристики\n",
    "            characteristics = self.extract_characteristics(category, description)\n",
    "            \n",
    "            # Создаем результат\n",
    "            result_row = {\n",
    "                'nomenclature': nomenclature,\n",
    "                'category': category,\n",
    "                'category_predicted': predicted_category,\n",
    "                'description': description,\n",
    "                **characteristics\n",
    "            }\n",
    "            \n",
    "            results.append(result_row)\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def save_model(self, filepath: str):\n",
    "        \"\"\"Сохранение модели\"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Модель не обучена\")\n",
    "        \n",
    "        model_data = {\n",
    "            'category_classifier': self.category_classifier,\n",
    "            'vectorizer': self.vectorizer,\n",
    "            'label_encoder': self.label_encoder,\n",
    "            'category_characteristics': dict(self.category_characteristics),\n",
    "            'value_patterns': dict(self.value_patterns),\n",
    "            'is_trained': self.is_trained\n",
    "        }\n",
    "        \n",
    "        joblib.dump(model_data, filepath)\n",
    "        print(f\"Модель сохранена в {filepath}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(cls, filepath: str) -> 'NomenclatureParser':\n",
    "        \"\"\"Загрузка модели\"\"\"\n",
    "        model_data = joblib.load(filepath)\n",
    "        \n",
    "        parser = cls()\n",
    "        parser.category_classifier = model_data['category_classifier']\n",
    "        parser.vectorizer = model_data['vectorizer']\n",
    "        parser.label_encoder = model_data['label_encoder']\n",
    "        parser.category_characteristics = defaultdict(list, model_data['category_characteristics'])\n",
    "        parser.value_patterns = defaultdict(list, model_data['value_patterns'])\n",
    "        parser.is_trained = model_data['is_trained']\n",
    "        \n",
    "        print(f\"Модель загружена из {filepath}\")\n",
    "        return parser\n",
    "\n",
    "# Функции для работы с данными\n",
    "def create_sample_unnormalized_data() -> pd.DataFrame:\n",
    "    \"\"\"Создание примера ненормализованных данных\"\"\"\n",
    "    return pd.DataFrame({\n",
    "        'nomenclature': ['1234', '5678', '91011', '121314'],\n",
    "        'category': ['Горелки теплотехнические', None, 'Самоспасатели', None],\n",
    "        'description': [\n",
    "            'Горелка газовая ЗСУ-ПИ-38-350-IP65 для промышленного использования',\n",
    "            'Электрическая горелка R93A M.PR.S.RU.A.8.50 с системой контроля',\n",
    "            'Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011',\n",
    "            'Фильтрующий самоспасатель Parat 3100 ТР ТС 019/2011'\n",
    "        ]\n",
    "    })\n",
    "\n",
    "def main():\n",
    "    \"\"\"Основная функция демонстрации\"\"\"\n",
    "    print(\"=== СИСТЕМА ПАРСИНГА ХАРАКТЕРИСТИК НОМЕНКЛАТУРЫ ===\\n\")\n",
    "    \n",
    "    # Инициализация парсера\n",
    "    parser = NomenclatureParser()\n",
    "    \n",
    "    try:\n",
    "        # Загрузка нормализованных данных\n",
    "        print(\"1. ЗАГРУЗКА НОРМАЛИЗОВАННЫХ ДАННЫХ...\")\n",
    "        normalized_data = parser.load_normalized_data('normalized.txt')\n",
    "        print(\"Первые 5 записей нормализованных данных:\")\n",
    "        print(normalized_data.head())\n",
    "        \n",
    "        # Обучение модели\n",
    "        print(\"\\n2. ОБУЧЕНИЕ МОДЕЛИ...\")\n",
    "        parser.train(normalized_data)\n",
    "        \n",
    "        # Создание тестовых данных\n",
    "        print(\"\\n3. ПОДГОТОВКА ТЕСТОВЫХ ДАННЫХ...\")\n",
    "        unnormalized_data = create_sample_unnormalized_data()\n",
    "        print(\"Данные для обработки:\")\n",
    "        print(unnormalized_data)\n",
    "        \n",
    "        # Обработка данных\n",
    "        print(\"\\n4. ОБРАБОТКА ДАННЫХ...\")\n",
    "        results = parser.process_unnormalized_data(unnormalized_data)\n",
    "        \n",
    "        print(\"\\n5. РЕЗУЛЬТАТЫ ОБРАБОТКИ:\")\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', 1000)\n",
    "        print(results)\n",
    "        \n",
    "        # Сохранение модели\n",
    "        print(\"\\n6. СОХРАНЕНИЕ МОДЕЛИ...\")\n",
    "        parser.save_model('nomenclature_parser.pkl')\n",
    "        \n",
    "        # Демонстрация загрузки модели\n",
    "        print(\"\\n7. ТЕСТ ЗАГРУЗКИ МОДЕЛИ...\")\n",
    "        loaded_parser = NomenclatureParser.load_model('nomenclature_parser.pkl')\n",
    "        \n",
    "        # Тестирование на новых данных\n",
    "        test_data = pd.DataFrame({\n",
    "            'nomenclature': ['9999'],\n",
    "            'category': [None],\n",
    "            'description': ['Станция радиолокационный ECAT2 252/12/MK/VM2 Sperry Marine']\n",
    "        })\n",
    "        \n",
    "        test_results = loaded_parser.process_unnormalized_data(test_data)\n",
    "        print(\"\\nРезультаты теста новой модели:\")\n",
    "        print(test_results)\n",
    "        \n",
    "        return parser, results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка: {e}\")\n",
    "        # Создаем демонстрационные данные если файл не найден\n",
    "        print(\"\\nСоздание демонстрационных данных...\")\n",
    "        return create_demo_example()\n",
    "\n",
    "def create_demo_example():\n",
    "    \"\"\"Создание демонстрационного примера если файл не найден\"\"\"\n",
    "    # Создаем нормализованные данные на основе предоставленного примера\n",
    "    normalized_data = pd.DataFrame({\n",
    "        'nomenclature': ['1267', '1267', '1267', '1324', '1324', '1324', \n",
    "                        '2356', '2356', '2356', '4325', '4325', '4325'],\n",
    "        'category': ['Горелки теплотехнические'] * 6 + ['Самоспасатели'] * 6,\n",
    "        'description': [\n",
    "            'Горелка газовая ЗСУ-ПИ-38-350-IP65',\n",
    "            'Горелка газовая ЗСУ-ПИ-38-350-IP66', \n",
    "            'Горелка газовая ЗСУ-ПИ-38-350-IP67',\n",
    "            'Горелка электрическая R93A M.PR.S.RU.A.8.50',\n",
    "            'Горелка электрическая R93A M.PR.S.RU.A.8.51',\n",
    "            'Горелка электрическая R93A M.PR.S.RU.A.8.52',\n",
    "            'Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011',\n",
    "            'Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011',\n",
    "            'Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011',\n",
    "            'Самоспасатель фильтрующий ЗЕВС 30У ТР ТС 019/2011',\n",
    "            'Самоспасатель фильтрующий ЗЕВС 30У ТР ТС 019/2011',\n",
    "            'Самоспасатель фильтрующий ЗЕВС 30У ТР ТС 019/2011'\n",
    "        ],\n",
    "        'characteristic': [\n",
    "            'Вид продукции', 'Тип горелки', 'Модель',\n",
    "            'Вид продукции', 'Тип горелки', 'Модель', \n",
    "            'Вид продукции', 'Тип самоспасателя', 'Модель',\n",
    "            'Вид продукции', 'Тип самоспасателя', 'Модель'\n",
    "        ],\n",
    "        'value': [\n",
    "            'Горелка', 'газовая', 'ЗСУ-ПИ-38-350-IP67',\n",
    "            'Горелка', 'электрическая', 'R93A M.PR.S.RU.A.8.52',\n",
    "            'Самоспасатель', 'изолирующий', 'СПИ-20 ТР ТС 019/2011',\n",
    "            'Самоспасатель', 'фильтрующий', 'ЗЕВС 30У ТР ТС 019/2011'\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    parser = NomenclatureParser()\n",
    "    parser.train(normalized_data)\n",
    "    \n",
    "    unnormalized_data = create_sample_unnormalized_data()\n",
    "    results = parser.process_unnormalized_data(unnormalized_data)\n",
    "    \n",
    "    print(\"Демонстрационные результаты:\")\n",
    "    print(results)\n",
    "    \n",
    "    return parser, results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser, results = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee6805e",
   "metadata": {},
   "source": [
    "## Основная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47979673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, mean_squared_error, r2_score\n",
    "from rapidfuzz import process, fuzz\n",
    "import joblib\n",
    "from typing import Dict, List, Tuple, Any, Optional, Union\n",
    "from collections import defaultdict\n",
    "\n",
    "class NumericCharacteristicExtractor:\n",
    "    \"\"\"Класс для извлечения числовых характеристик\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.numeric_patterns = {\n",
    "            'длина': [\n",
    "                r'(\\d+[.,]?\\d*)\\s*(мм|см|м|метр|сантиметр|миллиметр)',\n",
    "                r'длина[:\\s]*(\\d+[.,]?\\d*)\\s*(мм|см|м)?',\n",
    "                r'(\\d+[.,]?\\d*)\\s*(мм|см|м)\\s*длина'\n",
    "            ],\n",
    "            'ширина': [\n",
    "                r'ширина[:\\s]*(\\d+[.,]?\\d*)\\s*(мм|см|м)?',\n",
    "                r'(\\d+[.,]?\\d*)\\s*(мм|см|м)\\s*ширина'\n",
    "            ],\n",
    "            'высота': [\n",
    "                r'высота[:\\s]*(\\d+[.,]?\\d*)\\s*(мм|см|м)?',\n",
    "                r'(\\d+[.,]?\\d*)\\s*(мм|см|м)\\s*высота'\n",
    "            ],\n",
    "            'диаметр': [\n",
    "                r'диаметр[:\\s]*(\\d+[.,]?\\d*)\\s*(мм|см|м)?',\n",
    "                r'(\\d+[.,]?\\d*)\\s*(мм|см|м)\\s*диаметр',\n",
    "                r'ø\\s*(\\d+[.,]?\\d*)\\s*(мм|см|м)?'\n",
    "            ],\n",
    "            'вес': [\n",
    "                r'вес[:\\s]*(\\d+[.,]?\\d*)\\s*(г|кг|т|грамм|килограмм|тонн)?',\n",
    "                r'(\\d+[.,]?\\d*)\\s*(г|кг|т)\\s*вес',\n",
    "                r'масса[:\\s]*(\\d+[.,]?\\d*)\\s*(г|кг|т)?'\n",
    "            ],\n",
    "            'объем': [\n",
    "                r'объем[:\\s]*(\\d+[.,]?\\d*)\\s*(мл|л|см3|м3)?',\n",
    "                r'(\\d+[.,]?\\d*)\\s*(мл|л|см3|м3)\\s*объем'\n",
    "            ],\n",
    "            'мощность': [\n",
    "                r'мощность[:\\s]*(\\d+[.,]?\\d*)\\s*(вт|квт|ватт|киловатт)?',\n",
    "                r'(\\d+[.,]?\\d*)\\s*(вт|квт)\\s*мощность'\n",
    "            ],\n",
    "            'напряжение': [\n",
    "                r'напряжение[:\\s]*(\\d+[.,]?\\d*)\\s*(в|вольт|кв)?',\n",
    "                r'(\\d+[.,]?\\d*)\\s*(в|вольт)\\s*напряжение'\n",
    "            ],\n",
    "            'ток': [\n",
    "                r'ток[:\\s]*(\\d+[.,]?\\d*)\\s*(а|ампер|ма)?',\n",
    "                r'(\\d+[.,]?\\d*)\\s*(а|ампер)\\s*ток',\n",
    "                r'сила тока[:\\s]*(\\d+[.,]?\\d*)\\s*(а|ампер)?'\n",
    "            ],\n",
    "            'температура': [\n",
    "                r'температура[:\\s]*([+-]?\\d+[.,]?\\d*)\\s*(°c|°f|с|градус)?',\n",
    "                r'([+-]?\\d+[.,]?\\d*)\\s*(°c|°f)\\s*температура',\n",
    "                r't[:\\s]*([+-]?\\d+[.,]?\\d*)\\s*(°c|°f)?'\n",
    "            ],\n",
    "            'давление': [\n",
    "                r'давление[:\\s]*(\\d+[.,]?\\d*)\\s*(па|кпа|мпа|бар|атм)?',\n",
    "                r'(\\d+[.,]?\\d*)\\s*(па|бар|атм)\\s*давление'\n",
    "            ],\n",
    "            'скорость': [\n",
    "                r'скорость[:\\s]*(\\d+[.,]?\\d*)\\s*(м/с|км/ч|об/мин)?',\n",
    "                r'(\\d+[.,]?\\d*)\\s*(м/с|км/ч)\\s*скорость'\n",
    "            ],\n",
    "            'количество': [\n",
    "                r'(\\d+)\\s*(шт|штук|единиц)',\n",
    "                r'количество[:\\s]*(\\d+)\\s*(шт|штук)?',\n",
    "                r'(\\d+)\\s*штук'\n",
    "            ],\n",
    "            'размер': [\n",
    "                r'размер[:\\s]*(\\d+[.,]?\\d*)\\s*(мм|см|м)?',\n",
    "                r'(\\d+[.,]?\\d*)\\s*(мм|см|м)\\s*размер'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        self.unit_converters = {\n",
    "            'длина': self._convert_length,\n",
    "            'вес': self._convert_weight,\n",
    "            'объем': self._convert_volume,\n",
    "            'мощность': self._convert_power,\n",
    "            'напряжение': self._convert_voltage,\n",
    "            'ток': self._convert_current,\n",
    "            'температура': self._convert_temperature,\n",
    "            'давление': self._convert_pressure\n",
    "        }\n",
    "    \n",
    "    def _convert_length(self, value: float, unit: str) -> Tuple[float, str]:\n",
    "        \"\"\"Конвертация единиц длины в мм\"\"\"\n",
    "        unit = unit.lower()\n",
    "        if unit in ['м', 'метр']:\n",
    "            return value * 1000, 'мм'\n",
    "        elif unit in ['см', 'сантиметр']:\n",
    "            return value * 10, 'мм'\n",
    "        else:\n",
    "            return value, 'мм'\n",
    "    \n",
    "    def _convert_weight(self, value: float, unit: str) -> Tuple[float, str]:\n",
    "        \"\"\"Конвертация единиц веса в кг\"\"\"\n",
    "        unit = unit.lower()\n",
    "        if unit in ['г', 'грамм']:\n",
    "            return value / 1000, 'кг'\n",
    "        elif unit in ['т', 'тонн']:\n",
    "            return value * 1000, 'кг'\n",
    "        else:\n",
    "            return value, 'кг'\n",
    "    \n",
    "    def _convert_volume(self, value: float, unit: str) -> Tuple[float, str]:\n",
    "        \"\"\"Конвертация единиц объема в литры\"\"\"\n",
    "        unit = unit.lower()\n",
    "        if unit in ['мл']:\n",
    "            return value / 1000, 'л'\n",
    "        elif unit in ['м3']:\n",
    "            return value * 1000, 'л'\n",
    "        else:\n",
    "            return value, 'л'\n",
    "    \n",
    "    def _convert_power(self, value: float, unit: str) -> Tuple[float, str]:\n",
    "        \"\"\"Конвертация единиц мощности в Вт\"\"\"\n",
    "        unit = unit.lower()\n",
    "        if unit in ['квт', 'киловатт']:\n",
    "            return value * 1000, 'вт'\n",
    "        else:\n",
    "            return value, 'вт'\n",
    "    \n",
    "    def _convert_voltage(self, value: float, unit: str) -> Tuple[float, str]:\n",
    "        \"\"\"Конвертация единиц напряжения в В\"\"\"\n",
    "        unit = unit.lower()\n",
    "        if unit in ['кв', 'киловольт']:\n",
    "            return value * 1000, 'в'\n",
    "        else:\n",
    "            return value, 'в'\n",
    "    \n",
    "    def _convert_current(self, value: float, unit: str) -> Tuple[float, str]:\n",
    "        \"\"\"Конвертация единиц тока в А\"\"\"\n",
    "        unit = unit.lower()\n",
    "        if unit in ['ма']:\n",
    "            return value / 1000, 'а'\n",
    "        else:\n",
    "            return value, 'а'\n",
    "    \n",
    "    def _convert_temperature(self, value: float, unit: str) -> Tuple[float, str]:\n",
    "        \"\"\"Конвертация единиц температуры в °C\"\"\"\n",
    "        unit = unit.lower()\n",
    "        if unit in ['°f']:\n",
    "            return (value - 32) * 5/9, '°c'\n",
    "        else:\n",
    "            return value, '°c'\n",
    "    \n",
    "    def _convert_pressure(self, value: float, unit: str) -> Tuple[float, str]:\n",
    "        \"\"\"Конвертация единиц давления в бар\"\"\"\n",
    "        unit = unit.lower()\n",
    "        if unit in ['па']:\n",
    "            return value / 100000, 'бар'\n",
    "        elif unit in ['кпа']:\n",
    "            return value / 100, 'бар'\n",
    "        elif unit in ['мпа']:\n",
    "            return value * 10, 'бар'\n",
    "        elif unit in ['атм']:\n",
    "            return value * 1.01325, 'бар'\n",
    "        else:\n",
    "            return value, 'бар'\n",
    "    \n",
    "    def extract_numeric_value(self, char_name: str, text: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Извлечение числового значения для характеристики\"\"\"\n",
    "        if char_name not in self.numeric_patterns:\n",
    "            return None\n",
    "        \n",
    "        patterns = self.numeric_patterns[char_name]\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            matches = re.findall(pattern, text_lower, re.IGNORECASE)\n",
    "            if matches:\n",
    "                for match in matches:\n",
    "                    # match может быть кортежем (значение, единица) или (значение, единица, что-то еще)\n",
    "                    if len(match) >= 1:\n",
    "                        value_str = match[0].replace(',', '.')\n",
    "                        unit = match[1] if len(match) > 1 and match[1] else ''\n",
    "                        \n",
    "                        try:\n",
    "                            # Пробуем преобразовать в число\n",
    "                            if '.' in value_str:\n",
    "                                value = float(value_str)\n",
    "                            else:\n",
    "                                value = int(value_str)\n",
    "                            \n",
    "                            # Конвертируем единицы измерения если нужно\n",
    "                            if char_name in self.unit_converters and unit:\n",
    "                                value, standard_unit = self.unit_converters[char_name](value, unit)\n",
    "                            else:\n",
    "                                standard_unit = unit\n",
    "                            \n",
    "                            return {\n",
    "                                'value': value,\n",
    "                                'unit': standard_unit,\n",
    "                                'original_value': value_str,\n",
    "                                'original_unit': unit\n",
    "                            }\n",
    "                        except (ValueError, TypeError):\n",
    "                            continue\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def extract_all_numeric_values(self, text: str) -> Dict[str, Dict[str, Any]]:\n",
    "        \"\"\"Извлечение всех числовых значений из текста\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for char_name in self.numeric_patterns.keys():\n",
    "            value_info = self.extract_numeric_value(char_name, text)\n",
    "            if value_info:\n",
    "                results[char_name] = value_info\n",
    "        \n",
    "        return results\n",
    "\n",
    "class EnhancedNomenclatureParser:\n",
    "    \"\"\"Улучшенный парсер с поддержкой числовых характеристик\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.category_classifier = None\n",
    "        self.vectorizer = None\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.category_characteristics = defaultdict(list)\n",
    "        self.characteristic_types = defaultdict(str)  # characteristic -> type (text/numeric)\n",
    "        self.numeric_extractor = NumericCharacteristicExtractor()\n",
    "        self.value_patterns = defaultdict(list)\n",
    "        self.is_trained = False\n",
    "        \n",
    "    def load_normalized_data(self, file_path: str) -> pd.DataFrame:\n",
    "        \"\"\"Загрузка нормализованных данных\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep='\\t', encoding='utf-8')\n",
    "            if df.shape[1] == 1:\n",
    "                df = pd.read_csv(file_path, sep=',', encoding='utf-8')\n",
    "        except:\n",
    "            df = pd.read_csv(file_path, encoding='utf-8', sep=None, engine='python')\n",
    "        \n",
    "        required_columns = ['nomenclature', 'category', 'description', 'characteristic', 'value']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        \n",
    "        if missing_columns:\n",
    "            raise ValueError(f\"Отсутствуют обязательные колонки: {missing_columns}\")\n",
    "        \n",
    "        print(f\"Загружено {len(df)} записей нормализованных данных\")\n",
    "        print(f\"Количество категорий: {df['category'].nunique()}\")\n",
    "        print(f\"Количество характеристик: {df['characteristic'].nunique()}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        \"\"\"Предобработка текста\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        text = str(text).lower()\n",
    "        text = re.sub(r'[^\\w\\s\\d\\.\\,\\-\\+\\/\\±]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    def analyze_characteristic_types(self, normalized_data: pd.DataFrame):\n",
    "        \"\"\"Анализ типов характеристик (текстовые/числовые)\"\"\"\n",
    "        \n",
    "        for category in normalized_data['category'].unique():\n",
    "            category_data = normalized_data[normalized_data['category'] == category]\n",
    "            \n",
    "            for char_name in category_data['characteristic'].unique():\n",
    "                char_data = category_data[category_data['characteristic'] == char_name]\n",
    "                values = char_data['value'].dropna()\n",
    "                \n",
    "                # Определяем тип характеристики\n",
    "                is_numeric = False\n",
    "                numeric_count = 0\n",
    "                total_count = len(values)\n",
    "                \n",
    "                for value in values:\n",
    "                    value_str = str(value)\n",
    "                    # Проверяем, является ли значение числовым\n",
    "                    if re.match(r'^-?\\d+[.,]?\\d*$', value_str.replace(',', '.')):\n",
    "                        numeric_count += 1\n",
    "                    # Проверяем, содержит ли значение число с единицами измерения\n",
    "                    elif re.search(r'\\d+', value_str):\n",
    "                        # Если есть число, но не только число, считаем смешанным\n",
    "                        pass\n",
    "                \n",
    "                # Если более 50% значений числовые, считаем характеристику числовой\n",
    "                if total_count > 0 and numeric_count / total_count > 0.5:\n",
    "                    self.characteristic_types[char_name] = 'numeric'\n",
    "                else:\n",
    "                    self.characteristic_types[char_name] = 'text'\n",
    "                \n",
    "                print(f\"  {char_name}: {self.characteristic_types[char_name]} \"\n",
    "                      f\"({numeric_count}/{total_count} числовых)\")\n",
    "    \n",
    "    def analyze_characteristics(self, normalized_data: pd.DataFrame):\n",
    "        \"\"\"Анализ характеристик и их значений\"\"\"\n",
    "        \n",
    "        # Анализ типов характеристик\n",
    "        self.analyze_characteristic_types(normalized_data)\n",
    "        \n",
    "        # Группируем по категориям и характеристикам\n",
    "        for category in normalized_data['category'].unique():\n",
    "            category_data = normalized_data[normalized_data['category'] == category]\n",
    "            \n",
    "            for char_name in category_data['characteristic'].unique():\n",
    "                char_data = category_data[category_data['characteristic'] == char_name]\n",
    "                \n",
    "                # Добавляем характеристику в список для категории\n",
    "                if char_name not in self.category_characteristics[category]:\n",
    "                    self.category_characteristics[category].append(char_name)\n",
    "                \n",
    "                # Для текстовых характеристик анализируем значения\n",
    "                if self.characteristic_types.get(char_name) == 'text':\n",
    "                    values = char_data['value'].dropna().unique()\n",
    "                    \n",
    "                    for value in values:\n",
    "                        value_str = str(value).lower()\n",
    "                        patterns = self._extract_patterns_from_value(value_str)\n",
    "                        for pattern in patterns:\n",
    "                            if pattern not in self.value_patterns[char_name]:\n",
    "                                self.value_patterns[char_name].append(pattern)\n",
    "        \n",
    "        print(\"Анализ характеристик завершен:\")\n",
    "        for category, chars in self.category_characteristics.items():\n",
    "            numeric_chars = [ch for ch in chars if self.characteristic_types.get(ch) == 'numeric']\n",
    "            text_chars = [ch for ch in chars if self.characteristic_types.get(ch) == 'text']\n",
    "            print(f\"  {category}: {len(chars)} характеристик \"\n",
    "                  f\"({len(numeric_chars)} числовых, {len(text_chars)} текстовых)\")\n",
    "    \n",
    "    def _extract_patterns_from_value(self, value: str) -> List[str]:\n",
    "        \"\"\"Извлечение паттернов из значений характеристик\"\"\"\n",
    "        patterns = []\n",
    "        \n",
    "        # Числовые паттерны\n",
    "        number_patterns = [\n",
    "            r'\\d+[.,]?\\d*',  # числа с плавающей точкой\n",
    "            r'\\d+',          # целые числа\n",
    "        ]\n",
    "        \n",
    "        # Текстовые паттерны\n",
    "        text_patterns = [\n",
    "            r'[a-zа-я]+',    # слова\n",
    "            r'[a-zа-я]+\\s+[a-zа-я]+',  # словосочетания\n",
    "        ]\n",
    "        \n",
    "        # Специальные паттерны (коды, модели)\n",
    "        special_patterns = [\n",
    "            r'[a-zа-я]\\d+',           # буква + цифры\n",
    "            r'\\d+[a-zа-я]',           # цифры + буква\n",
    "            r'[a-zа-я]\\d+[a-zа-я]',   # буква + цифры + буква\n",
    "            r'\\d+-\\d+',               # числа через дефис\n",
    "            r'[a-zа-я]+-\\d+',         # буквы-числа\n",
    "        ]\n",
    "        \n",
    "        # Проверяем каждый паттерн\n",
    "        all_patterns = number_patterns + text_patterns + special_patterns\n",
    "        \n",
    "        for pattern in all_patterns:\n",
    "            matches = re.findall(pattern, value, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                if len(match) > 1 and match not in patterns:\n",
    "                    patterns.append(match)\n",
    "        \n",
    "        return patterns\n",
    "    \n",
    "    def train_category_classifier(self, normalized_data: pd.DataFrame):\n",
    "        \"\"\"Обучение классификатора категорий\"\"\"\n",
    "        \n",
    "        unique_data = normalized_data.drop_duplicates(subset=['nomenclature', 'category', 'description'])\n",
    "        \n",
    "        if len(unique_data) == 0:\n",
    "            raise ValueError(\"Недостаточно данных для обучения классификатора\")\n",
    "        \n",
    "        descriptions = unique_data['description'].apply(self.preprocess_text).tolist()\n",
    "        categories = unique_data['category'].tolist()\n",
    "        \n",
    "        # Кодируем категории\n",
    "        categories_encoded = self.label_encoder.fit_transform(categories)\n",
    "        \n",
    "        # Векторизация текста\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=1000,\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words=None\n",
    "        )\n",
    "        \n",
    "        X = self.vectorizer.fit_transform(descriptions)\n",
    "        \n",
    "        # Обучение модели\n",
    "        self.category_classifier = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            class_weight='balanced'\n",
    "        )\n",
    "        \n",
    "        self.category_classifier.fit(X, categories_encoded)\n",
    "        \n",
    "        print(f\"Классификатор категорий обучен на {len(descriptions)} примерах\")\n",
    "        print(f\"Количество категорий: {len(self.label_encoder.classes_)}\")\n",
    "    \n",
    "    def predict_category(self, description: str) -> str:\n",
    "        \"\"\"Предсказание категории для описания\"\"\"\n",
    "        if self.category_classifier is None:\n",
    "            raise ValueError(\"Классификатор категорий не обучен\")\n",
    "        \n",
    "        text = self.preprocess_text(description)\n",
    "        X = self.vectorizer.transform([text])\n",
    "        y_pred = self.category_classifier.predict(X)\n",
    "        return self.label_encoder.inverse_transform(y_pred)[0]\n",
    "    \n",
    "    def extract_characteristics(self, category: str, description: str) -> Dict[str, Any]:\n",
    "        \"\"\"Извлечение характеристик для указанной категории\"\"\"\n",
    "        if category not in self.category_characteristics:\n",
    "            return {}\n",
    "        \n",
    "        characteristics = {}\n",
    "        text = self.preprocess_text(description)\n",
    "        \n",
    "        for char_name in self.category_characteristics[category]:\n",
    "            char_type = self.characteristic_types.get(char_name, 'text')\n",
    "            \n",
    "            if char_type == 'numeric':\n",
    "                # Извлечение числовой характеристики\n",
    "                value_info = self.numeric_extractor.extract_numeric_value(char_name, description)\n",
    "                if value_info:\n",
    "                    characteristics[char_name] = value_info\n",
    "                else:\n",
    "                    # Если не нашли числовое значение, пробуем текстовое извлечение\n",
    "                    text_value = self._extract_text_characteristic(char_name, text)\n",
    "                    if text_value:\n",
    "                        characteristics[char_name] = {'value': text_value, 'type': 'text'}\n",
    "            else:\n",
    "                # Извлечение текстовой характеристики\n",
    "                text_value = self._extract_text_characteristic(char_name, text)\n",
    "                if text_value:\n",
    "                    characteristics[char_name] = {'value': text_value, 'type': 'text'}\n",
    "        \n",
    "        return characteristics\n",
    "    \n",
    "    def _extract_text_characteristic(self, char_name: str, text: str) -> Optional[str]:\n",
    "        \"\"\"Извлечение текстовой характеристики\"\"\"\n",
    "        \n",
    "        # Специализированные методы для разных характеристик\n",
    "        specialized_methods = {\n",
    "            'вид продукции': self._extract_product_type,\n",
    "            'тип горелки': self._extract_burner_type,\n",
    "            'тип самоспасателя': self._extract_respirator_type,\n",
    "            'модель': self._extract_model,\n",
    "        }\n",
    "        \n",
    "        if char_name.lower() in specialized_methods:\n",
    "            return specialized_methods[char_name.lower()](text)\n",
    "        else:\n",
    "            return self._extract_general_text_characteristic(char_name, text)\n",
    "    \n",
    "    def _extract_product_type(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Извлечение вида продукции\"\"\"\n",
    "        product_types = ['горелка', 'самоспасатель']\n",
    "        \n",
    "        for product_type in product_types:\n",
    "            if product_type in text:\n",
    "                return product_type.capitalize()\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _extract_burner_type(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Извлечение типа горелки\"\"\"\n",
    "        burner_types = ['газовая', 'электрическая']\n",
    "        \n",
    "        for burner_type in burner_types:\n",
    "            if burner_type in text:\n",
    "                return burner_type\n",
    "        \n",
    "        if 'газ' in text:\n",
    "            return 'газовая'\n",
    "        elif 'электр' in text:\n",
    "            return 'электрическая'\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _extract_respirator_type(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Извлечение типа самоспасателя\"\"\"\n",
    "        respirator_types = ['изолирующий', 'фильтрующий']\n",
    "        \n",
    "        for resp_type in respirator_types:\n",
    "            if resp_type in text:\n",
    "                return resp_type\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _extract_model(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Извлечение модели/артикула\"\"\"\n",
    "        model_patterns = [\n",
    "            r'[a-zа-я]{2,}\\s*[\\-\\s]*[a-zа-я]*\\s*\\d+[\\-\\s]*\\d*[a-zа-я]*',\n",
    "            r'[a-zа-я]+\\s*\\d+[a-zа-я]*',\n",
    "            r'[a-zа-я]+\\s*\\d+[\\s\\-]*[a-zа-я]*\\s*\\d*',\n",
    "            r'[a-zа-я]+\\s*\\d+[a-zа-я]+\\s*\\d*',\n",
    "        ]\n",
    "        \n",
    "        for pattern in model_patterns:\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            if matches:\n",
    "                best_match = max(matches, key=len)\n",
    "                return best_match.upper()\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _extract_general_text_characteristic(self, char_name: str, text: str) -> Optional[str]:\n",
    "        \"\"\"Общий метод извлечения текстовых характеристик\"\"\"\n",
    "        if char_name in self.value_patterns:\n",
    "            for pattern in self.value_patterns[char_name]:\n",
    "                if pattern in text:\n",
    "                    return pattern\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def train(self, normalized_data: pd.DataFrame):\n",
    "        \"\"\"Полное обучение модели\"\"\"\n",
    "        print(\"=== ОБУЧЕНИЕ МОДЕЛИ ===\")\n",
    "        \n",
    "        # Анализ характеристик\n",
    "        self.analyze_characteristics(normalized_data)\n",
    "        \n",
    "        # Обучение классификатора категорий\n",
    "        self.train_category_classifier(normalized_data)\n",
    "        \n",
    "        self.is_trained = True\n",
    "        print(\"Модель успешно обучена\")\n",
    "    \n",
    "    def process_unnormalized_data(self, unnormalized_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Обработка ненормализованных данных\"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Модель не обучена. Сначала выполните обучение.\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for _, row in unnormalized_data.iterrows():\n",
    "            nomenclature = row.get('nomenclature', '')\n",
    "            category = row.get('category')\n",
    "            description = row.get('description', '')\n",
    "            \n",
    "            # Если категория не указана, предсказываем её\n",
    "            if pd.isna(category) or not category:\n",
    "                try:\n",
    "                    category = self.predict_category(description)\n",
    "                    predicted_category = True\n",
    "                except:\n",
    "                    category = \"unknown\"\n",
    "                    predicted_category = True\n",
    "            else:\n",
    "                predicted_category = False\n",
    "            \n",
    "            # Извлекаем характеристики\n",
    "            characteristics = self.extract_characteristics(category, description)\n",
    "            \n",
    "            # Создаем результат\n",
    "            result_row = {\n",
    "                'nomenclature': nomenclature,\n",
    "                'category': category,\n",
    "                'category_predicted': predicted_category,\n",
    "                'description': description,\n",
    "                'extracted_characteristics': characteristics\n",
    "            }\n",
    "            \n",
    "            # Добавляем отдельные колонки для каждой характеристики\n",
    "            for char_name, char_info in characteristics.items():\n",
    "                if isinstance(char_info, dict) and 'value' in char_info:\n",
    "                    result_row[char_name] = char_info['value']\n",
    "                    result_row[f'{char_name}_type'] = char_info.get('type', 'unknown')\n",
    "                    if 'unit' in char_info:\n",
    "                        result_row[f'{char_name}_unit'] = char_info['unit']\n",
    "                else:\n",
    "                    result_row[char_name] = char_info\n",
    "            \n",
    "            results.append(result_row)\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def save_model(self, filepath: str):\n",
    "        \"\"\"Сохранение модели\"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Модель не обучена\")\n",
    "        \n",
    "        model_data = {\n",
    "            'category_classifier': self.category_classifier,\n",
    "            'vectorizer': self.vectorizer,\n",
    "            'label_encoder': self.label_encoder,\n",
    "            'category_characteristics': dict(self.category_characteristics),\n",
    "            'characteristic_types': dict(self.characteristic_types),\n",
    "            'value_patterns': dict(self.value_patterns),\n",
    "            'is_trained': self.is_trained\n",
    "        }\n",
    "        \n",
    "        joblib.dump(model_data, filepath)\n",
    "        print(f\"Модель сохранена в {filepath}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(cls, filepath: str) -> 'EnhancedNomenclatureParser':\n",
    "        \"\"\"Загрузка модели\"\"\"\n",
    "        model_data = joblib.load(filepath)\n",
    "        \n",
    "        parser = cls()\n",
    "        parser.category_classifier = model_data['category_classifier']\n",
    "        parser.vectorizer = model_data['vectorizer']\n",
    "        parser.label_encoder = model_data['label_encoder']\n",
    "        parser.category_characteristics = defaultdict(list, model_data['category_characteristics'])\n",
    "        parser.characteristic_types = defaultdict(str, model_data['characteristic_types'])\n",
    "        parser.value_patterns = defaultdict(list, model_data['value_patterns'])\n",
    "        parser.is_trained = model_data['is_trained']\n",
    "        \n",
    "        print(f\"Модель загружена из {filepath}\")\n",
    "        return parser\n",
    "\n",
    "# Пример использования с числовыми характеристиками\n",
    "def create_sample_data_with_numeric() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Создание примера данных с числовыми характеристиками\"\"\"\n",
    "    \n",
    "    # Нормализованные данные\n",
    "    normalized_data = pd.DataFrame({\n",
    "        'nomenclature': ['1267', '1267', '1267', '1267', '1324', '1324', '1324', '1324'],\n",
    "        'category': ['Горелки теплотехнические'] * 4 + ['Самоспасатели'] * 4,\n",
    "        'description': [\n",
    "            'Горелка газовая ЗСУ-ПИ-38-350-IP65',\n",
    "            'Горелка газовая ЗСУ-ПИ-38-350-IP65', \n",
    "            'Горелка газовая ЗСУ-ПИ-38-350-IP65',\n",
    "            'Горелка газовая ЗСУ-ПИ-38-350-IP65',\n",
    "            'Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011',\n",
    "            'Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011',\n",
    "            'Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011',\n",
    "            'Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011'\n",
    "        ],\n",
    "        'characteristic': [\n",
    "            'Вид продукции', 'Тип горелки', 'Модель', 'Мощность',\n",
    "            'Вид продукции', 'Тип самоспасателя', 'Модель', 'Время защиты'\n",
    "        ],\n",
    "        'value': [\n",
    "            'Горелка', 'газовая', 'ЗСУ-ПИ-38-350-IP65', '350',\n",
    "            'Самоспасатель', 'изолирующий', 'СПИ-20', '20'\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Ненормализованные данные\n",
    "    unnormalized_data = pd.DataFrame({\n",
    "        'nomenclature': ['1234', '5678', '91011'],\n",
    "        'category': ['Горелки теплотехнические', None, 'Самоспасатели'],\n",
    "        'description': [\n",
    "            'Горелка газовая мощностью 350 кВт модель ЗСУ-ПИ-38-350',\n",
    "            'Электрическая горелка мощность 250 кВт диаметр 150 мм',\n",
    "            'Самоспасатель изолирующий время защиты 25 минут вес 2.5 кг'\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    return normalized_data, unnormalized_data\n",
    "\n",
    "def main():\n",
    "    \"\"\"Основная функция демонстрации\"\"\"\n",
    "    print(\"=== УЛУЧШЕННАЯ СИСТЕМА ПАРСИНГА С ЧИСЛОВЫМИ ХАРАКТЕРИСТИКАМИ ===\\n\")\n",
    "    \n",
    "    # Инициализация парсера\n",
    "    parser = EnhancedNomenclatureParser()\n",
    "    \n",
    "    try:\n",
    "        # Загрузка или создание данных\n",
    "        print(\"1. ПОДГОТОВКА ДАННЫХ...\")\n",
    "        normalized_data, unnormalized_data = create_sample_data_with_numeric()\n",
    "        \n",
    "        print(\"Нормализованные данные:\")\n",
    "        print(normalized_data)\n",
    "        print(\"\\nДанные для обработки:\")\n",
    "        print(unnormalized_data)\n",
    "        \n",
    "        # Обучение модели\n",
    "        print(\"\\n2. ОБУЧЕНИЕ МОДЕЛИ...\")\n",
    "        parser.train(normalized_data)\n",
    "        \n",
    "        # Обработка данных\n",
    "        print(\"\\n3. ОБРАБОТКА ДАННЫХ...\")\n",
    "        results = parser.process_unnormalized_data(unnormalized_data)\n",
    "        \n",
    "        print(\"\\n4. РЕЗУЛЬТАТЫ ОБРАБОТКИ:\")\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', 1000)\n",
    "        print(results)\n",
    "        \n",
    "        # Детальный анализ извлеченных характеристик\n",
    "        print(\"\\n5. ДЕТАЛЬНЫЙ АНАЛИЗ ХАРАКТЕРИСТИК:\")\n",
    "        for _, row in results.iterrows():\n",
    "            print(f\"\\nНоменклатура: {row['nomenclature']}\")\n",
    "            print(f\"Категория: {row['category']}\")\n",
    "            if 'extracted_characteristics' in row and row['extracted_characteristics']:\n",
    "                for char_name, char_info in row['extracted_characteristics'].items():\n",
    "                    print(f\"  {char_name}: {char_info}\")\n",
    "        \n",
    "        # Сохранение модели\n",
    "        print(\"\\n6. СОХРАНЕНИЕ МОДЕЛИ...\")\n",
    "        parser.save_model('enhanced_nomenclature_parser.pkl')\n",
    "        \n",
    "        return parser, results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7048e4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== УЛУЧШЕННАЯ СИСТЕМА ПАРСИНГА С ЧИСЛОВЫМИ ХАРАКТЕРИСТИКАМИ ===\n",
      "\n",
      "1. ПОДГОТОВКА ДАННЫХ...\n",
      "Нормализованные данные:\n",
      "  nomenclature                  category  \\\n",
      "0         1267  Горелки теплотехнические   \n",
      "1         1267  Горелки теплотехнические   \n",
      "2         1267  Горелки теплотехнические   \n",
      "3         1267  Горелки теплотехнические   \n",
      "4         1324             Самоспасатели   \n",
      "5         1324             Самоспасатели   \n",
      "6         1324             Самоспасатели   \n",
      "7         1324             Самоспасатели   \n",
      "\n",
      "                                       description     characteristic  \\\n",
      "0               Горелка газовая ЗСУ-ПИ-38-350-IP65      Вид продукции   \n",
      "1               Горелка газовая ЗСУ-ПИ-38-350-IP65        Тип горелки   \n",
      "2               Горелка газовая ЗСУ-ПИ-38-350-IP65             Модель   \n",
      "3               Горелка газовая ЗСУ-ПИ-38-350-IP65           Мощность   \n",
      "4  Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011      Вид продукции   \n",
      "5  Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011  Тип самоспасателя   \n",
      "6  Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011             Модель   \n",
      "7  Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011       Время защиты   \n",
      "\n",
      "                value  \n",
      "0             Горелка  \n",
      "1             газовая  \n",
      "2  ЗСУ-ПИ-38-350-IP65  \n",
      "3                 350  \n",
      "4       Самоспасатель  \n",
      "5         изолирующий  \n",
      "6              СПИ-20  \n",
      "7                  20  \n",
      "\n",
      "Данные для обработки:\n",
      "  nomenclature                  category  \\\n",
      "0         1234  Горелки теплотехнические   \n",
      "1         5678                      None   \n",
      "2        91011             Самоспасатели   \n",
      "\n",
      "                                         description  \n",
      "0  Горелка газовая мощностью 350 кВт модель ЗСУ-П...  \n",
      "1  Электрическая горелка мощность 250 кВт диаметр...  \n",
      "2  Самоспасатель изолирующий время защиты 25 мину...  \n",
      "\n",
      "2. ОБУЧЕНИЕ МОДЕЛИ...\n",
      "=== ОБУЧЕНИЕ МОДЕЛИ ===\n",
      "  Вид продукции: text (0/1 числовых)\n",
      "  Тип горелки: text (0/1 числовых)\n",
      "  Модель: text (0/1 числовых)\n",
      "  Мощность: numeric (1/1 числовых)\n",
      "  Вид продукции: text (0/1 числовых)\n",
      "  Тип самоспасателя: text (0/1 числовых)\n",
      "  Модель: text (0/1 числовых)\n",
      "  Время защиты: numeric (1/1 числовых)\n",
      "Анализ характеристик завершен:\n",
      "  Горелки теплотехнические: 4 характеристик (1 числовых, 3 текстовых)\n",
      "  Самоспасатели: 4 характеристик (1 числовых, 3 текстовых)\n",
      "Классификатор категорий обучен на 2 примерах\n",
      "Количество категорий: 2\n",
      "Модель успешно обучена\n",
      "\n",
      "3. ОБРАБОТКА ДАННЫХ...\n",
      "\n",
      "4. РЕЗУЛЬТАТЫ ОБРАБОТКИ:\n",
      "  nomenclature                  category  category_predicted                                        description                          extracted_characteristics  Вид продукции Вид продукции_type    Тип горелки Тип горелки_type                     Модель Модель_type Тип самоспасателя Тип самоспасателя_type\n",
      "0         1234  Горелки теплотехнические               False  Горелка газовая мощностью 350 кВт модель ЗСУ-П...  {'Вид продукции': {'value': 'Горелка', 'type':...        Горелка               text        газовая             text  ГАЗОВАЯ МОЩНОСТЬЮ 350 КВТ        text               NaN                    NaN\n",
      "1         5678  Горелки теплотехнические                True  Электрическая горелка мощность 250 кВт диаметр...  {'Вид продукции': {'value': 'Горелка', 'type':...        Горелка               text  электрическая             text   ГОРЕЛКА МОЩНОСТЬ 250 КВТ        text               NaN                    NaN\n",
      "2        91011             Самоспасатели               False  Самоспасатель изолирующий время защиты 25 мину...  {'Вид продукции': {'value': 'Самоспасатель', '...  Самоспасатель               text            NaN              NaN      ВРЕМЯ ЗАЩИТЫ 25 МИНУТ        text       изолирующий                   text\n",
      "\n",
      "5. ДЕТАЛЬНЫЙ АНАЛИЗ ХАРАКТЕРИСТИК:\n",
      "\n",
      "Номенклатура: 1234\n",
      "Категория: Горелки теплотехнические\n",
      "  Вид продукции: {'value': 'Горелка', 'type': 'text'}\n",
      "  Тип горелки: {'value': 'газовая', 'type': 'text'}\n",
      "  Модель: {'value': 'ГАЗОВАЯ МОЩНОСТЬЮ 350 КВТ', 'type': 'text'}\n",
      "\n",
      "Номенклатура: 5678\n",
      "Категория: Горелки теплотехнические\n",
      "  Вид продукции: {'value': 'Горелка', 'type': 'text'}\n",
      "  Тип горелки: {'value': 'электрическая', 'type': 'text'}\n",
      "  Модель: {'value': 'ГОРЕЛКА МОЩНОСТЬ 250 КВТ', 'type': 'text'}\n",
      "\n",
      "Номенклатура: 91011\n",
      "Категория: Самоспасатели\n",
      "  Вид продукции: {'value': 'Самоспасатель', 'type': 'text'}\n",
      "  Тип самоспасателя: {'value': 'изолирующий', 'type': 'text'}\n",
      "  Модель: {'value': 'ВРЕМЯ ЗАЩИТЫ 25 МИНУТ', 'type': 'text'}\n",
      "\n",
      "6. СОХРАНЕНИЕ МОДЕЛИ...\n",
      "Модель сохранена в enhanced_nomenclature_parser.pkl\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser, results = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d69e43f",
   "metadata": {},
   "source": [
    "## Отчет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ad3c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "def analyze_processing_results(processed_data: pd.DataFrame, parser=None):\n",
    "    \"\"\"Расширенный анализ результатов обработки с учетом числовых характеристик\"\"\"\n",
    "    print(\"=== РАСШИРЕННЫЙ АНАЛИЗ РЕЗУЛЬТАТОВ ===\")\n",
    "    \n",
    "    # Базовая статистика\n",
    "    print(f\"\\n1. ОБЩАЯ СТАТИСТИКА:\")\n",
    "    print(f\"   Всего обработано записей: {len(processed_data)}\")\n",
    "    print(f\"   Уникальных номенклатур: {processed_data['nomenclature'].nunique()}\")\n",
    "    print(f\"   Уникальных категорий: {processed_data['category'].nunique()}\")\n",
    "    \n",
    "    # Статистика по категориям\n",
    "    print(f\"\\n2. РАСПРЕДЕЛЕНИЕ ПО КАТЕГОРИЯМ:\")\n",
    "    category_stats = processed_data['category'].value_counts()\n",
    "    for category, count in category_stats.items():\n",
    "        print(f\"   {category}: {count} записей ({count/len(processed_data)*100:.1f}%)\")\n",
    "    \n",
    "    # Статистика по предсказанным категориям\n",
    "    if 'category_predicted' in processed_data.columns:\n",
    "        predicted_stats = processed_data['category_predicted'].value_counts()\n",
    "        print(f\"\\n3. СТАТИСТИКА ПРЕДСКАЗАНИЯ КАТЕГОРИЙ:\")\n",
    "        print(f\"   Предсказано категорий: {predicted_stats.get(True, 0)}\")\n",
    "        print(f\"   Известно категорий: {predicted_stats.get(False, 0)}\")\n",
    "    \n",
    "    # Анализ характеристик\n",
    "    print(f\"\\n4. АНАЛИЗ ИЗВЛЕЧЕННЫХ ХАРАКТЕРИСТИК:\")\n",
    "    \n",
    "    # Находим колонки с характеристиками (исключаем служебные)\n",
    "    service_columns = ['nomenclature', 'category', 'description', 'category_predicted', 'extracted_characteristics']\n",
    "    characteristic_cols = [col for col in processed_data.columns if col not in service_columns]\n",
    "    \n",
    "    # Разделяем на основные характеристики и дополнительные поля (unit, type)\n",
    "    main_characteristics = []\n",
    "    additional_fields = []\n",
    "    \n",
    "    for col in characteristic_cols:\n",
    "        if any(col.endswith(suffix) for suffix in ['_type', '_unit', '_original']):\n",
    "            additional_fields.append(col)\n",
    "        else:\n",
    "            main_characteristics.append(col)\n",
    "    \n",
    "    print(f\"   Всего извлечено характеристик: {len(main_characteristics)}\")\n",
    "    \n",
    "    # Анализ каждой характеристики\n",
    "    char_analysis = []\n",
    "    for char in main_characteristics:\n",
    "        char_data = processed_data[char]\n",
    "        fill_rate = char_data.notna().mean() * 100\n",
    "        unique_values = char_data.nunique()\n",
    "        \n",
    "        # Определяем тип характеристики\n",
    "        char_type = \"неизвестно\"\n",
    "        type_col = f\"{char}_type\"\n",
    "        if type_col in processed_data.columns:\n",
    "            type_values = processed_data[type_col].dropna().unique()\n",
    "            if len(type_values) > 0:\n",
    "                char_type = type_values[0]\n",
    "        \n",
    "        # Анализ единиц измерения для числовых характеристик\n",
    "        unit_info = \"\"\n",
    "        unit_col = f\"{char}_unit\"\n",
    "        if unit_col in processed_data.columns:\n",
    "            units = processed_data[unit_col].dropna().unique()\n",
    "            if len(units) > 0:\n",
    "                unit_info = f\", единицы: {', '.join(map(str, units))}\"\n",
    "        \n",
    "        char_analysis.append({\n",
    "            'characteristic': char,\n",
    "            'fill_rate': fill_rate,\n",
    "            'unique_values': unique_values,\n",
    "            'type': char_type,\n",
    "            'unit_info': unit_info\n",
    "        })\n",
    "        \n",
    "        print(f\"   ├─ {char}:\")\n",
    "        print(f\"   │  Заполнено: {fill_rate:.1f}%\")\n",
    "        print(f\"   │  Уникальных значений: {unique_values}\")\n",
    "        print(f\"   │  Тип: {char_type}{unit_info}\")\n",
    "    \n",
    "    # Анализ числовых характеристик\n",
    "    numeric_chars = [char for char in char_analysis if char['type'] == 'numeric']\n",
    "    if numeric_chars:\n",
    "        print(f\"\\n5. АНАЛИЗ ЧИСЛОВЫХ ХАРАКТЕРИСТИК:\")\n",
    "        for char_info in numeric_chars:\n",
    "            char_name = char_info['characteristic']\n",
    "            numeric_data = processed_data[char_name].dropna()\n",
    "            \n",
    "            if len(numeric_data) > 0:\n",
    "                # Преобразуем в числа, если возможно\n",
    "                try:\n",
    "                    numeric_series = pd.to_numeric(numeric_data, errors='coerce')\n",
    "                    numeric_series = numeric_series.dropna()\n",
    "                    \n",
    "                    if len(numeric_series) > 0:\n",
    "                        print(f\"   ├─ {char_name}:\")\n",
    "                        print(f\"   │  Минимум: {numeric_series.min():.2f}\")\n",
    "                        print(f\"   │  Максимум: {numeric_series.max():.2f}\")\n",
    "                        print(f\"   │  Среднее: {numeric_series.mean():.2f}\")\n",
    "                        print(f\"   │  Медиана: {numeric_series.median():.2f}\")\n",
    "                        print(f\"   │  Стандартное отклонение: {numeric_series.std():.2f}\")\n",
    "                except:\n",
    "                    print(f\"   ├─ {char_name}: не удалось проанализировать числовые значения\")\n",
    "    \n",
    "    # Анализ качества извлечения по категориям\n",
    "    if parser and hasattr(parser, 'category_characteristics'):\n",
    "        print(f\"\\n6. АНАЛИЗ ПОЛНОТЫ ИЗВЛЕЧЕНИЯ ПО КАТЕГОРИЯМ:\")\n",
    "        for category in processed_data['category'].unique():\n",
    "            category_data = processed_data[processed_data['category'] == category]\n",
    "            expected_chars = parser.category_characteristics.get(category, [])\n",
    "            \n",
    "            if expected_chars:\n",
    "                extracted_count = 0\n",
    "                for char in expected_chars:\n",
    "                    if char in processed_data.columns:\n",
    "                        fill_rate = category_data[char].notna().mean() * 100\n",
    "                        extracted_count += 1 if fill_rate > 0 else 0\n",
    "                \n",
    "                completeness = extracted_count / len(expected_chars) * 100\n",
    "                print(f\"   ├─ {category}:\")\n",
    "                print(f\"   │  Ожидаемые характеристики: {len(expected_chars)}\")\n",
    "                print(f\"   │  Извлеченные характеристики: {extracted_count}\")\n",
    "                print(f\"   │  Полнота извлечения: {completeness:.1f}%\")\n",
    "    \n",
    "    # Анализ сложных случаев\n",
    "    print(f\"\\n7. АНАЛИЗ СЛОЖНЫХ СЛУЧАЕВ:\")\n",
    "    \n",
    "    # Записи без извлеченных характеристик\n",
    "    empty_records = processed_data[processed_data[main_characteristics].isna().all(axis=1)]\n",
    "    if len(empty_records) > 0:\n",
    "        print(f\"   Записей без извлеченных характеристик: {len(empty_records)}\")\n",
    "        for _, record in empty_records.head(3).iterrows():\n",
    "            print(f\"     - {record['nomenclature']}: {record['description'][:50]}...\")\n",
    "    \n",
    "    # Записи с частично извлеченными характеристиками\n",
    "    if parser and hasattr(parser, 'category_characteristics'):\n",
    "        partial_records = []\n",
    "        for _, record in processed_data.iterrows():\n",
    "            category = record['category']\n",
    "            expected_chars = parser.category_characteristics.get(category, [])\n",
    "            if expected_chars:\n",
    "                extracted_chars = sum(1 for char in expected_chars \n",
    "                                   if char in record and pd.notna(record.get(char)))\n",
    "                if 0 < extracted_chars < len(expected_chars):\n",
    "                    partial_records.append((record, extracted_chars, len(expected_chars)))\n",
    "        \n",
    "        if partial_records:\n",
    "            print(f\"   Записей с частичным извлечением: {len(partial_records)}\")\n",
    "            for record, extracted, total in partial_records[:3]:\n",
    "                print(f\"     - {record['nomenclature']}: {extracted}/{total} характеристик\")\n",
    "    \n",
    "    return {\n",
    "        'total_records': len(processed_data),\n",
    "        'categories_count': processed_data['category'].nunique(),\n",
    "        'characteristics_count': len(main_characteristics),\n",
    "        'characteristics_analysis': char_analysis,\n",
    "        'numeric_characteristics_count': len(numeric_chars),\n",
    "        'empty_records_count': len(empty_records) if 'empty_records' in locals() else 0\n",
    "    }\n",
    "\n",
    "def export_results_to_excel(processed_data: pd.DataFrame, filename: str, parser=None):\n",
    "    \"\"\"Расширенный экспорт результатов в Excel с учетом числовых характеристик\"\"\"\n",
    "    \n",
    "    with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
    "        # Основные результаты\n",
    "        processed_data.to_excel(writer, sheet_name='Результаты', index=False)\n",
    "        \n",
    "        # Статистика характеристик\n",
    "        service_columns = ['nomenclature', 'category', 'description', 'category_predicted', 'extracted_characteristics']\n",
    "        characteristic_cols = [col for col in processed_data.columns if col not in service_columns]\n",
    "        \n",
    "        main_characteristics = [col for col in characteristic_cols \n",
    "                              if not any(col.endswith(suffix) for suffix in ['_type', '_unit', '_original'])]\n",
    "        \n",
    "        stats_data = []\n",
    "        for char in main_characteristics:\n",
    "            char_data = processed_data[char]\n",
    "            fill_rate = char_data.notna().mean() * 100\n",
    "            unique_values = char_data.nunique()\n",
    "            \n",
    "            # Тип характеристики\n",
    "            char_type = \"неизвестно\"\n",
    "            type_col = f\"{char}_type\"\n",
    "            if type_col in processed_data.columns:\n",
    "                type_values = processed_data[type_col].dropna().unique()\n",
    "                if len(type_values) > 0:\n",
    "                    char_type = type_values[0]\n",
    "            \n",
    "            # Единицы измерения\n",
    "            units = \"\"\n",
    "            unit_col = f\"{char}_unit\"\n",
    "            if unit_col in processed_data.columns:\n",
    "                unit_values = processed_data[unit_col].dropna().unique()\n",
    "                if len(unit_values) > 0:\n",
    "                    units = ', '.join(map(str, unit_values))\n",
    "            \n",
    "            stats_data.append({\n",
    "                'Характеристика': char,\n",
    "                'Тип': char_type,\n",
    "                'Заполнено (%)': fill_rate,\n",
    "                'Уникальных значений': unique_values,\n",
    "                'Единицы измерения': units\n",
    "            })\n",
    "        \n",
    "        stats_df = pd.DataFrame(stats_data)\n",
    "        stats_df.to_excel(writer, sheet_name='Статистика характеристик', index=False)\n",
    "        \n",
    "        # Распределение по категориям\n",
    "        category_stats = processed_data['category'].value_counts().reset_index()\n",
    "        category_stats.columns = ['Категория', 'Количество']\n",
    "        category_stats.to_excel(writer, sheet_name='Распределение по категориям', index=False)\n",
    "        \n",
    "        # Детальный анализ числовых характеристик\n",
    "        numeric_stats_data = []\n",
    "        for char in main_characteristics:\n",
    "            type_col = f\"{char}_type\"\n",
    "            if type_col in processed_data.columns and processed_data[type_col].notna().any():\n",
    "                if 'numeric' in processed_data[type_col].values:\n",
    "                    numeric_data = processed_data[char].dropna()\n",
    "                    if len(numeric_data) > 0:\n",
    "                        try:\n",
    "                            numeric_series = pd.to_numeric(numeric_data, errors='coerce').dropna()\n",
    "                            if len(numeric_series) > 0:\n",
    "                                numeric_stats_data.append({\n",
    "                                    'Характеристика': char,\n",
    "                                    'Минимум': numeric_series.min(),\n",
    "                                    'Максимум': numeric_series.max(),\n",
    "                                    'Среднее': numeric_series.mean(),\n",
    "                                    'Медиана': numeric_series.median(),\n",
    "                                    'Стандартное отклонение': numeric_series.std(),\n",
    "                                    'Количество значений': len(numeric_series)\n",
    "                                })\n",
    "                        except:\n",
    "                            pass\n",
    "        \n",
    "        if numeric_stats_data:\n",
    "            numeric_stats_df = pd.DataFrame(numeric_stats_data)\n",
    "            numeric_stats_df.to_excel(writer, sheet_name='Числовые характеристики', index=False)\n",
    "        \n",
    "        # Анализ полноты извлечения по категориям\n",
    "        if parser and hasattr(parser, 'category_characteristics'):\n",
    "            completeness_data = []\n",
    "            for category in processed_data['category'].unique():\n",
    "                category_data = processed_data[processed_data['category'] == category]\n",
    "                expected_chars = parser.category_characteristics.get(category, [])\n",
    "                \n",
    "                if expected_chars:\n",
    "                    category_stats = {'Категория': category}\n",
    "                    for char in expected_chars:\n",
    "                        if char in processed_data.columns:\n",
    "                            fill_rate = category_data[char].notna().mean() * 100\n",
    "                            category_stats[char] = f\"{fill_rate:.1f}%\"\n",
    "                        else:\n",
    "                            category_stats[char] = \"0%\"\n",
    "                    \n",
    "                    completeness_data.append(category_stats)\n",
    "            \n",
    "            if completeness_data:\n",
    "                completeness_df = pd.DataFrame(completeness_data)\n",
    "                completeness_df.to_excel(writer, sheet_name='Полнота извлечения', index=False)\n",
    "    \n",
    "    print(f\"Результаты экспортированы в {filename}\")\n",
    "\n",
    "def create_detailed_report(processed_data: pd.DataFrame, parser=None, filename: str = \"детальный_отчет.html\"):\n",
    "    \"\"\"Создание детального HTML отчета\"\"\"\n",
    "    \n",
    "    analysis_results = analyze_processing_results(processed_data, parser)\n",
    "    \n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>Детальный отчет по парсингу характеристик</title>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; margin: 20px; }}\n",
    "            .section {{ margin-bottom: 30px; }}\n",
    "            .metric {{ margin: 10px 0; }}\n",
    "            .characteristic {{ margin: 5px 0; padding: 5px; background: #f5f5f5; }}\n",
    "            .numeric {{ border-left: 4px solid #4CAF50; }}\n",
    "            .text {{ border-left: 4px solid #2196F3; }}\n",
    "            table {{ border-collapse: collapse; width: 100%; }}\n",
    "            th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
    "            th {{ background-color: #f2f2f2; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Детальный отчет по парсингу характеристик</h1>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>Общая статистика</h2>\n",
    "            <div class=\"metric\">Всего обработано записей: {analysis_results['total_records']}</div>\n",
    "            <div class=\"metric\">Уникальных категорий: {analysis_results['categories_count']}</div>\n",
    "            <div class=\"metric\">Извлеченных характеристик: {analysis_results['characteristics_count']}</div>\n",
    "            <div class=\"metric\">Числовых характеристик: {analysis_results['numeric_characteristics_count']}</div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>Анализ характеристик</h2>\n",
    "    \"\"\"\n",
    "    \n",
    "    for char_info in analysis_results['characteristics_analysis']:\n",
    "        type_class = 'numeric' if char_info['type'] == 'numeric' else 'text'\n",
    "        html_content += f\"\"\"\n",
    "            <div class=\"characteristic {type_class}\">\n",
    "                <strong>{char_info['characteristic']}</strong><br>\n",
    "                Тип: {char_info['type']} | Заполнено: {char_info['fill_rate']:.1f}% | \n",
    "                Уникальных значений: {char_info['unique_values']}\n",
    "                {char_info['unit_info']}\n",
    "            </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>Примеры данных</h2>\n",
    "            <table>\n",
    "                <tr>\n",
    "                    <th>Номенклатура</th>\n",
    "                    <th>Категория</th>\n",
    "                    <th>Описание</th>\n",
    "                    <th>Извлеченные характеристики</th>\n",
    "                </tr>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Добавляем несколько примеров\n",
    "    for _, row in processed_data.head(5).iterrows():\n",
    "        characteristics = []\n",
    "        for col in processed_data.columns:\n",
    "            if col not in ['nomenclature', 'category', 'description', 'category_predicted', 'extracted_characteristics']:\n",
    "                if pd.notna(row[col]):\n",
    "                    characteristics.append(f\"{col}: {row[col]}\")\n",
    "        \n",
    "        html_content += f\"\"\"\n",
    "                <tr>\n",
    "                    <td>{row['nomenclature']}</td>\n",
    "                    <td>{row['category']}</td>\n",
    "                    <td>{row['description'][:100]}...</td>\n",
    "                    <td>{'<br>'.join(characteristics)}</td>\n",
    "                </tr>\n",
    "        \"\"\"\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "            </table>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    print(f\"Детальный отчет создан: {filename}\")\n",
    "\n",
    "def validate_parsing_quality(processed_data: pd.DataFrame, test_data_with_truth: pd.DataFrame):\n",
    "    \"\"\"Валидация качества парсинга на тестовых данных с известными значениями\"\"\"\n",
    "    print(\"=== ВАЛИДАЦИЯ КАЧЕСТВА ПАРСИНГА ===\")\n",
    "    \n",
    "    if test_data_with_truth.empty:\n",
    "        print(\"Нет тестовых данных для валидации\")\n",
    "        return\n",
    "    \n",
    "    # Проверяем совпадение категорий\n",
    "    if 'true_category' in test_data_with_truth.columns and 'category' in processed_data.columns:\n",
    "        correct_categories = 0\n",
    "        total_categories = 0\n",
    "        \n",
    "        for _, test_row in test_data_with_truth.iterrows():\n",
    "            nomenclature = test_row['nomenclature']\n",
    "            true_category = test_row['true_category']\n",
    "            \n",
    "            # Ищем соответствующую запись в обработанных данных\n",
    "            processed_row = processed_data[processed_data['nomenclature'] == nomenclature]\n",
    "            if not processed_row.empty:\n",
    "                predicted_category = processed_row.iloc[0]['category']\n",
    "                if predicted_category == true_category:\n",
    "                    correct_categories += 1\n",
    "                total_categories += 1\n",
    "        \n",
    "        if total_categories > 0:\n",
    "            accuracy = correct_categories / total_categories * 100\n",
    "            print(f\"Точность определения категории: {accuracy:.1f}% ({correct_categories}/{total_categories})\")\n",
    "    \n",
    "    # Проверяем извлечение характеристик\n",
    "    print(\"\\nКачество извлечения характеристик:\")\n",
    "    characteristic_cols = [col for col in processed_data.columns \n",
    "                         if col not in ['nomenclature', 'category', 'description', 'category_predicted', 'extracted_characteristics']]\n",
    "    \n",
    "    for char_col in characteristic_cols:\n",
    "        if char_col in test_data_with_truth.columns:\n",
    "            correct_values = 0\n",
    "            total_values = 0\n",
    "            \n",
    "            for _, test_row in test_data_with_truth.iterrows():\n",
    "                nomenclature = test_row['nomenclature']\n",
    "                true_value = test_row[char_col]\n",
    "                \n",
    "                if pd.notna(true_value):\n",
    "                    processed_row = processed_data[processed_data['nomenclature'] == nomenclature]\n",
    "                    if not processed_row.empty and pd.notna(processed_row.iloc[0].get(char_col)):\n",
    "                        predicted_value = processed_row.iloc[0][char_col]\n",
    "                        # Простое сравнение значений\n",
    "                        if str(predicted_value) == str(true_value):\n",
    "                            correct_values += 1\n",
    "                        total_values += 1\n",
    "            \n",
    "            if total_values > 0:\n",
    "                accuracy = correct_values / total_values * 100\n",
    "                print(f\"  {char_col}: {accuracy:.1f}% ({correct_values}/{total_values})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1820602e",
   "metadata": {},
   "source": [
    "## Запуск отчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64ded422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== УЛУЧШЕННАЯ СИСТЕМА ПАРСИНГА С ЧИСЛОВЫМИ ХАРАКТЕРИСТИКАМИ ===\n",
      "\n",
      "1. ПОДГОТОВКА ДАННЫХ...\n",
      "Нормализованные данные:\n",
      "  nomenclature                  category                                      description     characteristic               value\n",
      "0         1267  Горелки теплотехнические               Горелка газовая ЗСУ-ПИ-38-350-IP65      Вид продукции             Горелка\n",
      "1         1267  Горелки теплотехнические               Горелка газовая ЗСУ-ПИ-38-350-IP65        Тип горелки             газовая\n",
      "2         1267  Горелки теплотехнические               Горелка газовая ЗСУ-ПИ-38-350-IP65             Модель  ЗСУ-ПИ-38-350-IP65\n",
      "3         1267  Горелки теплотехнические               Горелка газовая ЗСУ-ПИ-38-350-IP65           Мощность                 350\n",
      "4         1324             Самоспасатели  Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011      Вид продукции       Самоспасатель\n",
      "5         1324             Самоспасатели  Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011  Тип самоспасателя         изолирующий\n",
      "6         1324             Самоспасатели  Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011             Модель              СПИ-20\n",
      "7         1324             Самоспасатели  Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011       Время защиты                  20\n",
      "\n",
      "Данные для обработки:\n",
      "  nomenclature                  category                                        description\n",
      "0         1234  Горелки теплотехнические  Горелка газовая мощностью 350 кВт модель ЗСУ-П...\n",
      "1         5678                      None  Электрическая горелка мощность 250 кВт диаметр...\n",
      "2        91011             Самоспасатели  Самоспасатель изолирующий время защиты 25 мину...\n",
      "\n",
      "2. ОБУЧЕНИЕ МОДЕЛИ...\n",
      "=== ОБУЧЕНИЕ МОДЕЛИ ===\n",
      "  Вид продукции: text (0/1 числовых)\n",
      "  Тип горелки: text (0/1 числовых)\n",
      "  Модель: text (0/1 числовых)\n",
      "  Мощность: numeric (1/1 числовых)\n",
      "  Вид продукции: text (0/1 числовых)\n",
      "  Тип самоспасателя: text (0/1 числовых)\n",
      "  Модель: text (0/1 числовых)\n",
      "  Время защиты: numeric (1/1 числовых)\n",
      "Анализ характеристик завершен:\n",
      "  Горелки теплотехнические: 4 характеристик (1 числовых, 3 текстовых)\n",
      "  Самоспасатели: 4 характеристик (1 числовых, 3 текстовых)\n",
      "Классификатор категорий обучен на 2 примерах\n",
      "Количество категорий: 2\n",
      "Модель успешно обучена\n",
      "\n",
      "3. ОБРАБОТКА ДАННЫХ...\n",
      "\n",
      "4. РЕЗУЛЬТАТЫ ОБРАБОТКИ:\n",
      "  nomenclature                  category  category_predicted                                        description                          extracted_characteristics  Вид продукции Вид продукции_type    Тип горелки Тип горелки_type                     Модель Модель_type Тип самоспасателя Тип самоспасателя_type\n",
      "0         1234  Горелки теплотехнические               False  Горелка газовая мощностью 350 кВт модель ЗСУ-П...  {'Вид продукции': {'value': 'Горелка', 'type':...        Горелка               text        газовая             text  ГАЗОВАЯ МОЩНОСТЬЮ 350 КВТ        text               NaN                    NaN\n",
      "1         5678  Горелки теплотехнические                True  Электрическая горелка мощность 250 кВт диаметр...  {'Вид продукции': {'value': 'Горелка', 'type':...        Горелка               text  электрическая             text   ГОРЕЛКА МОЩНОСТЬ 250 КВТ        text               NaN                    NaN\n",
      "2        91011             Самоспасатели               False  Самоспасатель изолирующий время защиты 25 мину...  {'Вид продукции': {'value': 'Самоспасатель', '...  Самоспасатель               text            NaN              NaN      ВРЕМЯ ЗАЩИТЫ 25 МИНУТ        text       изолирующий                   text\n",
      "\n",
      "5. ДЕТАЛЬНЫЙ АНАЛИЗ ХАРАКТЕРИСТИК:\n",
      "\n",
      "Номенклатура: 1234\n",
      "Категория: Горелки теплотехнические\n",
      "  Вид продукции: {'value': 'Горелка', 'type': 'text'}\n",
      "  Тип горелки: {'value': 'газовая', 'type': 'text'}\n",
      "  Модель: {'value': 'ГАЗОВАЯ МОЩНОСТЬЮ 350 КВТ', 'type': 'text'}\n",
      "\n",
      "Номенклатура: 5678\n",
      "Категория: Горелки теплотехнические\n",
      "  Вид продукции: {'value': 'Горелка', 'type': 'text'}\n",
      "  Тип горелки: {'value': 'электрическая', 'type': 'text'}\n",
      "  Модель: {'value': 'ГОРЕЛКА МОЩНОСТЬ 250 КВТ', 'type': 'text'}\n",
      "\n",
      "Номенклатура: 91011\n",
      "Категория: Самоспасатели\n",
      "  Вид продукции: {'value': 'Самоспасатель', 'type': 'text'}\n",
      "  Тип самоспасателя: {'value': 'изолирующий', 'type': 'text'}\n",
      "  Модель: {'value': 'ВРЕМЯ ЗАЩИТЫ 25 МИНУТ', 'type': 'text'}\n",
      "\n",
      "6. СОХРАНЕНИЕ МОДЕЛИ...\n",
      "Модель сохранена в enhanced_nomenclature_parser.pkl\n",
      "\n",
      "============================================================\n",
      "АНАЛИЗ РЕЗУЛЬТАТОВ С ПОМОЩЬЮ УТИЛИТ\n",
      "============================================================\n",
      "=== РАСШИРЕННЫЙ АНАЛИЗ РЕЗУЛЬТАТОВ ===\n",
      "\n",
      "1. ОБЩАЯ СТАТИСТИКА:\n",
      "   Всего обработано записей: 3\n",
      "   Уникальных номенклатур: 3\n",
      "   Уникальных категорий: 2\n",
      "\n",
      "2. РАСПРЕДЕЛЕНИЕ ПО КАТЕГОРИЯМ:\n",
      "   Горелки теплотехнические: 2 записей (66.7%)\n",
      "   Самоспасатели: 1 записей (33.3%)\n",
      "\n",
      "3. СТАТИСТИКА ПРЕДСКАЗАНИЯ КАТЕГОРИЙ:\n",
      "   Предсказано категорий: 1\n",
      "   Известно категорий: 2\n",
      "\n",
      "4. АНАЛИЗ ИЗВЛЕЧЕННЫХ ХАРАКТЕРИСТИК:\n",
      "   Всего извлечено характеристик: 4\n",
      "   ├─ Вид продукции:\n",
      "   │  Заполнено: 100.0%\n",
      "   │  Уникальных значений: 2\n",
      "   │  Тип: text\n",
      "   ├─ Тип горелки:\n",
      "   │  Заполнено: 66.7%\n",
      "   │  Уникальных значений: 2\n",
      "   │  Тип: text\n",
      "   ├─ Модель:\n",
      "   │  Заполнено: 100.0%\n",
      "   │  Уникальных значений: 3\n",
      "   │  Тип: text\n",
      "   ├─ Тип самоспасателя:\n",
      "   │  Заполнено: 33.3%\n",
      "   │  Уникальных значений: 1\n",
      "   │  Тип: text\n",
      "\n",
      "6. АНАЛИЗ ПОЛНОТЫ ИЗВЛЕЧЕНИЯ ПО КАТЕГОРИЯМ:\n",
      "   ├─ Горелки теплотехнические:\n",
      "   │  Ожидаемые характеристики: 4\n",
      "   │  Извлеченные характеристики: 3\n",
      "   │  Полнота извлечения: 75.0%\n",
      "   ├─ Самоспасатели:\n",
      "   │  Ожидаемые характеристики: 4\n",
      "   │  Извлеченные характеристики: 3\n",
      "   │  Полнота извлечения: 75.0%\n",
      "\n",
      "7. АНАЛИЗ СЛОЖНЫХ СЛУЧАЕВ:\n",
      "   Записей с частичным извлечением: 3\n",
      "     - 1234: 3/4 характеристик\n",
      "     - 5678: 3/4 характеристик\n",
      "     - 91011: 3/4 характеристик\n",
      "Результаты экспортированы в результаты_парсинга.xlsx\n",
      "=== РАСШИРЕННЫЙ АНАЛИЗ РЕЗУЛЬТАТОВ ===\n",
      "\n",
      "1. ОБЩАЯ СТАТИСТИКА:\n",
      "   Всего обработано записей: 3\n",
      "   Уникальных номенклатур: 3\n",
      "   Уникальных категорий: 2\n",
      "\n",
      "2. РАСПРЕДЕЛЕНИЕ ПО КАТЕГОРИЯМ:\n",
      "   Горелки теплотехнические: 2 записей (66.7%)\n",
      "   Самоспасатели: 1 записей (33.3%)\n",
      "\n",
      "3. СТАТИСТИКА ПРЕДСКАЗАНИЯ КАТЕГОРИЙ:\n",
      "   Предсказано категорий: 1\n",
      "   Известно категорий: 2\n",
      "\n",
      "4. АНАЛИЗ ИЗВЛЕЧЕННЫХ ХАРАКТЕРИСТИК:\n",
      "   Всего извлечено характеристик: 4\n",
      "   ├─ Вид продукции:\n",
      "   │  Заполнено: 100.0%\n",
      "   │  Уникальных значений: 2\n",
      "   │  Тип: text\n",
      "   ├─ Тип горелки:\n",
      "   │  Заполнено: 66.7%\n",
      "   │  Уникальных значений: 2\n",
      "   │  Тип: text\n",
      "   ├─ Модель:\n",
      "   │  Заполнено: 100.0%\n",
      "   │  Уникальных значений: 3\n",
      "   │  Тип: text\n",
      "   ├─ Тип самоспасателя:\n",
      "   │  Заполнено: 33.3%\n",
      "   │  Уникальных значений: 1\n",
      "   │  Тип: text\n",
      "\n",
      "6. АНАЛИЗ ПОЛНОТЫ ИЗВЛЕЧЕНИЯ ПО КАТЕГОРИЯМ:\n",
      "   ├─ Горелки теплотехнические:\n",
      "   │  Ожидаемые характеристики: 4\n",
      "   │  Извлеченные характеристики: 3\n",
      "   │  Полнота извлечения: 75.0%\n",
      "   ├─ Самоспасатели:\n",
      "   │  Ожидаемые характеристики: 4\n",
      "   │  Извлеченные характеристики: 3\n",
      "   │  Полнота извлечения: 75.0%\n",
      "\n",
      "7. АНАЛИЗ СЛОЖНЫХ СЛУЧАЕВ:\n",
      "   Записей с частичным извлечением: 3\n",
      "     - 1234: 3/4 характеристик\n",
      "     - 5678: 3/4 характеристик\n",
      "     - 91011: 3/4 характеристик\n",
      "Детальный отчет создан: детальный_отчет.html\n",
      "\n",
      "Анализ завершен!\n"
     ]
    }
   ],
   "source": [
    "# Основной скрипт (добавьте в конец)\n",
    "if __name__ == \"__main__\":\n",
    "    # ... ваш существующий код ...\n",
    "    \n",
    "    parser, results = main()\n",
    "    \n",
    "    # Используем утилиты для анализа\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"АНАЛИЗ РЕЗУЛЬТАТОВ С ПОМОЩЬЮ УТИЛИТ\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Анализ результатов\n",
    "    analysis_results = analyze_processing_results(results, parser)\n",
    "    \n",
    "    # Экспорт в Excel\n",
    "    export_results_to_excel(results, 'результаты_парсинга.xlsx', parser)\n",
    "    \n",
    "    # Создание HTML отчета\n",
    "    create_detailed_report(results, parser, 'детальный_отчет.html')\n",
    "    \n",
    "    print(\"\\nАнализ завершен!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21db91e2",
   "metadata": {},
   "source": [
    "## Обновление данных\n",
    "\n",
    "Краткий план действий:\n",
    "Автоматическое обновление - просто переобучить на новых данных\n",
    "\n",
    "Ручная настройка - добавить специализированные методы для сложных случаев\n",
    "\n",
    "Конфигурационная система - для максимальной гибкости\n",
    "\n",
    "Тестирование - проверить качество на новых классах\n",
    "\n",
    "Мониторинг - отслеживать производительность\n",
    "\n",
    "Система спроектирована так, чтобы минимизировать ручную работу при добавлении новых классов!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d111da4",
   "metadata": {},
   "source": [
    "При добавлении новых классов с новыми характеристиками потребуется несколько шагов для адаптации системы. Вот полный план действий:\n",
    "\n",
    "1. Автоматическое обновление (минимальные изменения)\n",
    "Система уже частично поддерживает автоматическое обновление:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5382f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если новые данные в том же формате - просто переобучить модель\n",
    "def update_model_with_new_data(parser, new_normalized_data):\n",
    "    \"\"\"Автоматическое обновление модели с новыми данными\"\"\"\n",
    "    print(\"=== ОБНОВЛЕНИЕ МОДЕЛИ С НОВЫМИ ДАННЫМИ ===\")\n",
    "    \n",
    "    # Просто переобучаем модель на объединенных данных\n",
    "    parser.train(new_normalized_data)\n",
    "    \n",
    "    print(\"Модель успешно обновлена!\")\n",
    "    print(f\"Новые классы: {list(parser.category_characteristics.keys())}\")\n",
    "    \n",
    "    return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6abcad",
   "metadata": {},
   "source": [
    "2. Ручное обновление для сложных случаев\n",
    "Если новые классы требуют специальных правил извлечения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "796a9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedNomenclatureParser(EnhancedNomenclatureParser):\n",
    "    \"\"\"Расширенный парсер с поддержкой новых классов\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Добавляем специализированные методы для новых классов\n",
    "        self.specialized_methods.update({\n",
    "            'трубы': self._extract_pipe_characteristics,\n",
    "            'кабели': self._extract_cable_characteristics,\n",
    "            'арматура': self._extract_fittings_characteristics,\n",
    "        })\n",
    "        \n",
    "        # Добавляем паттерны для новых характеристик\n",
    "        self.numeric_extractor.numeric_patterns.update({\n",
    "            'толщина стенки': [\n",
    "                r'толщина стенки[:\\s]*(\\d+[.,]?\\d*)\\s*(мм|см)?',\n",
    "                r'стенка[:\\s]*(\\d+[.,]?\\d*)\\s*(мм|см)?',\n",
    "            ],\n",
    "            'сечение': [\n",
    "                r'сечение[:\\s]*(\\d+[.,]?\\d*)\\s*(мм2|мм²|мм\\^2)?',\n",
    "                r'(\\d+[.,]?\\d*)\\s*(мм2|мм²)\\s*сечение',\n",
    "            ],\n",
    "            'диаметр условный': [\n",
    "                r'ду[:\\s]*(\\d+[.,]?\\d*)\\s*(мм)?',\n",
    "                r'условный диаметр[:\\s]*(\\d+[.,]?\\d*)\\s*(мм)?',\n",
    "            ]\n",
    "        })\n",
    "    \n",
    "    def _extract_pipe_characteristics(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Извлечение характеристик для труб\"\"\"\n",
    "        characteristics = {}\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Материал трубы\n",
    "        materials = ['пнд', 'пвх', 'пп', 'сталь', 'чугун', 'медь']\n",
    "        for material in materials:\n",
    "            if material in text_lower:\n",
    "                characteristics['материал'] = material.upper()\n",
    "                break\n",
    "        \n",
    "        # Тип трубы\n",
    "        if 'напорная' in text_lower:\n",
    "            characteristics['тип трубы'] = 'напорная'\n",
    "        elif 'безнапорная' in text_lower:\n",
    "            characteristics['тип трубы'] = 'безнапорная'\n",
    "        \n",
    "        return characteristics\n",
    "    \n",
    "    def _extract_cable_characteristics(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Извлечение характеристик для кабелей\"\"\"\n",
    "        characteristics = {}\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Марка кабеля\n",
    "        cable_brands = ['ввг', 'ввгнг', 'пвс', 'шввп', 'кабель', 'провод']\n",
    "        for brand in cable_brands:\n",
    "            if brand in text_lower:\n",
    "                characteristics['марка'] = brand.upper()\n",
    "                break\n",
    "        \n",
    "        # Количество жил\n",
    "        cores_match = re.search(r'(\\d+)\\s*[хx]\\s*(\\d+)', text_lower)\n",
    "        if cores_match:\n",
    "            characteristics['жилы'] = f\"{cores_match.group(1)}x{cores_match.group(2)}\"\n",
    "        \n",
    "        return characteristics\n",
    "    \n",
    "    def _extract_fittings_characteristics(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Извлечение характеристик для арматуры\"\"\"\n",
    "        characteristics = {}\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Тип соединения\n",
    "        connections = ['резьба', 'фланец', 'сварка', 'муфта']\n",
    "        for connection in connections:\n",
    "            if connection in text_lower:\n",
    "                characteristics['тип соединения'] = connection\n",
    "                break\n",
    "        \n",
    "        return characteristics\n",
    "    \n",
    "    def _extract_single_characteristic(self, char_name: str, text: str) -> Optional[str]:\n",
    "        \"\"\"Переопределяем метод для поддержки новых классов\"\"\"\n",
    "        # Сначала пробуем специализированные методы\n",
    "        category = self._infer_category_from_text(text)\n",
    "        if category in self.specialized_methods:\n",
    "            specialized_chars = self.specialized_methods[category](text)\n",
    "            if char_name in specialized_chars:\n",
    "                return specialized_chars[char_name]\n",
    "        \n",
    "        # Затем стандартные методы\n",
    "        return super()._extract_single_characteristic(char_name, text)\n",
    "    \n",
    "    def _infer_category_from_text(self, text: str) -> str:\n",
    "        \"\"\"Определяем категорию по тексту для специализированных методов\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        if any(word in text_lower for word in ['труба', 'трубка', 'трубопровод']):\n",
    "            return 'трубы'\n",
    "        elif any(word in text_lower for word in ['кабель', 'провод', 'кабельный']):\n",
    "            return 'кабели'\n",
    "        elif any(word in text_lower for word in ['арматура', 'фитинг', 'муфта', 'отвод']):\n",
    "            return 'арматура'\n",
    "        else:\n",
    "            return 'общий'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac7c938",
   "metadata": {},
   "source": [
    "## добавление с YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f388fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.py\n",
    "import yaml\n",
    "\n",
    "CLASS_CONFIG = \"\"\"\n",
    "# Конфигурация классов и их характеристик\n",
    "классы:\n",
    "  горелки теплотехнические:\n",
    "    тип: оборудование\n",
    "    характеристики:\n",
    "      вид продукции:\n",
    "        тип: текст\n",
    "        паттерны: [\"горелка\", \"burner\"]\n",
    "        обязательная: true\n",
    "      \n",
    "      тип горелки:\n",
    "        тип: текст  \n",
    "        паттерны: [\"газовая\", \"электрическая\"]\n",
    "        значения: [\"газовая\", \"электрическая\"]\n",
    "      \n",
    "      мощность:\n",
    "        тип: числовая\n",
    "        единицы: [\"квт\", \"вт\"]\n",
    "        паттерны: [\"мощность\", \"power\"]\n",
    "      \n",
    "      модель:\n",
    "        тип: текст\n",
    "        паттерны: [\"модель\", \"model\", \"артикул\"]\n",
    "\n",
    "  трубы:\n",
    "    тип: материалы\n",
    "    характеристики:\n",
    "      материал:\n",
    "        тип: текст\n",
    "        паттерны: [\"материал\", \"material\"]\n",
    "        значения: [\"ПНД\", \"ПВХ\", \"ПП\", \"сталь\"]\n",
    "      \n",
    "      диаметр:\n",
    "        тип: числовая\n",
    "        единицы: [\"мм\", \"дюйм\"]\n",
    "        паттерны: [\"диаметр\", \"ø\", \"dn\"]\n",
    "      \n",
    "      толщина стенки:\n",
    "        тип: числовая\n",
    "        единицы: [\"мм\"]\n",
    "        паттерны: [\"толщина стенки\", \"стенка\"]\n",
    "      \n",
    "      длина:\n",
    "        тип: числовая\n",
    "        единицы: [\"м\", \"мм\"]\n",
    "        паттерны: [\"длина\", \"length\"]\n",
    "\n",
    "  кабели:\n",
    "    тип: материалы  \n",
    "    характеристики:\n",
    "      марка:\n",
    "        тип: текст\n",
    "        паттерны: [\"марка\", \"brand\"]\n",
    "        значения: [\"ВВГ\", \"ВВГнг\", \"ПВС\", \"ШВВП\"]\n",
    "      \n",
    "      сечение:\n",
    "        тип: числовая\n",
    "        единицы: [\"мм2\", \"мм²\"]\n",
    "        паттерны: [\"сечение\", \"площадь\"]\n",
    "      \n",
    "      количество жил:\n",
    "        тип: числовая\n",
    "        паттерны: [\"жилы\", \"cores\", \"количество жил\"]\n",
    "      \n",
    "      напряжение:\n",
    "        тип: числовая\n",
    "        единицы: [\"в\", \"вольт\"]\n",
    "        паттерны: [\"напряжение\", \"voltage\"]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd805030",
   "metadata": {},
   "source": [
    "## Установка зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d8477f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in c:\\users\\vasil\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (6.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\vasil\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vasil\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\vasil\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.13.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\vasil\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\vasil\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vasil\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vasil\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vasil\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vasil\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vasil\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vasil\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\vasil\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vasil\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\vasil\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vasil\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "DEPRECATION: desc 2.1.1 has a non-standard dependency specifier matplotlib>=2.2pydot. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of desc or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml pandas scikit-learn rapidfuzz joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c872b8f",
   "metadata": {},
   "source": [
    "## Создание конфигурируемого парсера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "484d5522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurable_parser.py\n",
    "import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import Dict, List, Any, Optional\n",
    "#from enhanced_nomenclature_parser import EnhancedNomenclatureParser\n",
    "\n",
    "class ConfigurableNomenclatureParser(EnhancedNomenclatureParser):\n",
    "    \"\"\"\n",
    "    Универсальный парсер с конфигурацией из YAML-файла\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: str = \"config.yaml\"):\n",
    "        super().__init__()\n",
    "        self.config_path = config_path\n",
    "        self.config = self._load_config()\n",
    "        self._apply_config()\n",
    "        print(\"Конфигурируемый парсер инициализирован\")\n",
    "    \n",
    "    def _load_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Загрузка конфигурации из YAML-файла\"\"\"\n",
    "        if not os.path.exists(self.config_path):\n",
    "            raise FileNotFoundError(f\"Конфигурационный файл не найден: {self.config_path}\")\n",
    "        \n",
    "        with open(self.config_path, 'r', encoding='utf-8') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        \n",
    "        print(f\"Загружена конфигурация для {len(config.get('классы', {}))} классов\")\n",
    "        return config\n",
    "    \n",
    "    def _apply_config(self):\n",
    "        \"\"\"Применение конфигурации к парсеру\"\"\"\n",
    "        if 'классы' not in self.config:\n",
    "            print(\"В конфигурации не найдены классы\")\n",
    "            return\n",
    "        \n",
    "        # Очищаем существующие характеристики\n",
    "        self.category_characteristics.clear()\n",
    "        self.characteristic_types.clear()\n",
    "        \n",
    "        # Загружаем классы и их характеристики из конфигурации\n",
    "        for class_name, class_config in self.config['классы'].items():\n",
    "            if 'характеристики' in class_config:\n",
    "                characteristics = list(class_config['характеристики'].keys())\n",
    "                self.category_characteristics[class_name] = characteristics\n",
    "                \n",
    "                # Устанавливаем типы характеристик\n",
    "                for char_name, char_config in class_config['характеристики'].items():\n",
    "                    self.characteristic_types[char_name] = char_config.get('тип', 'текст')\n",
    "        \n",
    "        # Обновляем паттерны для числового экстрактора\n",
    "        self._update_numeric_patterns()\n",
    "        \n",
    "        print(\"Конфигурация применена успешно\")\n",
    "    \n",
    "    def _update_numeric_patterns(self):\n",
    "        \"\"\"Обновление паттернов для числовых характеристик\"\"\"\n",
    "        for class_name, class_config in self.config['классы'].items():\n",
    "            if 'характеристики' in class_config:\n",
    "                for char_name, char_config in class_config['характеристики'].items():\n",
    "                    if char_config.get('тип') == 'числовая':\n",
    "                        patterns = self._create_numeric_patterns(char_name, char_config)\n",
    "                        self.numeric_extractor.numeric_patterns[char_name] = patterns\n",
    "    \n",
    "    def _create_numeric_patterns(self, char_name: str, char_config: Dict) -> List[str]:\n",
    "        \"\"\"Создание паттернов для числовой характеристики\"\"\"\n",
    "        patterns = []\n",
    "        units = \"|\".join(char_config.get('единицы', ['']))\n",
    "        \n",
    "        for pattern in char_config.get('паттерны', []):\n",
    "            # Паттерн: характеристика: число единица\n",
    "            patterns.append(f\"{pattern}[\\\\s:]*([\\\\d.,]+)\\\\s*({units})?\")\n",
    "            # Паттерн: число единица характеристика\n",
    "            patterns.append(f\"([\\\\d.,]+)\\\\s*({units})?\\\\s*{pattern}\")\n",
    "        \n",
    "        return patterns\n",
    "    \n",
    "    def add_new_class(self, class_name: str, characteristics_config: Dict):\n",
    "        \"\"\"Динамическое добавление нового класса\"\"\"\n",
    "        if class_name not in self.config['классы']:\n",
    "            self.config['классы'][class_name] = characteristics_config\n",
    "            self._apply_config()\n",
    "            print(f\"Добавлен новый класс: {class_name}\")\n",
    "        else:\n",
    "            print(f\"Класс {class_name} уже существует\")\n",
    "    \n",
    "    def update_class(self, class_name: str, characteristics_config: Dict):\n",
    "        \"\"\"Обновление существующего класса\"\"\"\n",
    "        if class_name in self.config['классы']:\n",
    "            self.config['классы'][class_name] = characteristics_config\n",
    "            self._apply_config()\n",
    "            print(f\"Класс {class_name} обновлен\")\n",
    "        else:\n",
    "            print(f\"Класс {class_name} не найден\")\n",
    "    \n",
    "    def save_config(self, config_path: str = None):\n",
    "        \"\"\"Сохранение текущей конфигурации в файл\"\"\"\n",
    "        save_path = config_path or self.config_path\n",
    "        \n",
    "        with open(save_path, 'w', encoding='utf-8') as f:\n",
    "            yaml.dump(self.config, f, allow_unicode=True, default_flow_style=False)\n",
    "        \n",
    "        print(f\"Конфигурация сохранена в {save_path}\")\n",
    "    \n",
    "    def get_class_info(self, class_name: str) -> Dict:\n",
    "        \"\"\"Получение информации о классе\"\"\"\n",
    "        return self.config['классы'].get(class_name, {})\n",
    "    \n",
    "    def list_classes(self) -> List[str]:\n",
    "        \"\"\"Список всех классов\"\"\"\n",
    "        return list(self.config['классы'].keys())\n",
    "    \n",
    "    def get_characteristics_for_class(self, class_name: str) -> List[str]:\n",
    "        \"\"\"Получение характеристик для класса\"\"\"\n",
    "        class_config = self.config['классы'].get(class_name, {})\n",
    "        return list(class_config.get('характеристики', {}).keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3058bb",
   "metadata": {},
   "source": [
    "## Использование конфигурируемого парсера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90b58bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ИНИЦИАЛИЗАЦИЯ КОНФИГУРИРУЕМОГО ПАРСЕРА ===\n",
      "Загружена конфигурация для 4 классов\n",
      "Конфигурация применена успешно\n",
      "Конфигурируемый парсер инициализирован\n",
      "\n",
      "Доступные классы:\n",
      "  горелки теплотехнические: 4 характеристик\n",
      "  самоспасатели: 4 характеристик\n",
      "  трубы: 4 характеристик\n",
      "  кабели: 4 характеристик\n",
      "\n",
      "=== ЗАГРУЗКА ДАННЫХ ДЛЯ ОБУЧЕНИЯ ===\n",
      "Файл с нормализованными данными не найден, создаем демо-данные...\n",
      "=== ОБУЧЕНИЕ МОДЕЛИ ===\n",
      "  вид продукции: text (0/1 числовых)\n",
      "  тип горелки: text (0/1 числовых)\n",
      "  модель: text (0/1 числовых)\n",
      "  вид продукции: text (0/1 числовых)\n",
      "  тип самоспасателя: text (0/1 числовых)\n",
      "  модель: text (0/1 числовых)\n",
      "Анализ характеристик завершен:\n",
      "  горелки теплотехнические: 4 характеристик (0 числовых, 3 текстовых)\n",
      "  самоспасатели: 4 характеристик (0 числовых, 3 текстовых)\n",
      "  трубы: 4 характеристик (0 числовых, 0 текстовых)\n",
      "  кабели: 4 характеристик (0 числовых, 0 текстовых)\n",
      "Классификатор категорий обучен на 2 примерах\n",
      "Количество категорий: 2\n",
      "Модель успешно обучена\n",
      "\n",
      "=== ОБРАБОТКА ТЕСТОВЫХ ДАННЫХ ===\n",
      "\n",
      "Результаты обработки:\n",
      "\n",
      "Номенклатура: 001\n",
      "Категория: трубы\n",
      "Описание: Труба ПНД диаметр 32 мм толщина стенки 3 мм длина 6 м\n",
      "\n",
      "Номенклатура: 002\n",
      "Категория: горелки теплотехнические\n",
      "Описание: Кабель ВВГнг 3х2.5 сечение 2.5 мм² напряжение 660В\n",
      "  модель: КАБЕЛЬ ВВГНГ 3Х\n",
      "  модель_type: text\n",
      "\n",
      "Номенклатура: 003\n",
      "Категория: кабели\n",
      "Описание: Провод ПВС 2х1.5 длина 50 м\n",
      "\n",
      "Номенклатура: 004\n",
      "Категория: горелки теплотехнические\n",
      "Описание: Горелка газовая модель ZSU-PI-38 мощность 350 кВт\n",
      "  модель: PI-38 МОЩНОСТЬ\n",
      "  модель_type: text\n",
      "  вид продукции: Горелка\n",
      "  вид продукции_type: text\n",
      "  тип горелки: газовая\n",
      "  тип горелки_type: text\n",
      "\n",
      "=== СОХРАНЕНИЕ МОДЕЛИ ===\n",
      "Модель сохранена в configurable_parser.pkl\n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "#from configurable_parser import ConfigurableNomenclatureParser\n",
    "import pandas as pd\n",
    "\n",
    "def main():\n",
    "    # 1. Инициализация парсера с конфигурацией\n",
    "    print(\"=== ИНИЦИАЛИЗАЦИЯ КОНФИГУРИРУЕМОГО ПАРСЕРА ===\")\n",
    "    parser = ConfigurableNomenclatureParser(\"config.yaml\")\n",
    "    \n",
    "    # 2. Просмотр доступных классов\n",
    "    print(\"\\nДоступные классы:\")\n",
    "    for class_name in parser.list_classes():\n",
    "        characteristics = parser.get_characteristics_for_class(class_name)\n",
    "        print(f\"  {class_name}: {len(characteristics)} характеристик\")\n",
    "    \n",
    "    # 3. Загрузка нормализованных данных для обучения\n",
    "    print(\"\\n=== ЗАГРУЗКА ДАННЫХ ДЛЯ ОБУЧЕНИЯ ===\")\n",
    "    try:\n",
    "        normalized_data = parser.load_normalized_data(\"normalized.txt\")\n",
    "        \n",
    "        # 4. Обучение модели\n",
    "        print(\"\\n=== ОБУЧЕНИЕ МОДЕЛИ ===\")\n",
    "        parser.train(normalized_data)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Файл с нормализованными данными не найден, создаем демо-данные...\")\n",
    "        normalized_data = create_demo_data()\n",
    "        parser.train(normalized_data)\n",
    "    \n",
    "    # 5. Обработка тестовых данных\n",
    "    print(\"\\n=== ОБРАБОТКА ТЕСТОВЫХ ДАННЫХ ===\")\n",
    "    test_data = pd.DataFrame({\n",
    "        'nomenclature': ['001', '002', '003', '004'],\n",
    "        'category': ['трубы', None, 'кабели', 'горелки теплотехнические'],\n",
    "        'description': [\n",
    "            'Труба ПНД диаметр 32 мм толщина стенки 3 мм длина 6 м',\n",
    "            'Кабель ВВГнг 3х2.5 сечение 2.5 мм² напряжение 660В',\n",
    "            'Провод ПВС 2х1.5 длина 50 м',\n",
    "            'Горелка газовая модель ZSU-PI-38 мощность 350 кВт'\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    results = parser.process_unnormalized_data(test_data)\n",
    "    \n",
    "    print(\"\\nРезультаты обработки:\")\n",
    "    for _, row in results.iterrows():\n",
    "        print(f\"\\nНоменклатура: {row['nomenclature']}\")\n",
    "        print(f\"Категория: {row['category']}\")\n",
    "        print(f\"Описание: {row['description']}\")\n",
    "        \n",
    "        # Выводим извлеченные характеристики\n",
    "        for col in results.columns:\n",
    "            if col not in ['nomenclature', 'category', 'description', 'category_predicted', 'extracted_characteristics']:\n",
    "                if pd.notna(row[col]):\n",
    "                    print(f\"  {col}: {row[col]}\")\n",
    "    \n",
    "    # 6. Сохранение модели\n",
    "    print(\"\\n=== СОХРАНЕНИЕ МОДЕЛИ ===\")\n",
    "    parser.save_model('configurable_parser.pkl')\n",
    "    \n",
    "    return parser, results\n",
    "\n",
    "def create_demo_data():\n",
    "    \"\"\"Создание демонстрационных данных\"\"\"\n",
    "    return pd.DataFrame({\n",
    "        'nomenclature': ['1267', '1267', '1267', '2356', '2356', '2356'],\n",
    "        'category': ['горелки теплотехнические', 'горелки теплотехнические', 'горелки теплотехнические', \n",
    "                    'самоспасатели', 'самоспасатели', 'самоспасатели'],\n",
    "        'description': [\n",
    "            'Горелка газовая ЗСУ-ПИ-38-350-IP65',\n",
    "            'Горелка газовая ЗСУ-ПИ-38-350-IP65',\n",
    "            'Горелка газовая ЗСУ-ПИ-38-350-IP65',\n",
    "            'Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011',\n",
    "            'Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011',\n",
    "            'Самоспасатель изолирующий СПИ-20 ТР ТС 019/2011'\n",
    "        ],\n",
    "        'characteristic': ['вид продукции', 'тип горелки', 'модель', \n",
    "                          'вид продукции', 'тип самоспасателя', 'модель'],\n",
    "        'value': ['Горелка', 'газовая', 'ЗСУ-ПИ-38-350-IP65',\n",
    "                 'Самоспасатель', 'изолирующий', 'СПИ-20 ТР ТС 019/2011']\n",
    "    })\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser, results = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31e1494",
   "metadata": {},
   "source": [
    "## Динамическое добавление новых классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34db48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Существующая модель загружена\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'add_new_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m                     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[col]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 75\u001b[0m     parser \u001b[38;5;241m=\u001b[39m \u001b[43madd_new_classes_dynamically\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     test_new_class(parser)\n",
      "Cell \u001b[1;32mIn[33], line 41\u001b[0m, in \u001b[0;36madd_new_classes_dynamically\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m new_class_config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mтип\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mматериалы\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mхарактеристики\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     }\n\u001b[0;32m     38\u001b[0m }\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Добавление нового класса\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_new_class\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mарматура\u001b[39m\u001b[38;5;124m'\u001b[39m, new_class_config)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Сохранение обновленной конфигурации\u001b[39;00m\n\u001b[0;32m     44\u001b[0m parser\u001b[38;5;241m.\u001b[39msave_config(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig_updated.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'add_new_class'"
     ]
    }
   ],
   "source": [
    "# add_new_classes.py\n",
    "#from configurable_parser import ConfigurableNomenclatureParser\n",
    "import joblib\n",
    "\n",
    "def add_new_classes_dynamically():\n",
    "    \"\"\"Пример динамического добавления новых классов\"\"\"\n",
    "    \n",
    "    # Загрузка существующей модели\n",
    "    try:\n",
    "        parser = joblib.load('configurable_parser.pkl')\n",
    "        print(\"Существующая модель загружена\")\n",
    "    except:\n",
    "        parser = ConfigurableNomenclatureParser(\"config.yaml\")\n",
    "        print(\"Создана новая модель\")\n",
    "    \n",
    "    # Конфигурация нового класса \"арматура\"\n",
    "    new_class_config = {\n",
    "        'тип': 'материалы',\n",
    "        'характеристики': {\n",
    "            'тип арматуры': {\n",
    "                'тип': 'текст',\n",
    "                'паттерны': ['арматура', 'фитинг', 'муфта'],\n",
    "                'значения': ['отвод', 'тройник', 'муфта', 'переходник']\n",
    "            },\n",
    "            'диаметр': {\n",
    "                'тип': 'числовая',\n",
    "                'единицы': ['мм', 'дюйм'],\n",
    "                'паттерны': ['диаметр', 'ø', 'размер'],\n",
    "                'минимальное_значение': 15,\n",
    "                'максимальное_значение': 300\n",
    "            },\n",
    "            'материал': {\n",
    "                'тип': 'текст',\n",
    "                'паттерны': ['материал', 'сталь', 'пластик'],\n",
    "                'значения': ['сталь', 'ПНД', 'ПП', 'латунь']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Добавление нового класса\n",
    "    parser.add_new_class('арматура', new_class_config)\n",
    "    \n",
    "    # Сохранение обновленной конфигурации\n",
    "    parser.save_config(\"config_updated.yaml\")\n",
    "    \n",
    "    # Сохранение обновленной модели\n",
    "    parser.save_model('configurable_parser_updated.pkl')\n",
    "    \n",
    "    print(\"Новый класс 'арматура' успешно добавлен\")\n",
    "    print(f\"Характеристики: {parser.get_characteristics_for_class('арматура')}\")\n",
    "    \n",
    "    return parser\n",
    "\n",
    "# Тестирование нового класса\n",
    "def test_new_class(parser):\n",
    "    \"\"\"Тестирование нового класса\"\"\"\n",
    "    test_data = pd.DataFrame({\n",
    "        'nomenclature': ['005'],\n",
    "        'category': ['арматура'],\n",
    "        'description': ['Отвод стальной диаметр 50 мм для трубопровода']\n",
    "    })\n",
    "    \n",
    "    results = parser.process_unnormalized_data(test_data)\n",
    "    \n",
    "    print(\"\\nТестирование нового класса:\")\n",
    "    for _, row in results.iterrows():\n",
    "        print(f\"Номенклатура: {row['nomenclature']}\")\n",
    "        print(f\"Категория: {row['category']}\")\n",
    "        for col in results.columns:\n",
    "            if col not in ['nomenclature', 'category', 'description', 'category_predicted']:\n",
    "                if pd.notna(row[col]):\n",
    "                    print(f\"  {col}: {row[col]}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = add_new_classes_dynamically()\n",
    "    test_new_class(parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7dbb46",
   "metadata": {},
   "source": [
    "## Процесс добавления новых классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afb5cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow.py\n",
    "def complete_workflow_for_new_classes():\n",
    "    \"\"\"Полный процесс добавления новых классов\"\"\"\n",
    "    \n",
    "    # 1. Загрузка существующей модели\n",
    "    try:\n",
    "        parser = EnhancedNomenclatureParser.load_model('enhanced_nomenclature_parser.pkl')\n",
    "        print(\"Существующая модель загружена\")\n",
    "    except:\n",
    "        parser = EnhancedNomenclatureParser()\n",
    "        print(\"Создана новая модель\")\n",
    "    \n",
    "    # 2. Загрузка новых данных\n",
    "    new_data = pd.read_csv('новые_данные.csv')\n",
    "    print(f\"Загружено {len(new_data)} новых записей\")\n",
    "    \n",
    "    # 3. Анализ новых классов\n",
    "    new_categories = new_data['category'].unique()\n",
    "    print(f\"Новые классы: {list(new_categories)}\")\n",
    "    \n",
    "    # 4. Автоматическое обновление\n",
    "    parser = update_model_with_new_data(parser, new_data)\n",
    "    \n",
    "    # 5. При необходимости - ручная настройка\n",
    "    if 'трубы' in new_categories:\n",
    "        extended_parser = ExtendedNomenclatureParser()\n",
    "        # ... перенос обученных моделей ...\n",
    "    \n",
    "    # 6. Тестирование\n",
    "    test_results = test_new_classes(parser, new_data)\n",
    "    \n",
    "    # 7. Сохранение обновленной модели\n",
    "    parser.save_model('nomenclature_parser_updated.pkl')\n",
    "    \n",
    "    return parser\n",
    "\n",
    "def test_new_classes(parser, test_data):\n",
    "    \"\"\"Тестирование на новых классах\"\"\"\n",
    "    print(\"=== ТЕСТИРОВАНИЕ НОВЫХ КЛАССОВ ===\")\n",
    "    \n",
    "    results = parser.process_unnormalized_data(test_data)\n",
    "    \n",
    "    # Анализ эффективности для новых классов\n",
    "    new_categories = test_data['category'].unique()\n",
    "    \n",
    "    for category in new_categories:\n",
    "        category_data = results[results['category'] == category]\n",
    "        expected_chars = parser.category_characteristics.get(category, [])\n",
    "        \n",
    "        print(f\"\\nКласс: {category}\")\n",
    "        print(f\"Обработано записей: {len(category_data)}\")\n",
    "        print(f\"Ожидаемые характеристики: {expected_chars}\")\n",
    "        \n",
    "        # Анализ заполнения характеристик\n",
    "        for char in expected_chars:\n",
    "            if char in category_data.columns:\n",
    "                fill_rate = category_data[char].notna().mean() * 100\n",
    "                print(f\"  {char}: {fill_rate:.1f}% заполнено\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7710bf",
   "metadata": {},
   "source": [
    "## Утилиты для мониторинга и обновления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cb1a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitoring.py\n",
    "def monitor_model_performance(parser, new_data):\n",
    "    \"\"\"Мониторинг производительности модели на новых данных\"\"\"\n",
    "    \n",
    "    performance_report = {\n",
    "        'new_classes': [],\n",
    "        'characteristics_coverage': {},\n",
    "        'recommendations': []\n",
    "    }\n",
    "    \n",
    "    for category in new_data['category'].unique():\n",
    "        category_data = new_data[new_data['category'] == category]\n",
    "        \n",
    "        if category not in parser.category_characteristics:\n",
    "            performance_report['new_classes'].append(category)\n",
    "            performance_report['recommendations'].append(\n",
    "                f\"Добавить правила извлечения для класса '{category}'\"\n",
    "            )\n",
    "            continue\n",
    "        \n",
    "        # Анализ покрытия характеристик\n",
    "        expected_chars = parser.category_characteristics[category]\n",
    "        extracted_chars = []\n",
    "        \n",
    "        for desc in category_data['description'].head(10):  # Тестируем на выборке\n",
    "            extracted = parser.extract_characteristics(category, desc)\n",
    "            extracted_chars.extend(extracted.keys())\n",
    "        \n",
    "        coverage = len(set(extracted_chars)) / len(expected_chars) * 100\n",
    "        performance_report['characteristics_coverage'][category] = coverage\n",
    "        \n",
    "        if coverage < 70:\n",
    "            performance_report['recommendations'].append(\n",
    "                f\"Низкое покрытие характеристик для '{category}': {coverage:.1f}%\"\n",
    "            )\n",
    "    \n",
    "    return performance_report\n",
    "\n",
    "def create_update_checklist(new_classes):\n",
    "    \"\"\"Создание чеклиста для обновления\"\"\"\n",
    "    checklist = {\n",
    "        'required_actions': [\n",
    "            \"Добавить новые классы в конфигурацию\",\n",
    "            \"Определить характеристики для каждого класса\", \n",
    "            \"Настроить паттерны извлечения для новых характеристик\",\n",
    "            \"Добавить специализированные методы извлечения при необходимости\",\n",
    "            \"Протестировать на代表性тельных данных\",\n",
    "            \"Обновить документацию\"\n",
    "        ],\n",
    "        'new_classes': new_classes,\n",
    "        'testing_requirements': [\n",
    "            f\"Проверить извлечение характеристик для {cls}\" for cls in new_classes\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return checklist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
